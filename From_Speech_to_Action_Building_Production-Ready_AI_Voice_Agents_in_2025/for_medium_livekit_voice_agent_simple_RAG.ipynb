{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet \"livekit-agents[openai,silero]\"\n",
        "!pip install --quiet livekit-api\n",
        "!pip install --quiet llama-index\n",
        "!pip install --quiet aiohttp\n",
        "!pip install --quiet nest-asyncio"
      ],
      "metadata": {
        "id": "GvX8sVWMa0_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYwVPY_Hat5B"
      },
      "outputs": [],
      "source": [
        "# WORKING NOTEBOOK + RAG\n",
        "\n",
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# =============================================================================\n",
        "# SET YOUR API KEYS HERE (same as working version)\n",
        "# =============================================================================\n",
        "# os.environ['OPENAI_API_KEY'] = 'your-openai-api-key-here'\n",
        "# os.environ['ELEVEN_API_KEY'] = 'your-elevenlabs-api-key-here'  # Optional\n",
        "# os.environ['LIVEKIT_URL'] = 'wss://your-project.livekit.cloud'\n",
        "# os.environ['LIVEKIT_API_KEY'] = 'your-livekit-api-key'\n",
        "# os.environ['LIVEKIT_API_SECRET'] = 'your-livekit-api-secret'\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# QUICK RAG SETUP (works with YOUR uploaded files)\n",
        "# =============================================================================\n",
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
        "\n",
        "# Setup directories\n",
        "DATA_DIR = Path(\"/content/rag_data\")\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"üìÅ UPLOAD YOUR OWN FILES:\")\n",
        "print(\"1. Click the folder icon on the left sidebar\")\n",
        "print(\"2. Upload your .txt files to Colab\")\n",
        "print(\"3. Run this code to move them:\")\n",
        "print(\"\")\n",
        "print(\"# Copy your uploaded files to the RAG directory\")\n",
        "print(\"!cp /content/*.txt /content/rag_data/\")\n",
        "print(\"\")\n",
        "print(\"4. Then run the main code below\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def setup_quick_rag():\n",
        "    \"\"\"RAG setup using YOUR uploaded files\"\"\"\n",
        "    global rag_index\n",
        "\n",
        "    print(\"üìÅ Looking for your uploaded text files...\")\n",
        "\n",
        "    # Check for uploaded files first\n",
        "    uploaded_files = list(DATA_DIR.glob(\"*.txt\"))\n",
        "\n",
        "    if uploaded_files:\n",
        "        print(f\"‚úÖ Found {len(uploaded_files)} uploaded files:\")\n",
        "        for file in uploaded_files:\n",
        "            print(f\"   - {file.name}\")\n",
        "    else:\n",
        "        print(\"üìù No uploaded files found. Creating sample documents...\")\n",
        "        print(\"üí° To use your own files:\")\n",
        "        print(\"   1. Upload .txt files to Colab\")\n",
        "        print(\"   2. Move them to /content/rag_data/\")\n",
        "        print(\"   3. Restart this cell\")\n",
        "        print(\"\")\n",
        "\n",
        "        # Create sample documents as fallback\n",
        "        sample_docs = [\n",
        "            (\"ai_basics.txt\", \"\"\"\n",
        "            Artificial Intelligence (AI) is computer science focused on creating intelligent machines.\n",
        "            Machine Learning is a subset of AI that learns from data without explicit programming.\n",
        "            Deep Learning uses neural networks with multiple layers for complex pattern recognition.\n",
        "            Natural Language Processing (NLP) enables computers to understand human language.\n",
        "            Computer Vision allows machines to interpret visual information from images and videos.\n",
        "            The three main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning.\n",
        "            \"\"\"),\n",
        "\n",
        "            (\"python_info.txt\", \"\"\"\n",
        "            Python is a high-level programming language known for simplicity and readability.\n",
        "            Popular Python libraries include NumPy for numerical computing, Pandas for data analysis,\n",
        "            Matplotlib for visualization, Scikit-learn for machine learning, and TensorFlow for deep learning.\n",
        "            Python is used in web development, data science, automation, and artificial intelligence.\n",
        "            Python was created by Guido van Rossum and first released in 1991.\n",
        "            \"\"\"),\n",
        "\n",
        "            (\"vector_db_info.txt\", \"\"\"\n",
        "            Vector databases store high-dimensional vectors and enable similarity search.\n",
        "            Embeddings are numerical representations of data as vectors in high-dimensional space.\n",
        "            Popular vector databases include Pinecone, Weaviate, Chroma, and FAISS.\n",
        "            Vector databases are essential for RAG systems, recommendation engines, and semantic search.\n",
        "            Similarity search in vector databases typically uses cosine similarity or Euclidean distance.\n",
        "            \"\"\")\n",
        "        ]\n",
        "\n",
        "        # Write sample documents\n",
        "        for filename, content in sample_docs:\n",
        "            doc_path = DATA_DIR / filename\n",
        "            if not doc_path.exists():\n",
        "                with open(doc_path, 'w') as f:\n",
        "                    f.write(content)\n",
        "\n",
        "    # Create RAG index from all files in directory\n",
        "    print(\"üß† Building RAG index from text files...\")\n",
        "    documents = SimpleDirectoryReader(str(DATA_DIR)).load_data()\n",
        "    rag_index = VectorStoreIndex.from_documents(documents)\n",
        "    print(f\"‚úÖ RAG ready with {len(documents)} documents\")\n",
        "\n",
        "    # Show what's in the knowledge base\n",
        "    print(f\"üìö Knowledge base contains:\")\n",
        "    for doc in documents:\n",
        "        # Get first 100 characters as preview\n",
        "        preview = doc.text[:100].replace('\\n', ' ').strip()\n",
        "        print(f\"   - {preview}...\")\n",
        "\n",
        "\n",
        "# Initialize RAG\n",
        "rag_index = None\n",
        "setup_quick_rag()\n",
        "\n",
        "# =============================================================================\n",
        "# LIVEKIT SETUP\n",
        "# =============================================================================\n",
        "logger = logging.getLogger(\"dlai-agent\")\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "from livekit import agents\n",
        "from livekit.agents import Agent, AgentSession, JobContext, WorkerOptions, jupyter, llm\n",
        "from livekit.plugins import (\n",
        "    openai,\n",
        "    elevenlabs,\n",
        "    silero,\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# RAG FUNCTION\n",
        "# =============================================================================\n",
        "@llm.function_tool\n",
        "async def search_knowledge(query: str) -> str:\n",
        "    \"\"\"REQUIRED: Search the knowledge base for information. Must be used for ALL questions.\"\"\"\n",
        "    try:\n",
        "        print(f\"üîç RAG Search: {query}\")\n",
        "        query_engine = rag_index.as_query_engine(\n",
        "            use_async=True,\n",
        "            similarity_top_k=3,  # Get top 3 most relevant chunks\n",
        "        )\n",
        "        response = await query_engine.aquery(query)\n",
        "        result = str(response)\n",
        "\n",
        "        # Check if we got meaningful results\n",
        "        if len(result.strip()) < 20 or \"sorry\" in result.lower():\n",
        "            return \"NO_KNOWLEDGE_FOUND: I don't have information about this topic in my knowledge base.\"\n",
        "\n",
        "        print(f\"üìù RAG Answer: {result[:100]}...\")\n",
        "        return f\"KNOWLEDGE_BASE_RESULT: {result}\"\n",
        "    except Exception as e:\n",
        "        return f\"SEARCH_ERROR: I couldn't search the knowledge base: {str(e)}\"\n",
        "\n",
        "# =============================================================================\n",
        "# ASSISTANT CLASS\n",
        "# =============================================================================\n",
        "class Assistant(Agent):\n",
        "    def __init__(self) -> None:\n",
        "        llm_model = openai.LLM(model=\"gpt-4o\")\n",
        "        stt = openai.STT()\n",
        "        tts = elevenlabs.TTS()\n",
        "        #tts = elevenlabs.TTS(voice_id=\"CwhRBWXzGAHq8TQ4Fs17\")  # example with defined voice\n",
        "        silero_vad = silero.VAD.load()\n",
        "\n",
        "        super().__init__(\n",
        "            instructions=\"\"\"\n",
        "                CRITICAL INSTRUCTIONS - FOLLOW EXACTLY:\n",
        "\n",
        "                1. You MUST use the search_knowledge function for EVERY question or request.\n",
        "                2. You can ONLY answer based on information returned by search_knowledge.\n",
        "                3. If search_knowledge returns \"NO_KNOWLEDGE_FOUND\", say \"I don't have that information in my knowledge base.\"\n",
        "                4. If search_knowledge returns \"SEARCH_ERROR\", say \"I'm having trouble accessing my knowledge base.\"\n",
        "                5. NEVER use your built-in knowledge or training data to answer questions.\n",
        "                6. ALWAYS start your response by calling search_knowledge first.\n",
        "                7. If the search result doesn't fully answer the question, say \"My knowledge base has limited information on this topic\" and only share what was found.\n",
        "\n",
        "                You are a voice assistant that ONLY knows what's in the knowledge base.\n",
        "                Keep responses conversational and concise for voice interaction.\n",
        "            \"\"\",\n",
        "            stt=stt,\n",
        "            llm=llm_model,\n",
        "            tts=tts,\n",
        "            vad=silero_vad,\n",
        "            tools=[search_knowledge],  # ADD RAG TOOL HERE\n",
        "        )\n",
        "\n",
        "# =============================================================================\n",
        "# ENTRYPOINT\n",
        "# =============================================================================\n",
        "async def entrypoint(ctx: JobContext):\n",
        "    await ctx.connect()\n",
        "\n",
        "    session = AgentSession()\n",
        "\n",
        "    await session.start(\n",
        "        room=ctx.room,\n",
        "        agent=Assistant()\n",
        "    )\n",
        "\n",
        "# =============================================================================\n",
        "# RUN SETUP\n",
        "# =============================================================================\n",
        "print(\"üöÄ Starting your working notebook + RAG...\")\n",
        "print(\"üß† Now with knowledge about AI, Python, and vector databases!\")\n",
        "print(\"\")\n",
        "print(\"üìù Instructions:\")\n",
        "print(\"- Unmute the microphone symbol on the left\")\n",
        "print(\"- You can ignore the 'Start Audio' button\")\n",
        "print(\"- Start by speaking a long phrase like 'hello, how are you today'\")\n",
        "print(\"\")\n",
        "print(\"üé§ Try asking (should work - in knowledge base):\")\n",
        "print(\"- 'What is machine learning?'\")\n",
        "print(\"- 'Tell me about Python programming'\")\n",
        "print(\"- 'How do vector databases work?'\")\n",
        "print(\"- 'Who created Python?'\")\n",
        "print(\"\")\n",
        "print(\"üö´ Try asking (should say 'no knowledge'):\")\n",
        "print(\"- 'What's the weather today?'\")\n",
        "print(\"- 'Tell me about JavaScript'\")\n",
        "print(\"- 'Who is the CEO of our company?'\")\n",
        "print(\"\")\n",
        "print(\"‚úÖ The agent will ONLY answer from YOUR uploaded files (or samples if none uploaded)!\")\n",
        "\n",
        "# jupyter.run_app call\n",
        "jupyter.run_app(\n",
        "    WorkerOptions(entrypoint_fnc=entrypoint),\n",
        "    jupyter_url=\"https://jupyter-api-livekit.vercel.app/api/join-token\"\n",
        ")\n"
      ]
    }
  ]
}
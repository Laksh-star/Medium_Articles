{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install videodb\n",
        "%pip install llama-index\n",
        "%pip install llama-index-retrievers-videodb"
      ],
      "metadata": {
        "id": "FA7FzVEMp7nG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import List, Dict, Optional, Union\n",
        "from dataclasses import dataclass\n",
        "from videodb import connect, SceneExtractionType, SearchType, IndexType\n",
        "from llama_index.core import get_response_synthesizer\n",
        "from llama_index.retrievers.videodb import VideoDBRetriever\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from videodb.timeline import Timeline\n",
        "from videodb.asset import VideoAsset\n",
        "\n",
        "@dataclass\n",
        "class SceneInfo:\n",
        "    video_id: str  # Added video_id to track which video the scene belongs to\n",
        "    start_time: float\n",
        "    end_time: float\n",
        "    description: str\n",
        "    emotions: List[str]\n",
        "    characters: List[str]\n",
        "    dialogue: str\n",
        "\n",
        "class MovieSceneAnalyzer:\n",
        "    def __init__(self, videodb_api_key: str, openai_api_key: str):\n",
        "        \"\"\"Initialize the Movie Scene Analyzer with required API keys.\"\"\"\n",
        "        os.environ[\"VIDEO_DB_API_KEY\"] = videodb_api_key\n",
        "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "        self.conn = connect()\n",
        "        self.collection = self.conn.create_collection(\n",
        "            name=\"Movie Scene Analysis\",\n",
        "            description=\"Analysis of movie and TV scenes\"\n",
        "        )\n",
        "        self.llm = OpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "    def process_video(self, video) -> dict:\n",
        "        \"\"\"Process a video by indexing speech and scenes.\"\"\"\n",
        "        try:\n",
        "            # Index spoken content\n",
        "            print(\"Indexing spoken content...\")\n",
        "            video.index_spoken_words()\n",
        "\n",
        "            # Index visual scenes\n",
        "            print(\"Indexing visual content...\")\n",
        "            scene_index_id = video.index_scenes(\n",
        "                extraction_type=SceneExtractionType.shot_based,\n",
        "                extraction_config={\"frame_count\": 5},\n",
        "                prompt=\"Describe the scene in detail including: setting, characters, actions, emotions, and cinematography\"\n",
        "            )\n",
        "\n",
        "            return {\"success\": True, \"scene_index_id\": scene_index_id}\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing video: {str(e)}\")\n",
        "            return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "    def add_video(self, url: str, title: str) -> dict:\n",
        "        \"\"\"Add a new video to the collection and process it.\"\"\"\n",
        "        try:\n",
        "            # Upload video\n",
        "            print(f\"Uploading video: {title}\")\n",
        "            video = self.collection.upload(url=url)\n",
        "\n",
        "            # Process the video\n",
        "            process_result = self.process_video(video)\n",
        "\n",
        "            if process_result[\"success\"]:\n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"video_id\": video.id,\n",
        "                    \"scene_index_id\": process_result[\"scene_index_id\"],\n",
        "                    \"title\": title\n",
        "                }\n",
        "            else:\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"error\": process_result[\"error\"]\n",
        "                }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error adding video: {str(e)}\")\n",
        "            return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "    def search_scenes(self, query: str, video_id: Optional[str] = None) -> List[SceneInfo]:\n",
        "        \"\"\"Search for scenes matching the query.\"\"\"\n",
        "        try:\n",
        "            # Configure retrievers\n",
        "            spoken_retriever = VideoDBRetriever(\n",
        "                collection=self.collection.id,\n",
        "                video=video_id,\n",
        "                search_type=SearchType.semantic,\n",
        "                index_type=IndexType.spoken_word,\n",
        "                score_threshold=0.2,\n",
        "            )\n",
        "\n",
        "            scene_retriever = VideoDBRetriever(\n",
        "                collection=self.collection.id,\n",
        "                video=video_id,\n",
        "                search_type=SearchType.semantic,\n",
        "                index_type=IndexType.scene,\n",
        "                score_threshold=0.2,\n",
        "            )\n",
        "\n",
        "            # Get relevant nodes\n",
        "            nodes = spoken_retriever.retrieve(query) + scene_retriever.retrieve(query)\n",
        "\n",
        "            # Extract scene information\n",
        "            scenes = []\n",
        "            for node in nodes:\n",
        "                scene = SceneInfo(\n",
        "                    video_id=node.metadata[\"video_id\"],\n",
        "                    start_time=node.metadata[\"start\"],\n",
        "                    end_time=node.metadata[\"end\"],\n",
        "                    description=node.text,\n",
        "                    emotions=self._extract_emotions(node.text),\n",
        "                    characters=self._extract_characters(node.text),\n",
        "                    dialogue=node.text if node.metadata.get(\"type\") == \"spoken\" else \"\"\n",
        "                )\n",
        "                scenes.append(scene)\n",
        "\n",
        "            return self._merge_overlapping_scenes(scenes)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error searching scenes: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def create_character_compilation(self,\n",
        "                                  character_name: str,\n",
        "                                  video_id: Optional[str] = None) -> Union[str, None]:\n",
        "        \"\"\"Create a compilation of scenes featuring a specific character.\"\"\"\n",
        "        try:\n",
        "            # Search for character scenes\n",
        "            scenes = self.search_scenes(f\"scenes with {character_name}\", video_id)\n",
        "\n",
        "            if not scenes:\n",
        "                print(f\"No scenes found for character: {character_name}\")\n",
        "                return None\n",
        "\n",
        "            # Create timeline\n",
        "            timeline = Timeline(self.conn)\n",
        "\n",
        "            # Add scenes to timeline\n",
        "            for scene in scenes:\n",
        "                try:\n",
        "                    asset = VideoAsset(\n",
        "                        asset_id=scene.video_id,\n",
        "                        start=scene.start_time,\n",
        "                        end=scene.end_time\n",
        "                    )\n",
        "                    timeline.add_inline(asset)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error adding scene to timeline: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            # Generate stream\n",
        "            try:\n",
        "                return timeline.generate_stream()\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating stream: {str(e)}\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating character compilation: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def _extract_emotions(self, text: str) -> List[str]:\n",
        "        \"\"\"Extract emotional content from scene description.\"\"\"\n",
        "        try:\n",
        "            prompt = \"Extract emotions from: \" + text\n",
        "            response = self.llm.complete(prompt)\n",
        "            return [emotion.strip() for emotion in response.text.split(\",\")]\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting emotions: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def _extract_characters(self, text: str) -> List[str]:\n",
        "        \"\"\"Extract character names from scene description.\"\"\"\n",
        "        try:\n",
        "            prompt = \"Extract character names from: \" + text\n",
        "            response = self.llm.complete(prompt)\n",
        "            return [name.strip() for name in response.text.split(\",\")]\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting characters: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def _merge_overlapping_scenes(self, scenes: List[SceneInfo]) -> List[SceneInfo]:\n",
        "        \"\"\"Merge overlapping scene segments.\"\"\"\n",
        "        if not scenes:\n",
        "            return []\n",
        "\n",
        "        # Sort scenes by start time\n",
        "        sorted_scenes = sorted(scenes, key=lambda x: x.start_time)\n",
        "        merged = [sorted_scenes[0]]\n",
        "\n",
        "        for current in sorted_scenes[1:]:\n",
        "            previous = merged[-1]\n",
        "\n",
        "            # Only merge scenes from the same video\n",
        "            if (current.video_id == previous.video_id and\n",
        "                current.start_time <= previous.end_time):\n",
        "                # Merge scenes\n",
        "                previous.end_time = max(previous.end_time, current.end_time)\n",
        "                previous.description += f\"\\n{current.description}\"\n",
        "                previous.emotions = list(set(previous.emotions + current.emotions))\n",
        "                previous.characters = list(set(previous.characters + current.characters))\n",
        "                previous.dialogue += f\"\\n{current.dialogue}\"\n",
        "            else:\n",
        "                merged.append(current)\n",
        "\n",
        "        return merged\n",
        "\n",
        "# Example usage\n",
        "def main():\n",
        "    try:\n",
        "        # Initialize the analyzer\n",
        "        analyzer = MovieSceneAnalyzer(\n",
        "            videodb_api_key=\"your_api_key_here\",\n",
        "            openai_api_key=\"your_api_key_here\"\n",
        "        )\n",
        "\n",
        "        # Add and process a video\n",
        "        video_info = analyzer.add_video(\n",
        "            url=\"https://www.youtube.com/watch?v=bTN3q_NjuWs\",  # Example video URL\n",
        "            title=\"Test Movie\"\n",
        "        )\n",
        "\n",
        "        if not video_info[\"success\"]:\n",
        "            print(f\"Failed to add video: {video_info.get('error')}\")\n",
        "            return\n",
        "\n",
        "        print(\"Video added successfully!\")\n",
        "        print(f\"Video ID: {video_info['video_id']}\")\n",
        "\n",
        "        # Search for scenes\n",
        "        scenes = analyzer.search_scenes(\n",
        "            \"dramatic scenes with dialogue\",\n",
        "            video_info[\"video_id\"]\n",
        "        )\n",
        "\n",
        "        if scenes:\n",
        "            print(f\"\\nFound {len(scenes)} scenes:\")\n",
        "            for i, scene in enumerate(scenes, 1):\n",
        "                print(f\"\\nScene {i}:\")\n",
        "                print(f\"Time: {scene.start_time:.2f}s - {scene.end_time:.2f}s\")\n",
        "                print(f\"Description: {scene.description}\")\n",
        "                print(f\"Characters: {', '.join(scene.characters)}\")\n",
        "                print(f\"Emotions: {', '.join(scene.emotions)}\")\n",
        "\n",
        "            # Try to create a character compilation\n",
        "            compilation = analyzer.create_character_compilation(\n",
        "                scenes[0].characters[0] if scenes[0].characters else \"main character\",\n",
        "                video_info[\"video_id\"]\n",
        "            )\n",
        "\n",
        "            if compilation:\n",
        "                print(f\"\\nCharacter compilation created: {compilation}\")\n",
        "            else:\n",
        "                print(\"\\nFailed to create character compilation\")\n",
        "        else:\n",
        "            print(\"\\nNo scenes found matching the criteria\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "jZtp7BnGpvR5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
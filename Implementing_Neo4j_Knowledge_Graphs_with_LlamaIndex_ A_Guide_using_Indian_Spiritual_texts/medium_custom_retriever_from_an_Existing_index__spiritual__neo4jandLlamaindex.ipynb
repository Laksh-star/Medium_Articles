{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install llama-index llama-index-graph-stores-neo4j openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNci3nGGrQlH",
        "outputId": "48f3cd04-6c08-4bc5-efc2-67a4032369b4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.10.55-py3-none-any.whl (6.8 kB)\n",
            "Collecting llama-index-graph-stores-neo4j\n",
            "  Downloading llama_index_graph_stores_neo4j-0.2.7-py3-none-any.whl (11 kB)\n",
            "Collecting openai\n",
            "  Downloading openai-1.35.14-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.2.8-py3-none-any.whl (13 kB)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
            "Collecting llama-index-core==0.10.55 (from llama-index)\n",
            "  Downloading llama_index_core-0.10.55-py3-none-any.whl (15.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.2.5-py3-none-any.whl (9.3 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.1.25-py3-none-any.whl (11 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.7-py3-none-any.whl (5.9 kB)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.1.30-py3-none-any.whl (38 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (3.9.5)\n",
            "Collecting dataclasses-json (from llama-index-core==0.10.55->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.55->llama-index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.55->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (2023.6.0)\n",
            "Collecting httpx (from llama-index-core==0.10.55->llama-index)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (8.5.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core==0.10.55->llama-index)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core==0.10.55->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (1.14.1)\n",
            "Collecting neo4j<6.0.0,>=5.16.0 (from llama-index-graph-stores-neo4j)\n",
            "  Downloading neo4j-5.22.0-py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.5/293.5 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.55->llama-index) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core==0.10.55->llama-index)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core==0.10.55->llama-index)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-cloud>=0.0.9 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index)\n",
            "  Downloading llama_cloud-0.0.9-py3-none-any.whl (146 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.8/146.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading pypdf-4.3.0-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index)\n",
            "  Downloading llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j<6.0.0,>=5.16.0->llama-index-graph-stores-neo4j) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.55->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.55->llama-index) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.55->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.55->llama-index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.55->llama-index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.55->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.55->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.55->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.55->llama-index) (2024.5.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.55->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.55->llama-index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.55->llama-index) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.10.55->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core==0.10.55->llama-index)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.55->llama-index) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.55->llama-index) (2024.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.55->llama-index) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.55->llama-index) (1.16.0)\n",
            "Installing collected packages: striprtf, dirtyjson, pypdf, neo4j, mypy-extensions, marshmallow, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llama-cloud, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-graph-stores-neo4j, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "Successfully installed dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 llama-cloud-0.0.9 llama-index-0.10.55 llama-index-agent-openai-0.2.8 llama-index-cli-0.1.12 llama-index-core-0.10.55 llama-index-embeddings-openai-0.1.10 llama-index-graph-stores-neo4j-0.2.7 llama-index-indices-managed-llama-cloud-0.2.5 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.25 llama-index-multi-modal-llms-openai-0.1.7 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.30 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.9 marshmallow-3.21.3 mypy-extensions-1.0.0 neo4j-5.22.0 openai-1.35.14 pypdf-4.3.0 striprtf-0.0.26 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj4cEO74q-B8",
        "outputId": "2a957063-7bd6-46fe-af09-5e17a20bae0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The procedure has a deprecated field. ('config' used by 'apoc.meta.graphSample' is deprecated.)} {position: line: 1, column: 1, offset: 0} for query: \"CALL apoc.meta.graphSample() YIELD nodes, relationships RETURN nodes, [rel in relationships | {name:apoc.any.property(rel, 'type'), count: apoc.any.property(rel, 'count')}] AS relationships\"\n"
          ]
        }
      ],
      "source": [
        "# this version is on spiritual texts,  Vidura Neethi,  Bhagavad Gita, , Ashtavakra Sanksrit, Sri Aurobindo\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core import PropertyGraphIndex\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.llms.openai import OpenAI\n",
        "import os\n",
        "import openai\n",
        "from llama_index.core.indices.property_graph import SchemaLLMPathExtractor\n",
        "import nest_asyncio\n",
        "import asyncio\n",
        "\n",
        "# Apply nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your_api_key_here\"\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
        "\n",
        "\n",
        "graph_store = Neo4jPropertyGraphStore(\n",
        "    username=\"neo4j\",\n",
        "    password=\"your_neo4j_instance_password\",\n",
        "    url=\"your_neo4j_db.databases.neo4j.io\",\n",
        ")\n",
        "\n",
        "# Use the existing index\n",
        "\n",
        "index = PropertyGraphIndex.from_existing(\n",
        "    property_graph_store=graph_store,\n",
        "    llm=OpenAI(model=\"gpt-4-turbo\", temperature=0.7),\n",
        "    embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\"),\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define retriever- default one\n",
        "# retriever = index.as_retriever(\n",
        "#     include_text=False,  # include source text in returned nodes, default True\n",
        "# )"
      ],
      "metadata": {
        "id": "Qzgg4zmQZhtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom retriever-from github - 18 July 6:44am\n",
        "from pydantic import BaseModel\n",
        "from typing import Optional, List\n",
        "\n",
        "\n",
        "class Entities(BaseModel):\n",
        "    \"\"\"List of named entities in the text such as names of people, organizations, concepts, and spiritual texts\"\"\"\n",
        "    names: Optional[List[str]]\n",
        "\n",
        "\n",
        "prompt_template_entities = \"\"\"\n",
        "Extract all named entities such as names of people, organizations, concepts, and spiritual texts\n",
        "from the following text:\n",
        "{text}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Rofu5pTmZkqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom retriever-from github - 18 July 6:44am\n",
        "from typing import Any, Optional\n",
        "\n",
        "from llama_index.core.embeddings import BaseEmbedding\n",
        "from llama_index.core.retrievers import CustomPGRetriever, VectorContextRetriever\n",
        "from llama_index.core.vector_stores.types import VectorStore\n",
        "from llama_index.program.openai import OpenAIPydanticProgram\n",
        "\n",
        "\n",
        "class MyCustomRetriever(CustomPGRetriever):\n",
        "    \"\"\"Custom retriever with cohere reranking.\"\"\"\n",
        "\n",
        "    def init(\n",
        "        self,\n",
        "        ## vector context retriever params\n",
        "        embed_model: Optional[BaseEmbedding] = None,\n",
        "        vector_store: Optional[VectorStore] = None,\n",
        "        similarity_top_k: int = 4,\n",
        "        path_depth: int = 1,\n",
        "        include_text: bool = True,\n",
        "        **kwargs: Any,\n",
        "    ) -> None:\n",
        "        \"\"\"Uses any kwargs passed in from class constructor.\"\"\"\n",
        "        self.entity_extraction = OpenAIPydanticProgram.from_defaults(\n",
        "            output_cls=Entities, prompt_template_str=prompt_template_entities\n",
        "        )\n",
        "        self.vector_retriever = VectorContextRetriever(\n",
        "            self.graph_store,\n",
        "            include_text=self.include_text,\n",
        "            embed_model=embed_model,\n",
        "            similarity_top_k=similarity_top_k,\n",
        "            path_depth=path_depth,\n",
        "        )\n",
        "\n",
        "    def custom_retrieve(self, query_str: str) -> str:\n",
        "        \"\"\"Define custom retriever with reranking.\n",
        "\n",
        "        Could return `str`, `TextNode`, `NodeWithScore`, or a list of those.\n",
        "        \"\"\"\n",
        "        entities = self.entity_extraction(text=query_str).names\n",
        "        result_nodes = []\n",
        "        if entities:\n",
        "            print(f\"Detected entities: {entities}\")\n",
        "            for entity in entities:\n",
        "                result_nodes.extend(self.vector_retriever.retrieve(entity))\n",
        "        else:\n",
        "            result_nodes.extend(self.vector_retriever.retrieve(query_str))\n",
        "        ## TMP: please change\n",
        "        final_text = \"\\n\\n\".join(\n",
        "            [n.get_content(metadata_mode=\"llm\") for n in result_nodes]\n",
        "        )\n",
        "        return final_text"
      ],
      "metadata": {
        "id": "0RtGEzjuZukx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
        "#llm = OpenAI(model=\"gpt-4o\", temperature=0.0)\n",
        "embed_model = OpenAIEmbedding(model_name=\"text-embedding-3-small\")\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "custom_sub_retriever = MyCustomRetriever(\n",
        "    index.property_graph_store,\n",
        "    include_text=True,\n",
        "    vector_store=index.vector_store,\n",
        "    embed_model=embed_model\n",
        ")\n",
        "\n",
        "query_engine = RetrieverQueryEngine.from_args(\n",
        "    index.as_retriever(sub_retrievers=[custom_sub_retriever]), llm=llm\n",
        ")"
      ],
      "metadata": {
        "id": "QFLPaGDkaC2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are the 3 most important practical teachings that one can imbibe in daily life from Vidura and mention source?\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxbvmRJTaKeI",
        "outputId": "7cc3df20-d698-42d2-b5f6-9e23779fb2a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forgiveness, Non-violence, and Truth are the three most important practical teachings that one can imbibe in daily life from Vidura. The source of these teachings can be found in the work Vidura worked on, namely Vidura-N∂ti.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# results = retriever.retrieve(\"What are the 3 most important practical teachings that one can imbibe in daily life from Vidura?\")\n",
        "# for record in results:\n",
        "#     print(record.text)\n",
        "# query_engine = index.as_query_engine(include_text=True)\n",
        "# response = query_engine.query(\"What are the 3 most important practical teachings that one can imbibe in daily life from Vidura?\")\n",
        "# print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSb-kNWgbI-i",
        "outputId": "590881b2-2005-4e22-9fab-f431675b0501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vidura -> WORKED_ON -> Vidura-N∂ti\n",
            "Vidura -> WORKED_ON -> Udyogaparvaƒi-Prajågaraparvaƒi\n",
            "Vidura -> WORKED_ON -> Mahåbhårata\n",
            "Vidura -> WORKED_ON -> Neeti\n",
            "Vidura -> WORKED_ON -> King's Chambers\n",
            "Vidura -> WORKED_ON -> Human welfare\n",
            "Vidura -> WORKED_ON -> Friendship\n",
            "Vidura -> WORKED_ON -> Forgiveness\n",
            "Vidura -> WORKED_ON -> Non-violence\n",
            "Vidura -> WORKED_ON -> Justice\n",
            "Vidura -> WORKED_ON -> Truth\n",
            "Vidura -> WORKED_ON -> Polity\n",
            "Vidura -> WORKED_ON -> Råja Dharma\n",
            "Vidura -> WORKED_ON -> Mahåbhårata-Udyogaparva\n",
            "Virochana -> WORKED_ON -> spiritual instructions from Prajapati\n",
            "Ashtavakra -> WORKED_ON -> Ashtavakra-Gita\n",
            "Friendship, Forgiveness, and Non-violence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How can one correlate Ashtavakra Gita, Vidura Neeti and Bhagavad Gita?\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oEu-2oagxp9",
        "outputId": "25ce24c3-15e5-4052-fc5f-b43181e51e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One can correlate Ashtavakra Gita, Vidura Neeti, and Bhagavad Gita by recognizing their teachings on aspects such as liberation, wisdom, self-realization, and the nature of reality. Each text provides insights into the path to liberation, the importance of detachment, the nature of the self, and the significance of wisdom in navigating life's challenges. By studying these texts, one can gain a deeper understanding of spiritual principles and practical guidance for leading a fulfilling and purposeful life.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"Correlate Ashtavakra Gita, Vidura Neeti and Bhagavad Gita and generate a two stanza poem\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yntjZWshB6E",
        "outputId": "a2b6ed2a-ed61-4f39-c63e-eae84b0751dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In teachings profound, Ashtavakra spoke,  \n",
            "Mind's bondage and liberation he awoke.  \n",
            "Transcending desires, attachment's snare,  \n",
            "In detachment lies freedom, beyond all care.  \n",
            "\n",
            "Vidura's wisdom, like a guiding light,  \n",
            "Echoes Bhagavad Gita's truth so bright.  \n",
            "Through selfless devotion and wisdom pure,  \n",
            "Attain the Supreme, salvation's ultimate lure.\n"
          ]
        }
      ]
    }
  ]
}
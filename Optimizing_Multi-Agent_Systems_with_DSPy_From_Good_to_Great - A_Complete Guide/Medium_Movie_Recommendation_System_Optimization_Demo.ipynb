{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tY497m8aTbdM",
        "outputId": "3acb71a2-b5d7-4a83-e8a8-cff56ab8dcad",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dspy-ai\n",
            "  Downloading dspy_ai-2.6.27-py3-none-any.whl.metadata (286 bytes)\n",
            "Collecting dspy>=2.6.5 (from dspy-ai)\n",
            "  Downloading dspy-2.6.27-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting backoff>=2.2 (from dspy>=2.6.5->dspy-ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: joblib~=1.3 in /usr/local/lib/python3.11/dist-packages (from dspy>=2.6.5->dspy-ai) (1.5.1)\n",
            "Requirement already satisfied: openai>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from dspy>=2.6.5->dspy-ai) (1.91.0)\n",
            "Requirement already satisfied: pandas>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from dspy>=2.6.5->dspy-ai) (2.2.2)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.11/dist-packages (from dspy>=2.6.5->dspy-ai) (2024.11.6)\n",
            "Collecting ujson>=5.8.0 (from dspy>=2.6.5->dspy-ai)\n",
            "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from dspy>=2.6.5->dspy-ai) (4.67.1)\n",
            "Collecting datasets>=2.14.6 (from dspy>=2.6.5->dspy-ai)\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from dspy>=2.6.5->dspy-ai) (2.32.3)\n",
            "Collecting optuna>=3.4.0 (from dspy>=2.6.5->dspy-ai)\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from dspy>=2.6.5->dspy-ai) (2.11.7)\n",
            "Collecting magicattr>=0.1.6 (from dspy>=2.6.5->dspy-ai)\n",
            "  Downloading magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting litellm>=1.60.3 (from dspy>=2.6.5->dspy-ai)\n",
            "  Downloading litellm-1.73.6-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting diskcache>=5.6.0 (from dspy>=2.6.5->dspy-ai)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting json-repair>=0.30.0 (from dspy>=2.6.5->dspy-ai)\n",
            "  Downloading json_repair-0.47.4-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from dspy>=2.6.5->dspy-ai) (8.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from dspy>=2.6.5->dspy-ai) (4.9.0)\n",
            "Collecting asyncer==0.0.8 (from dspy>=2.6.5->dspy-ai)\n",
            "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: cachetools>=5.5.0 in /usr/local/lib/python3.11/dist-packages (from dspy>=2.6.5->dspy-ai) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dspy>=2.6.5->dspy-ai) (3.1.1)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from dspy>=2.6.5->dspy-ai) (13.9.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from dspy>=2.6.5->dspy-ai) (2.0.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio->dspy>=2.6.5->dspy-ai) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->dspy>=2.6.5->dspy-ai) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->dspy>=2.6.5->dspy-ai) (4.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->dspy>=2.6.5->dspy-ai)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (6.0.2)\n",
            "Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (3.11.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (8.2.1)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (4.24.0)\n",
            "Collecting python-dotenv>=0.2.0 (from litellm>=1.60.3->dspy>=2.6.5->dspy-ai)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (0.9.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (0.21.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=0.28.1->dspy>=2.6.5->dspy-ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=0.28.1->dspy>=2.6.5->dspy-ai) (0.10.0)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.4.0->dspy>=2.6.5->dspy-ai)\n",
            "  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna>=3.4.0->dspy>=2.6.5->dspy-ai)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.4.0->dspy>=2.6.5->dspy-ai) (2.0.41)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.1->dspy>=2.6.5->dspy-ai) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.1->dspy>=2.6.5->dspy-ai) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.1->dspy>=2.6.5->dspy-ai) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dspy>=2.6.5->dspy-ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dspy>=2.6.5->dspy-ai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dspy>=2.6.5->dspy-ai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->dspy>=2.6.5->dspy-ai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->dspy>=2.6.5->dspy-ai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->dspy>=2.6.5->dspy-ai) (2025.6.15)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->dspy>=2.6.5->dspy-ai) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->dspy>=2.6.5->dspy-ai) (2.19.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (1.20.1)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy>=2.6.5->dspy-ai) (1.1.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (1.1.5)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy>=2.6.5->dspy-ai) (0.25.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy>=2.6.5->dspy-ai) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1.1->dspy>=2.6.5->dspy-ai) (1.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.4.0->dspy>=2.6.5->dspy-ai) (3.2.3)\n",
            "Downloading dspy_ai-2.6.27-py3-none-any.whl (1.1 kB)\n",
            "Downloading dspy-2.6.27-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.3/297.3 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.47.4-py3-none-any.whl (22 kB)\n",
            "Downloading litellm-1.73.6-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading magicattr-0.1.6-py2.py3-none-any.whl (4.7 kB)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: magicattr, ujson, python-dotenv, json-repair, fsspec, diskcache, colorlog, backoff, asyncer, alembic, optuna, litellm, datasets, dspy, dspy-ai\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alembic-1.16.2 asyncer-0.0.8 backoff-2.2.1 colorlog-6.9.0 datasets-3.6.0 diskcache-5.6.3 dspy-2.6.27 dspy-ai-2.6.27 fsspec-2025.3.0 json-repair-0.47.4 litellm-1.73.6 magicattr-0.1.6 optuna-4.4.0 python-dotenv-1.1.1 ujson-5.10.0\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-3.1.1-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting mlflow-skinny==3.1.1 (from mlflow)\n",
            "  Downloading mlflow_skinny-3.1.1-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.1)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.16.2)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<21,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.41)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (8.2.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.1.1->mlflow)\n",
            "  Downloading databricks_sdk-0.57.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.115.13)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (8.7.0)\n",
            "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow)\n",
            "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow)\n",
            "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (2.11.7)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (4.14.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.34.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.4.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.3)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==3.1.1->mlflow) (0.46.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow) (3.23.0)\n",
            "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow)\n",
            "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (2025.6.15)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==3.1.1->mlflow) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.6.1)\n",
            "Downloading mlflow-3.1.1-py3-none-any.whl (24.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.1.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.57.0-py3-none-any.whl (733 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m733.8/733.8 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gunicorn, graphql-core, opentelemetry-api, graphql-relay, docker, opentelemetry-semantic-conventions, graphene, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n",
            "Successfully installed databricks-sdk-0.57.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-3.1.1 mlflow-skinny-3.1.1 opentelemetry-api-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.13)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.91.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: mlflow>=3.1 in /usr/local/lib/python3.11/dist-packages (from mlflow[databricks]>=3.1) (3.1.1)\n",
            "Requirement already satisfied: mlflow-skinny==3.1.1 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (3.1.1)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (3.1.1)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (1.16.2)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (23.0.0)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<21,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (1.15.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (2.0.41)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (8.2.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (3.1.1)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (0.57.0)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (0.115.13)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (1.34.1)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (24.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (2.11.7)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (4.14.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (0.34.3)\n",
            "Collecting azure-storage-file-datalake>12 (from mlflow[databricks]>=3.1)\n",
            "  Downloading azure_storage_file_datalake-12.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: google-cloud-storage>=1.30.0 in /usr/local/lib/python3.11/dist-packages (from mlflow[databricks]>=3.1) (2.19.0)\n",
            "Collecting boto3>1 (from mlflow[databricks]>=3.1)\n",
            "  Downloading boto3-1.38.46-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting botocore (from mlflow[databricks]>=3.1)\n",
            "  Downloading botocore-1.38.46-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting databricks-agents<2.0,>=1.0.0 (from mlflow[databricks]>=3.1)\n",
            "  Downloading databricks_agents-1.1.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow>=3.1->mlflow[databricks]>=3.1) (1.1.3)\n",
            "Collecting azure-core>=1.30.0 (from azure-storage-file-datalake>12->mlflow[databricks]>=3.1)\n",
            "  Downloading azure_core-1.34.0-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-storage-blob>=12.25.1 (from azure-storage-file-datalake>12->mlflow[databricks]>=3.1)\n",
            "  Downloading azure_storage_blob-12.25.1-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-file-datalake>12->mlflow[databricks]>=3.1)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>1->mlflow[databricks]>=3.1)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3>1->mlflow[databricks]>=3.1)\n",
            "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore->mlflow[databricks]>=3.1) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore->mlflow[databricks]>=3.1) (2.4.0)\n",
            "Collecting databricks-connect (from databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1)\n",
            "  Downloading databricks_connect-16.1.6-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting dataclasses-json (from databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1)\n",
            "  Downloading databricks_sdk-0.55.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: jinja2>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (3.1.6)\n",
            "Requirement already satisfied: tenacity>=8.5 in /usr/local/lib/python3.11/dist-packages (from databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (0.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (4.67.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow>=3.1->mlflow[databricks]>=3.1) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow>=3.1->mlflow[databricks]>=3.1) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow>=3.1->mlflow[databricks]>=3.1) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow>=3.1->mlflow[databricks]>=3.1) (3.1.3)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (2.38.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (2.25.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (1.7.1)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow>=3.1->mlflow[databricks]>=3.1) (3.2.6)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow>=3.1->mlflow[databricks]>=3.1) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=3.1->mlflow[databricks]>=3.1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=3.1->mlflow[databricks]>=3.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=3.1->mlflow[databricks]>=3.1) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=3.1->mlflow[databricks]>=3.1) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=3.1->mlflow[databricks]>=3.1) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=3.1->mlflow[databricks]>=3.1) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow>=3.1->mlflow[databricks]>=3.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow>=3.1->mlflow[databricks]>=3.1) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow>=3.1->mlflow[databricks]>=3.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow>=3.1->mlflow[databricks]>=3.1) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow>=3.1->mlflow[databricks]>=3.1) (3.2.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from azure-core>=1.30.0->azure-storage-file-datalake>12->mlflow[databricks]>=3.1) (1.17.0)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.11/dist-packages (from azure-storage-blob>=12.25.1->azure-storage-file-datalake>12->mlflow[databricks]>=3.1) (43.0.3)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (0.46.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (4.0.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (1.70.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (1.26.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (0.55b1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (2025.6.15)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.8.0->databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (2024.11.6)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (0.16.0)\n",
            "Requirement already satisfied: grpcio-status>=1.59.3 in /usr/local/lib/python3.11/dist-packages (from databricks-connect->databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (1.71.0)\n",
            "Requirement already satisfied: grpcio>=1.59.3 in /usr/local/lib/python3.11/dist-packages (from databricks-connect->databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (1.73.0)\n",
            "Collecting numpy<3 (from mlflow>=3.1->mlflow[databricks]>=3.1)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from databricks-connect->databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (0.10.9.7)\n",
            "Requirement already satisfied: setuptools>=68.0.0 in /usr/local/lib/python3.11/dist-packages (from databricks-connect->databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (75.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=2.1.4->azure-storage-blob>=12.25.1->azure-storage-file-datalake>12->mlflow[databricks]>=3.1) (1.17.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (5.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (0.6.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (4.9.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (1.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.25.1->azure-storage-file-datalake>12->mlflow[databricks]>=3.1) (2.22)\n",
            "Downloading azure_storage_file_datalake-12.20.0-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.38.46-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.38.46-py3-none-any.whl (13.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_agents-1.1.0-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.1/189.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.34.0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.4/207.4 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_storage_blob-12.25.1-py3-none-any.whl (406 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.0/407.0 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.55.0-py3-none-any.whl (722 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.9/722.9 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_connect-16.1.6-py2.py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: numpy, mypy-extensions, marshmallow, jmespath, isodate, typing-inspect, botocore, azure-core, s3transfer, dataclasses-json, databricks-sdk, azure-storage-blob, databricks-connect, boto3, azure-storage-file-datalake, databricks-agents\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: databricks-sdk\n",
            "    Found existing installation: databricks-sdk 0.57.0\n",
            "    Uninstalling databricks-sdk-0.57.0:\n",
            "      Successfully uninstalled databricks-sdk-0.57.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed azure-core-1.34.0 azure-storage-blob-12.25.1 azure-storage-file-datalake-12.20.0 boto3-1.38.46 botocore-1.38.46 databricks-agents-1.1.0 databricks-connect-16.1.6 databricks-sdk-0.55.0 dataclasses-json-0.6.7 isodate-0.7.2 jmespath-1.0.1 marshmallow-3.26.1 mypy-extensions-1.1.0 numpy-1.26.4 s3transfer-0.13.0 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "bf82f4cf5109496484a2f477b620362a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "🎬 DSPy Multi-Agent Movie Recommendation System - OPTIMIZATION DEMONSTRATION\n",
        "\n",
        "This notebook demonstrates how to optimize a sophisticated multi-agent system using DSPy.\n",
        "We'll take the existing movie recommendation system and systematically improve it.\n",
        "\n",
        "📊 What You'll See:\n",
        "1. Original multi-agent system baseline\n",
        "2. Training data generation for optimization\n",
        "3. Custom evaluation metrics for movie recommendations\n",
        "4. DSPy optimization applied to individual agents\n",
        "5. Side-by-side comparison of original vs optimized\n",
        "6. Performance analytics and improvement measurement\n",
        "\"\"\"\n",
        "\n",
        "# =============================================================================\n",
        "# 📦 SECTION 1: Environment Setup & Dependencies\n",
        "# =============================================================================\n",
        "\n",
        "# Install required packages\n",
        "!pip install dspy-ai\n",
        "!pip install mlflow\n",
        "!pip install requests\n",
        "!pip install gradio\n",
        "!pip install openai\n",
        "!pip install -U 'mlflow[databricks]>=3.1'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import required libraries\n",
        "import dspy\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List, Dict, Optional, Any, Tuple\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "import mlflow\n",
        "import gradio as gr\n",
        "import random\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "print(\"✅ All packages installed successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBOm1AvzTgye",
        "outputId": "9817f05e-787e-4d79-efc0-baaa0bdeb7fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All packages installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =============================================================================\n",
        "# 🔑 SECTION 2: API Configuration\n",
        "# =============================================================================\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "# Set up your API keys\n",
        "OPENAI_API_KEY = getpass(\"Enter your OpenAI API key: \")\n",
        "TMDB_API_KEY = getpass(\"Enter your TMDB API key (or use demo key): \")\n",
        "\n",
        "# Configure environment\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n",
        "# Configure DSPy\n",
        "llm = dspy.LM(model=\"openai/gpt-4o-mini\", max_tokens=1000)\n",
        "dspy.settings.configure(lm=llm)\n",
        "\n",
        "# Set Databricks authentication details as environment variables\n",
        "DATABRICKS_HOST = \"https://<your_id>.cloud.databricks.com\"\n",
        "DATABRICKS_TOKEN = getpass(\"Enter your Databricks PAT: \")  # Prompt for new PAT\n",
        "\n",
        "os.environ[\"DATABRICKS_HOST\"] = DATABRICKS_HOST\n",
        "os.environ[\"DATABRICKS_TOKEN\"] = DATABRICKS_TOKEN\n",
        "\n",
        "# Explicitly set tracking URI with Databricks format\n",
        "mlflow.set_tracking_uri(\"databricks\")\n",
        "\n",
        "# Set experiment with correct user path (replace with your actual email)\n",
        "mlflow.set_experiment(\"/Users/<email_id>/<experiment_name>\")  # Adjust email\n",
        "\n",
        "# Enable autologging\n",
        "mlflow.autolog()\n",
        "\n",
        "print(\"🔑 API configuration complete!\")\n",
        "# # Configure DSPy\n",
        "# llm = dspy.LM(model=\"openai/gpt-4o-mini\", max_tokens=1000)\n",
        "# dspy.settings.configure(lm=llm)\n",
        "\n",
        "# # Configure MLflow for tracking optimization\n",
        "# mlflow.set_experiment(\"dspy-movie-optimization-demo\")\n",
        "# mlflow.autolog()\n",
        "\n",
        "print(\"🔑 API configuration complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4PzPciSTlhx",
        "outputId": "7fa174d9-4de3-4140-e183-faf1a79d2e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n",
            "Enter your TMDB API key (or use demo key): ··········\n",
            "Enter your Databricks PAT: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/06/30 00:56:09 INFO mlflow.tracking.fluent: Experiment with name '/Users/movcro5@gmail.com/dspy-movie-optimization-demo' does not exist. Creating a new experiment.\n",
            "2025/06/30 00:56:09 INFO mlflow.tracking.fluent: Autologging successfully enabled for dspy.\n",
            "2025/06/30 00:56:10 INFO mlflow.tracking.fluent: Autologging successfully enabled for litellm.\n",
            "2025/06/30 00:56:10 INFO mlflow.tracking.fluent: Autologging successfully enabled for openai.\n",
            "2025/06/30 00:56:10 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2025/06/30 00:56:10 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔑 API configuration complete!\n",
            "🔑 API configuration complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z284rjyEVNqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =============================================================================\n",
        "# 🎬 SECTION 3: Enhanced TMDB Client (From Original System)\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedTMDBClient:\n",
        "    \"\"\"Enhanced TMDB API client with quality filtering\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str):\n",
        "        self.api_key = api_key\n",
        "        self.base_url = \"https://api.themoviedb.org/3\"\n",
        "\n",
        "    def search_movie(self, title: str) -> Dict:\n",
        "        \"\"\"Search for a movie by title\"\"\"\n",
        "        url = f\"{self.base_url}/search/movie\"\n",
        "        params = {\n",
        "            \"api_key\": self.api_key,\n",
        "            \"query\": title,\n",
        "            \"language\": \"en-US\"\n",
        "        }\n",
        "        try:\n",
        "            response = requests.get(url, params=params)\n",
        "            if response.status_code == 200:\n",
        "                results = response.json().get(\"results\", [])\n",
        "                return results[0] if results else {}\n",
        "        except Exception as e:\n",
        "            print(f\"Error searching movie: {e}\")\n",
        "        return {}\n",
        "\n",
        "    def get_movie_details(self, movie_id: int) -> Dict:\n",
        "        \"\"\"Get detailed movie information\"\"\"\n",
        "        url = f\"{self.base_url}/movie/{movie_id}\"\n",
        "        params = {\n",
        "            \"api_key\": self.api_key,\n",
        "            \"append_to_response\": \"credits,keywords,similar,recommendations\"\n",
        "        }\n",
        "        try:\n",
        "            response = requests.get(url, params=params)\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting movie details: {e}\")\n",
        "        return {}\n",
        "\n",
        "    def extract_movie_metadata(self, movie_details: Dict) -> Dict:\n",
        "        \"\"\"Extract structured metadata from TMDB movie details\"\"\"\n",
        "        if not movie_details:\n",
        "            return {}\n",
        "\n",
        "        # Extract genres\n",
        "        genres = [genre[\"name\"].lower() for genre in movie_details.get(\"genres\", [])]\n",
        "        genre_ids = [genre[\"id\"] for genre in movie_details.get(\"genres\", [])]\n",
        "\n",
        "        # Extract cast (top 5)\n",
        "        cast = []\n",
        "        credits = movie_details.get(\"credits\", {})\n",
        "        for actor in credits.get(\"cast\", [])[:5]:\n",
        "            cast.append(actor.get(\"name\", \"\"))\n",
        "\n",
        "        # Extract director\n",
        "        crew = credits.get(\"crew\", [])\n",
        "        director = \"\"\n",
        "        for person in crew:\n",
        "            if person.get(\"job\") == \"Director\":\n",
        "                director = person.get(\"name\", \"\")\n",
        "                break\n",
        "\n",
        "        # Extract themes from keywords\n",
        "        keywords_data = movie_details.get(\"keywords\", {})\n",
        "        themes = [kw[\"name\"].lower() for kw in keywords_data.get(\"keywords\", [])[:10]]\n",
        "\n",
        "        return {\n",
        "            \"title\": movie_details.get(\"title\", \"\"),\n",
        "            \"release_date\": movie_details.get(\"release_date\", \"\"),\n",
        "            \"overview\": movie_details.get(\"overview\", \"\"),\n",
        "            \"genres\": genres,\n",
        "            \"genre_ids\": genre_ids,\n",
        "            \"themes\": themes,\n",
        "            \"director\": director,\n",
        "            \"cast\": cast,\n",
        "            \"runtime\": movie_details.get(\"runtime\", 0),\n",
        "            \"vote_average\": movie_details.get(\"vote_average\", 0),\n",
        "            \"tmdb_id\": movie_details.get(\"id\", 0)\n",
        "        }\n",
        "\n",
        "    def get_comprehensive_movie_data(self, title: str) -> Dict:\n",
        "        \"\"\"Get comprehensive movie data for a title\"\"\"\n",
        "        search_result = self.search_movie(title)\n",
        "        if not search_result:\n",
        "            return {\"error\": f\"Movie '{title}' not found\"}\n",
        "\n",
        "        movie_id = search_result.get(\"id\")\n",
        "        details = self.get_movie_details(movie_id)\n",
        "        if not details:\n",
        "            return {\"error\": f\"Could not retrieve details for '{title}'\"}\n",
        "\n",
        "        metadata = self.extract_movie_metadata(details)\n",
        "\n",
        "        # Get recommendations\n",
        "        similar_movies = [movie[\"title\"] for movie in details.get(\"similar\", {}).get(\"results\", [])[:5]]\n",
        "        recommendations = [movie[\"title\"] for movie in details.get(\"recommendations\", {}).get(\"results\", [])[:5]]\n",
        "\n",
        "        metadata[\"similar_movies\"] = similar_movies\n",
        "        metadata[\"recommended_movies\"] = recommendations\n",
        "\n",
        "        return metadata\n",
        "\n",
        "# Initialize TMDB client\n",
        "tmdb = EnhancedTMDBClient(TMDB_API_KEY)\n",
        "print(\"🎬 TMDB client initialized!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja10oxiATpq7",
        "outputId": "da45241c-d6e4-425e-b549-c71f6c893897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎬 TMDB client initialized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =============================================================================\n",
        "# 🛠️ SECTION 4: Original Agent Tools\n",
        "# =============================================================================\n",
        "\n",
        "def movie_metadata_lookup_tool(movie_title: str) -> str:\n",
        "    \"\"\"Tool for looking up movie metadata from TMDB API\"\"\"\n",
        "    try:\n",
        "        metadata = tmdb.get_comprehensive_movie_data(movie_title)\n",
        "        if \"error\" in metadata:\n",
        "            return f\"Error: {metadata['error']}\"\n",
        "        return json.dumps(metadata, indent=2)\n",
        "    except Exception as e:\n",
        "        return f\"Error retrieving movie data: {str(e)}\"\n",
        "\n",
        "def movie_hypothesis_generator_tool(movie_title: str, metadata: str) -> str:\n",
        "    \"\"\"Tool for generating hypotheses about why user loved a movie\"\"\"\n",
        "    class HypothesisGenerator(dspy.Signature):\n",
        "        movie_title = dspy.InputField(desc=\"The movie the user loved\")\n",
        "        movie_metadata = dspy.InputField(desc=\"Real movie metadata from TMDB\")\n",
        "        hypotheses = dspy.OutputField(desc=\"Three specific hypotheses about what drew them to the movie\")\n",
        "\n",
        "    generator = dspy.ChainOfThought(HypothesisGenerator)\n",
        "    result = generator(movie_title=movie_title, movie_metadata=metadata)\n",
        "    return result.hypotheses\n",
        "\n",
        "def recommendation_generator_tool(movie_title: str, user_hypothesis: str) -> str:\n",
        "    \"\"\"Tool for generating movie recommendations based on user preferences\"\"\"\n",
        "    class RecommendationGenerator(dspy.Signature):\n",
        "        original_movie = dspy.InputField(desc=\"Movie the user loved\")\n",
        "        user_preference_hypothesis = dspy.InputField(desc=\"What the user likely enjoyed about the movie\")\n",
        "        recommendations = dspy.OutputField(desc=\"Three movie recommendations with brief explanations\")\n",
        "\n",
        "    generator = dspy.ChainOfThought(RecommendationGenerator)\n",
        "    result = generator(original_movie=movie_title, user_preference_hypothesis=user_hypothesis)\n",
        "    return result.recommendations\n",
        "\n",
        "def narrative_constructor_tool(movie_title: str, reason: str) -> str:\n",
        "    \"\"\"Tool for constructing compelling narrative explanations\"\"\"\n",
        "    class NarrativeConstructor(dspy.Signature):\n",
        "        recommended_movie = dspy.InputField(desc=\"The movie being recommended\")\n",
        "        connection_reason = dspy.InputField(desc=\"Why this movie connects to user's taste\")\n",
        "        narrative_explanation = dspy.OutputField(desc=\"A compelling story-driven explanation\")\n",
        "\n",
        "    constructor = dspy.ChainOfThought(NarrativeConstructor)\n",
        "    result = constructor(recommended_movie=movie_title, connection_reason=reason)\n",
        "    return result.narrative_explanation\n",
        "\n",
        "print(\"🛠️ Original agent tools ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoS2x4LyTunC",
        "outputId": "617c780e-16e7-4097-f467-f3ecbf825ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🛠️ Original agent tools ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =============================================================================\n",
        "# 🤖 SECTION 5: Original Multi-Agent System\n",
        "# =============================================================================\n",
        "\n",
        "class MovieAnalysisSignature(dspy.Signature):\n",
        "    \"\"\"Analyze a movie to understand user preferences and generate recommendations.\"\"\"\n",
        "    movie_title: str = dspy.InputField()\n",
        "    analysis_result: str = dspy.OutputField(desc=\"Complete analysis with movie recommendations\")\n",
        "\n",
        "class NarrativeSignature(dspy.Signature):\n",
        "    \"\"\"Create compelling narrative explanations for movie recommendations.\"\"\"\n",
        "    movie_recommendations: str = dspy.InputField()\n",
        "    narrative_explanations: str = dspy.OutputField(desc=\"Compelling narrative explanations\")\n",
        "\n",
        "class OrchestratorSignature(dspy.Signature):\n",
        "    \"\"\"Master orchestrator coordinating movie analysis and narrative agents.\"\"\"\n",
        "    user_input: str = dspy.InputField()\n",
        "    final_recommendations: str = dspy.OutputField(desc=\"Final movie recommendations with narratives\")\n",
        "\n",
        "# Create original agents\n",
        "original_movie_agent = dspy.ReAct(\n",
        "    MovieAnalysisSignature,\n",
        "    tools=[movie_metadata_lookup_tool, movie_hypothesis_generator_tool, recommendation_generator_tool]\n",
        ")\n",
        "\n",
        "original_narrative_agent = dspy.ReAct(\n",
        "    NarrativeSignature,\n",
        "    tools=[narrative_constructor_tool]\n",
        ")\n",
        "\n",
        "# Tools for orchestrator\n",
        "def call_movie_analysis_agent(movie_title: str) -> str:\n",
        "    \"\"\"Call the Movie Analysis Agent\"\"\"\n",
        "    result = original_movie_agent(movie_title=movie_title)\n",
        "    return result.analysis_result\n",
        "\n",
        "def call_narrative_agent(recommendations: str) -> str:\n",
        "    \"\"\"Call the Narrative Agent\"\"\"\n",
        "    result = original_narrative_agent(movie_recommendations=recommendations)\n",
        "    return result.narrative_explanations\n",
        "\n",
        "# Original orchestrator\n",
        "original_orchestrator = dspy.ReAct(\n",
        "    OrchestratorSignature,\n",
        "    tools=[call_movie_analysis_agent, call_narrative_agent, movie_metadata_lookup_tool]\n",
        ")\n",
        "\n",
        "print(\"🤖 Original multi-agent system ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i9VviukTzZ2",
        "outputId": "3135ee12-72f4-4035-f2eb-4fc3cbdb472e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 Original multi-agent system ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =============================================================================\n",
        "# 📊 SECTION 6: Training Dataset Generation\n",
        "# =============================================================================\n",
        "\n",
        "def generate_training_dataset(size: int = 60) -> List[dspy.Example]:\n",
        "    \"\"\"Generate training dataset for optimization\"\"\"\n",
        "\n",
        "    # Curated examples of good movie taste patterns\n",
        "    training_patterns = [\n",
        "        {\n",
        "            \"input_movie\": \"Inception\",\n",
        "            \"expected_recommendations\": [\"Memento\", \"Shutter Island\", \"The Prestige\"],\n",
        "            \"expected_themes\": [\"mind-bending\", \"psychological\", \"complex narrative\"],\n",
        "            \"quality_narrative\": \"If you loved Inception's layered reality and complex storytelling...\"\n",
        "        },\n",
        "        {\n",
        "            \"input_movie\": \"The Matrix\",\n",
        "            \"expected_recommendations\": [\"Blade Runner 2049\", \"Ex Machina\", \"Ghost in the Shell\"],\n",
        "            \"expected_themes\": [\"artificial intelligence\", \"reality questioning\", \"cyberpunk\"],\n",
        "            \"quality_narrative\": \"Like The Matrix, these films explore the nature of reality...\"\n",
        "        },\n",
        "        {\n",
        "            \"input_movie\": \"Pulp Fiction\",\n",
        "            \"expected_recommendations\": [\"Reservoir Dogs\", \"Kill Bill\", \"Snatch\"],\n",
        "            \"expected_themes\": [\"non-linear narrative\", \"crime\", \"dark humor\"],\n",
        "            \"quality_narrative\": \"These films share Tarantino's distinctive storytelling style...\"\n",
        "        },\n",
        "        {\n",
        "            \"input_movie\": \"Interstellar\",\n",
        "            \"expected_recommendations\": [\"Arrival\", \"Contact\", \"2001: A Space Odyssey\"],\n",
        "            \"expected_themes\": [\"space exploration\", \"scientific concepts\", \"emotional depth\"],\n",
        "            \"quality_narrative\": \"Like Interstellar, these films blend hard science with human emotion...\"\n",
        "        },\n",
        "        {\n",
        "            \"input_movie\": \"The Dark Knight\",\n",
        "            \"expected_recommendations\": [\"Heat\", \"The Departed\", \"Zodiac\"],\n",
        "            \"expected_themes\": [\"crime thriller\", \"moral complexity\", \"psychological depth\"],\n",
        "            \"quality_narrative\": \"These films share The Dark Knight's serious approach to crime...\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Generate more patterns programmatically\n",
        "    additional_patterns = []\n",
        "    movie_clusters = {\n",
        "        \"horror\": [\"The Exorcist\", \"Hereditary\", \"The Babadook\", \"Get Out\"],\n",
        "        \"comedy\": [\"The Grand Budapest Hotel\", \"In Bruges\", \"Kiss Kiss Bang Bang\", \"The Nice Guys\"],\n",
        "        \"drama\": [\"There Will Be Blood\", \"No Country for Old Men\", \"Moonlight\", \"Parasite\"],\n",
        "        \"action\": [\"Mad Max: Fury Road\", \"John Wick\", \"The Raid\", \"Baby Driver\"],\n",
        "        \"sci-fi\": [\"Blade Runner\", \"Alien\", \"Dune\", \"Her\"]\n",
        "    }\n",
        "\n",
        "    for genre, movies in movie_clusters.items():\n",
        "        for i, movie in enumerate(movies):\n",
        "            recommendations = [m for j, m in enumerate(movies) if j != i][:3]\n",
        "            additional_patterns.append({\n",
        "                \"input_movie\": movie,\n",
        "                \"expected_recommendations\": recommendations,\n",
        "                \"expected_themes\": [genre, \"quality filmmaking\", \"genre excellence\"],\n",
        "                \"quality_narrative\": f\"As a fan of {movie}, you'll appreciate these {genre} masterpieces...\"\n",
        "            })\n",
        "\n",
        "    all_patterns = training_patterns + additional_patterns[:size-len(training_patterns)]\n",
        "\n",
        "    # Convert to DSPy examples\n",
        "    training_examples = []\n",
        "    for pattern in all_patterns:\n",
        "        # Create the input as a user query\n",
        "        user_query = f\"I loved the movie {pattern['input_movie']}. Can you recommend similar movies?\"\n",
        "\n",
        "        # Create expected output format\n",
        "        expected_output = f\"\"\"\n",
        "**Recommendations for {pattern['input_movie']} lovers:**\n",
        "\n",
        "1. **{pattern['expected_recommendations'][0]}**: {pattern['quality_narrative']}\n",
        "2. **{pattern['expected_recommendations'][1]}**: Connected through {', '.join(pattern['expected_themes'][:2])}\n",
        "3. **{pattern['expected_recommendations'][2]}**: Shares the same {pattern['expected_themes'][0]} appeal\n",
        "\n",
        "**Analysis**: Based on your love for {pattern['input_movie']}, I identified these key themes: {', '.join(pattern['expected_themes'])}. These recommendations match those preferences perfectly.\n",
        "\"\"\"\n",
        "\n",
        "        example = dspy.Example(\n",
        "            user_input=user_query,\n",
        "            final_recommendations=expected_output,\n",
        "            input_movie=pattern['input_movie'],\n",
        "            expected_themes=pattern['expected_themes'],\n",
        "            expected_recs=pattern['expected_recommendations']\n",
        "        ).with_inputs(\"user_input\")\n",
        "\n",
        "        training_examples.append(example)\n",
        "\n",
        "    return training_examples\n",
        "\n",
        "# Generate training and validation sets\n",
        "print(\"📊 Generating training dataset...\")\n",
        "full_dataset = generate_training_dataset(80)\n",
        "random.shuffle(full_dataset)\n",
        "\n",
        "# Split into train/val\n",
        "train_size = int(0.7 * len(full_dataset))\n",
        "trainset = full_dataset[:train_size]\n",
        "valset = full_dataset[train_size:]\n",
        "\n",
        "print(f\"✅ Dataset created: {len(trainset)} training examples, {len(valset)} validation examples\")\n",
        "print(f\"📋 Sample training example:\")\n",
        "print(f\"Input: {trainset[0].user_input}\")\n",
        "print(f\"Expected output (first 200 chars): {trainset[0].final_recommendations[:200]}...\")\n"
      ],
      "metadata": {
        "id": "sgM9p34ET4bK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =============================================================================\n",
        "# 📏 SECTION 7: Custom Evaluation Metrics\n",
        "# =============================================================================\n",
        "\n",
        "def extract_recommended_movies(response: str) -> List[str]:\n",
        "    \"\"\"Extract movie titles from agent response\"\"\"\n",
        "    # Look for patterns like \"1. **Movie Title**\" or \"**Movie Title**\"\n",
        "    patterns = [\n",
        "        r'\\d+\\.\\s*\\*\\*([^*]+)\\*\\*',  # \"1. **Movie Title**\"\n",
        "        r'\\*\\*([^*]+)\\*\\*(?=:)',      # \"**Movie Title**:\"\n",
        "        r'recommend[^:]*:\\s*([^,\\n]+)',  # \"I recommend: Movie Title\"\n",
        "    ]\n",
        "\n",
        "    movies = []\n",
        "    for pattern in patterns:\n",
        "        matches = re.findall(pattern, response, re.IGNORECASE)\n",
        "        for match in matches:\n",
        "            movie = match.strip()\n",
        "            if len(movie) > 2 and movie not in movies:\n",
        "                movies.append(movie)\n",
        "\n",
        "    return movies[:3]  # Return top 3\n",
        "\n",
        "def recommendation_relevance_metric(example, pred, trace=None) -> float:\n",
        "    \"\"\"\n",
        "    Measure how relevant the recommendations are to the expected movies/themes\n",
        "    Returns score between 0.0 and 1.0\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Extract predicted movies\n",
        "        predicted_movies = extract_recommended_movies(pred.final_recommendations)\n",
        "        expected_movies = example.expected_recs\n",
        "        expected_themes = set(theme.lower() for theme in example.expected_themes)\n",
        "\n",
        "        if not predicted_movies:\n",
        "            return 0.0\n",
        "\n",
        "        # Score 1: Direct movie matches (40% weight)\n",
        "        movie_score = 0.0\n",
        "        for pred_movie in predicted_movies:\n",
        "            for exp_movie in expected_movies:\n",
        "                # Check for exact or partial matches\n",
        "                if pred_movie.lower() in exp_movie.lower() or exp_movie.lower() in pred_movie.lower():\n",
        "                    movie_score += 1.0\n",
        "                elif any(word in exp_movie.lower().split() for word in pred_movie.lower().split() if len(word) > 3):\n",
        "                    movie_score += 0.5\n",
        "\n",
        "        movie_score = min(movie_score, len(expected_movies)) / len(expected_movies)\n",
        "\n",
        "        # Score 2: Theme relevance (40% weight)\n",
        "        response_lower = pred.final_recommendations.lower()\n",
        "        theme_matches = sum(1 for theme in expected_themes if theme in response_lower)\n",
        "        theme_score = theme_matches / len(expected_themes)\n",
        "\n",
        "        # Score 3: Response quality (20% weight)\n",
        "        quality_indicators = [\n",
        "            \"recommendation\" in response_lower,\n",
        "            \"similar\" in response_lower,\n",
        "            \"love\" in response_lower or \"enjoy\" in response_lower,\n",
        "            len(pred.final_recommendations) > 200,  # Substantial response\n",
        "            \"**\" in pred.final_recommendations  # Formatted properly\n",
        "        ]\n",
        "        quality_score = sum(quality_indicators) / len(quality_indicators)\n",
        "\n",
        "        # Combined score\n",
        "        total_score = (movie_score * 0.4) + (theme_score * 0.4) + (quality_score * 0.2)\n",
        "        return min(total_score, 1.0)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in relevance metric: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "def narrative_quality_metric(example, pred, trace=None) -> float:\n",
        "    \"\"\"\n",
        "    Measure the quality of narrative explanations\n",
        "    Returns score between 0.0 and 1.0\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = pred.final_recommendations\n",
        "\n",
        "        # Quality indicators\n",
        "        indicators = {\n",
        "            \"compelling_language\": any(word in response.lower() for word in [\n",
        "                \"captivating\", \"compelling\", \"brilliant\", \"masterpiece\", \"extraordinary\",\n",
        "                \"remarkable\", \"stunning\", \"powerful\", \"moving\", \"unforgettable\"\n",
        "            ]),\n",
        "            \"connection_explanation\": any(phrase in response.lower() for phrase in [\n",
        "                \"like\", \"similar to\", \"if you loved\", \"shares\", \"connects\",\n",
        "                \"reminiscent of\", \"echoes\", \"parallels\"\n",
        "            ]),\n",
        "            \"specific_details\": any(word in response.lower() for word in [\n",
        "                \"director\", \"cinematography\", \"themes\", \"style\", \"genre\",\n",
        "                \"plot\", \"character\", \"atmosphere\"\n",
        "            ]),\n",
        "            \"emotional_appeal\": any(word in response.lower() for word in [\n",
        "                \"feel\", \"experience\", \"journey\", \"emotion\", \"heart\",\n",
        "                \"soul\", \"passion\", \"depth\"\n",
        "            ]),\n",
        "            \"structure\": \"**\" in response and len(response.split(\"**\")) >= 4,\n",
        "            \"length\": 300 <= len(response) <= 1500,  # Optimal length\n",
        "            \"coherence\": response.count(\".\") >= 5,  # Multiple sentences\n",
        "        }\n",
        "\n",
        "        score = sum(indicators.values()) / len(indicators)\n",
        "        return score\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in narrative quality metric: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "def combined_movie_recommendation_metric(example, pred, trace=None) -> float:\n",
        "    \"\"\"\n",
        "    Combined metric weighing both relevance and narrative quality\n",
        "    \"\"\"\n",
        "    relevance = recommendation_relevance_metric(example, pred, trace)\n",
        "    narrative = narrative_quality_metric(example, pred, trace)\n",
        "\n",
        "    # Weight relevance slightly higher than narrative\n",
        "    combined = (relevance * 0.6) + (narrative * 0.4)\n",
        "    return combined\n",
        "\n",
        "print(\"📏 Custom evaluation metrics ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B34oZlrT8N5",
        "outputId": "01cf36d0-6b64-471c-dafc-ad75bc850f87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📏 Custom evaluation metrics ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =============================================================================\n",
        "# 🎯 SECTION 8: DSPy Optimization Process\n",
        "# =============================================================================\n",
        "\n",
        "def run_optimization():\n",
        "    \"\"\"Run the complete optimization process\"\"\"\n",
        "\n",
        "    print(\"🎯 Starting DSPy optimization process...\")\n",
        "\n",
        "    # Set up the optimizer\n",
        "    optimizer = dspy.MIPROv2(\n",
        "        metric=combined_movie_recommendation_metric,\n",
        "        auto=\"light\",  # Use light mode for faster optimization\n",
        "        num_threads=4,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # Create evaluator for baseline measurement\n",
        "    evaluator = dspy.Evaluate(\n",
        "        metric=combined_movie_recommendation_metric,\n",
        "        devset=valset[:10],  # Use smaller set for demo\n",
        "        display_table=True,\n",
        "        display_progress=True\n",
        "    )\n",
        "\n",
        "    print(\"📊 Measuring baseline performance...\")\n",
        "    with mlflow.start_run(run_name=\"baseline_measurement\"):\n",
        "        baseline_score = evaluator(original_orchestrator)\n",
        "        mlflow.log_metric(\"baseline_score\", baseline_score)\n",
        "        print(f\"🔍 Baseline Score: {baseline_score:.3f}\")\n",
        "\n",
        "    print(\"🚀 Running optimization...\")\n",
        "    with mlflow.start_run(run_name=\"optimization_process\"):\n",
        "        optimized_orchestrator = optimizer.compile(\n",
        "            original_orchestrator,\n",
        "            trainset=trainset[:30],  # Use subset for demo\n",
        "            valset=valset[:10],\n",
        "            requires_permission_to_run=False\n",
        "        )\n",
        "\n",
        "        print(\"📊 Measuring optimized performance...\")\n",
        "        optimized_score = evaluator(optimized_orchestrator)\n",
        "        mlflow.log_metric(\"optimized_score\", optimized_score)\n",
        "        mlflow.log_metric(\"improvement\", optimized_score - baseline_score)\n",
        "\n",
        "        print(f\"🎉 Optimization Results:\")\n",
        "        print(f\"   Baseline Score: {baseline_score:.3f}\")\n",
        "        print(f\"   Optimized Score: {optimized_score:.3f}\")\n",
        "        print(f\"   Improvement: {optimized_score - baseline_score:.3f} ({((optimized_score - baseline_score) / baseline_score * 100):.1f}%)\")\n",
        "\n",
        "    return optimized_orchestrator, baseline_score, optimized_score\n",
        "\n",
        "# Run the optimization\n",
        "print(\"⚡ Running optimization process...\")\n",
        "optimized_orchestrator, baseline_score, optimized_score = run_optimization()\n",
        "print(\"✅ Optimization complete!\")\n"
      ],
      "metadata": {
        "id": "Dxeb4jpkT_rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =============================================================================\n",
        "# 🚀 SECTION 9: Comparison Interface\n",
        "# =============================================================================\n",
        "\n",
        "def create_comparison_interface():\n",
        "    \"\"\"Create interface showing original vs optimized system\"\"\"\n",
        "\n",
        "    def compare_systems(movie_title: str):\n",
        "        \"\"\"Compare original vs optimized recommendations\"\"\"\n",
        "        if not movie_title.strip():\n",
        "            return \"Please enter a movie title!\", \"\", \"\", \"\"\n",
        "\n",
        "        user_query = f\"I loved the movie {movie_title}. Can you recommend similar movies?\"\n",
        "\n",
        "        try:\n",
        "            # Get original system response\n",
        "            print(f\"🤖 Getting original system response for '{movie_title}'...\")\n",
        "            original_result = original_orchestrator(user_input=user_query)\n",
        "            original_response = original_result.final_recommendations\n",
        "\n",
        "            # Get optimized system response\n",
        "            print(f\"🎯 Getting optimized system response for '{movie_title}'...\")\n",
        "            optimized_result = optimized_orchestrator(user_input=user_query)\n",
        "            optimized_response = optimized_result.final_recommendations\n",
        "\n",
        "            # Analyze improvements\n",
        "            improvements = analyze_improvements(original_response, optimized_response, movie_title)\n",
        "\n",
        "            # Performance comparison\n",
        "            performance_comparison = f\"\"\"\n",
        "**🔍 Performance Analysis:**\n",
        "\n",
        "**Baseline System Score**: {baseline_score:.3f}\n",
        "**Optimized System Score**: {optimized_score:.3f}\n",
        "**Improvement**: {optimized_score - baseline_score:.3f} ({((optimized_score - baseline_score) / baseline_score * 100):.1f}%)\n",
        "\n",
        "**Key Optimization Areas**:\n",
        "• Recommendation Relevance: Better theme matching\n",
        "• Narrative Quality: More compelling explanations\n",
        "• Agent Coordination: Improved multi-agent workflow\n",
        "• TMDB Integration: Enhanced real data usage\n",
        "\n",
        "**Training Data**: {len(trainset)} examples\n",
        "**Validation Data**: {len(valset)} examples\n",
        "**Optimization Method**: DSPy MIPROv2 with custom metrics\n",
        "\"\"\"\n",
        "\n",
        "            return original_response, optimized_response, improvements, performance_comparison\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error comparing systems: {str(e)}\"\n",
        "            return error_msg, \"\", \"\", \"\"\n",
        "\n",
        "    def analyze_improvements(original: str, optimized: str, movie: str) -> str:\n",
        "        \"\"\"Analyze specific improvements between versions\"\"\"\n",
        "\n",
        "        orig_movies = extract_recommended_movies(original)\n",
        "        opt_movies = extract_recommended_movies(optimized)\n",
        "\n",
        "        analysis = f\"\"\"\n",
        "**🎯 Improvement Analysis for \"{movie}\":**\n",
        "\n",
        "**Original Recommendations**: {', '.join(orig_movies) if orig_movies else 'None extracted'}\n",
        "**Optimized Recommendations**: {', '.join(opt_movies) if opt_movies else 'None extracted'}\n",
        "\n",
        "**Length Comparison**:\n",
        "• Original Response: {len(original)} characters\n",
        "• Optimized Response: {len(optimized)} characters\n",
        "\n",
        "**Quality Indicators**:\n",
        "• **Formatting**: {'✅' if '**' in optimized else '❌'} Better formatting\n",
        "• **Detail Level**: {'✅' if len(optimized) > len(original) else '❌'} More detailed explanations\n",
        "• **Movie Count**: {'✅' if len(opt_movies) >= len(orig_movies) else '❌'} Adequate recommendations\n",
        "• **Narrative Elements**: {'✅' if any(word in optimized.lower() for word in ['love', 'enjoy', 'similar', 'like']) else '❌'} Compelling language\n",
        "\n",
        "**Optimization Impact**:\n",
        "The optimized system was trained on {len(trainset)} examples to improve:\n",
        "1. **Thematic Relevance**: Better matching of movie themes and genres\n",
        "2. **Narrative Coherence**: More compelling \"why you'll love this\" explanations\n",
        "3. **Response Structure**: Clearer formatting and organization\n",
        "4. **Agent Coordination**: Improved multi-agent collaboration\n",
        "\n",
        "**Training Focus**: The optimization specifically targeted recommendation accuracy and narrative quality using custom evaluation metrics.\n",
        "\"\"\"\n",
        "        return analysis\n",
        "\n",
        "    # Create Gradio interface\n",
        "    interface = gr.Interface(\n",
        "        fn=compare_systems,\n",
        "        inputs=[\n",
        "            gr.Textbox(\n",
        "                label=\"🎬 Movie Title\",\n",
        "                placeholder=\"Try: Inception, The Matrix, Pulp Fiction, Interstellar\",\n",
        "                lines=1\n",
        "            )\n",
        "        ],\n",
        "        outputs=[\n",
        "            gr.Textbox(label=\"🤖 Original System Response\", lines=15),\n",
        "            gr.Textbox(label=\"🎯 Optimized System Response\", lines=15),\n",
        "            gr.Textbox(label=\"📊 Improvement Analysis\", lines=12),\n",
        "            gr.Textbox(label=\"⚖️ Performance Metrics\", lines=10)\n",
        "        ],\n",
        "        title=\"🎯 DSPy Multi-Agent Optimization: Before vs After\",\n",
        "        description=f\"\"\"\n",
        "        **Real DSPy Optimization Demonstration**\n",
        "\n",
        "        🎯 **Optimization Results**: {optimized_score:.3f} vs {baseline_score:.3f} baseline ({((optimized_score - baseline_score) / baseline_score * 100):.1f}% improvement)\n",
        "\n",
        "        📊 **What Was Optimized**:\n",
        "        • **Training Data**: {len(trainset)} curated movie recommendation examples\n",
        "        • **Evaluation Metrics**: Custom metrics for recommendation relevance + narrative quality\n",
        "        • **Optimization Method**: DSPy MIPROv2 with multi-agent coordination\n",
        "        • **Focus Areas**: Thematic accuracy, compelling narratives, better agent collaboration\n",
        "\n",
        "        🎬 **Try It**: Enter any movie title to see how optimization improved the recommendations!\n",
        "        \"\"\",\n",
        "        examples=[\n",
        "            [\"Inception\"],\n",
        "            [\"The Matrix\"],\n",
        "            [\"Pulp Fiction\"],\n",
        "            [\"Interstellar\"],\n",
        "            [\"The Dark Knight\"]\n",
        "        ],\n",
        "        theme=gr.themes.Soft()\n",
        "    )\n",
        "\n",
        "    return interface\n",
        "\n",
        "# Create and launch the comparison interface\n",
        "comparison_demo = create_comparison_interface()\n",
        "\n",
        "print(\"🚀 Comparison interface ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR4BO0ikUDXd",
        "outputId": "c2df6e3a-692e-4fba-a5a6-b888c7f9eab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Comparison interface ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =============================================================================\n",
        "# 🎉 SECTION 10: Results Summary and Next Steps\n",
        "# =============================================================================\n",
        "\n",
        "def display_optimization_summary():\n",
        "    \"\"\"Display comprehensive summary of optimization results\"\"\"\n",
        "\n",
        "    summary = f\"\"\"\n",
        "# 🎯 DSPy Multi-Agent Optimization - Complete Results\n",
        "\n",
        "## 📊 Performance Improvement\n",
        "- **Baseline Score**: {baseline_score:.3f}\n",
        "- **Optimized Score**: {optimized_score:.3f}\n",
        "- **Improvement**: {optimized_score - baseline_score:.3f} ({((optimized_score - baseline_score) / baseline_score * 100):.1f}%)\n",
        "\n",
        "## 🎬 System Architecture\n",
        "**Original Multi-Agent Components**:\n",
        "- Movie Analysis Agent (hypothesis generation)\n",
        "- Narrative Agent (story construction)\n",
        "- Master Orchestrator (agent coordination)\n",
        "- TMDB Integration (real movie data)\n",
        "\n",
        "**Optimization Enhancements**:\n",
        "- Custom evaluation metrics for movie recommendations\n",
        "- Training dataset with {len(trainset)} curated examples\n",
        "- DSPy MIPROv2 optimizer with light configuration\n",
        "- Focus on recommendation relevance + narrative quality\n",
        "\n",
        "## 🎯 Key Improvements Demonstrated\n",
        "1. **Better Recommendations**: More thematically relevant movie suggestions\n",
        "2. **Enhanced Narratives**: More compelling \"why you'll love this\" explanations\n",
        "3. **Improved Structure**: Better formatting and organization\n",
        "4. **Smarter Coordination**: More efficient multi-agent collaboration\n",
        "\n",
        "## 🚀 Technical Implementation\n",
        "- **Framework**: DSPy ReAct agents with tool usage\n",
        "- **Data Source**: TMDB API for real movie metadata\n",
        "- **Optimization**: MIPROv2 with custom movie recommendation metrics\n",
        "- **Evaluation**: Combined relevance + narrative quality scoring\n",
        "- **Tracking**: MLflow for experiment management\n",
        "\n",
        "## 🎬 Next Steps for Production\n",
        "1. **Expand Training Data**: Include more diverse movie preferences\n",
        "2. **Advanced Metrics**: Add user satisfaction and click-through rate simulation\n",
        "3. **A/B Testing**: Deploy optimized system alongside baseline for comparison\n",
        "4. **Continuous Learning**: Regular retraining with new user preference data\n",
        "5. **Domain Expansion**: Apply same optimization approach to TV shows, books, music\n",
        "\n",
        "## 🔧 Code Availability\n",
        "This complete optimization pipeline demonstrates:\n",
        "- Real multi-agent system optimization using DSPy\n",
        "- Custom evaluation metrics for domain-specific tasks\n",
        "- Training data generation for recommendation systems\n",
        "- Before/after comparison interface\n",
        "- Production-ready optimization workflow\n",
        "\n",
        "🎉 **Ready to scale and deploy!**\n",
        "\"\"\"\n",
        "\n",
        "    print(summary)\n",
        "    return summary\n",
        "\n",
        "# Display final summary\n",
        "optimization_summary = display_optimization_summary()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🎉 DSPy MULTI-AGENT OPTIMIZATION DEMONSTRATION COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"🎯 Achieved {((optimized_score - baseline_score) / baseline_score * 100):.1f}% improvement in movie recommendation quality\")\n",
        "print(\"🚀 Launch the Gradio interface below to try the optimized system!\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Launch the comparison interface\n",
        "comparison_demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "AtaIYR1DUFha"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
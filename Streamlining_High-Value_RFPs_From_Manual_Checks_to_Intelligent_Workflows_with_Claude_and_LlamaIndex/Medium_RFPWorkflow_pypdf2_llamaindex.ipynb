{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#derived from Nov8_RFPWorkflow_pypdf2_llamaindex.ipynb\n",
        "pip install PyPDF2 llama-index-vector-stores-chroma nest-asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIT-c6TZvuCA",
        "outputId": "65f62a54-f927-488f-bebf-2144e225039c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: llama-index-vector-stores-chroma in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: chromadb>=0.5.17 in /usr/local/lib/python3.10/dist-packages (from llama-index-vector-stores-chroma) (0.5.18)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-vector-stores-chroma) (0.11.22)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.9.2)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.115.4)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.32.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.20.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.28.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.28.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.49b1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.28.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.66.6)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.64.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.2.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.12.5)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (31.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (8.5.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.10.10)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (13.9.3)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (2024.10.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (3.9.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (10.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (0.8.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (4.0.3)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (24.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.0.2)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.41.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.2.3)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (2024.9.11)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.28.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.65.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.28.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.28.1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.28.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.49b1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.49b1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.49b1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.49b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.49b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.49b1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.49b1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.49b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (3.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.24.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (1.0.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.24.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (14.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (3.23.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.16.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.20.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.1.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (0.2.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-llms-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dlejKfK9E_fK",
        "outputId": "76018921-5aa4-4606-aee4-b5868f026afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index-llms-openai in /usr/local/lib/python3.10/dist-packages (0.2.16)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.7 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-openai) (0.11.22)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-openai) (1.52.2)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.16.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.23.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (24.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPw-kfIAFWNz",
        "outputId": "a77fb52a-f500-4d2c-9011-74cc74eab3b2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZoeIggovpYh"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "import PyPDF2\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel\n",
        "import logging\n",
        "import json\n",
        "import os\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import urllib.parse\n",
        "from llama_index.core.workflow import (\n",
        "    Event,\n",
        "    StartEvent,\n",
        "    StopEvent,\n",
        "    Context,\n",
        "    Workflow,\n",
        "    step,\n",
        ")\n",
        "from llama_index.core import Document, VectorStoreIndex, SummaryIndex\n",
        "from llama_index.core.schema import NodeWithScore\n",
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "from llama_index.core.agent import FunctionCallingAgentWorker\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.vector_stores import (\n",
        "    MetadataFilter,\n",
        "    MetadataFilters,\n",
        "    FilterOperator,\n",
        ")\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Set up logging\n",
        "_logger = logging.getLogger(__name__)\n",
        "_logger.setLevel(logging.INFO)\n",
        "\n",
        "AGENT_SYSTEM_PROMPT = \"\"\"\\\n",
        "You are a senior research agent tasked with filling out a specific form key/question with the appropriate value, given a bank of context.\n",
        "You must approach each question with the following priorities:\n",
        "1. Competitive Differentiation: Always highlight unique strengths, market position, and key differentiators\n",
        "2. Quantifiable Evidence: Use specific metrics, case studies, and achievements to support all claims\n",
        "3. Value Proposition: Emphasize ROI, cost savings, and tangible benefits\n",
        "4. Recent Experience: Prioritize recent and relevant experience, especially in the target industry\n",
        "\n",
        "For each question:\n",
        "1. Think step-by-step and use the existing tools to find relevant information\n",
        "2. MUST use at least one tool to answer each question\n",
        "3. When using multiple sources, synthesize information to present the strongest possible response\n",
        "4. Always include:\n",
        "   - Specific metrics and achievements\n",
        "   - Relevant case studies or examples\n",
        "   - Competitive advantages\n",
        "   - Value proposition elements\n",
        "5. Only after exhausting all tools should you reason from first principles\n",
        "6. When forced to reason without direct evidence, maintain alignment with known company strengths and market position\n",
        "7. Never say 'I don't know' - provide a strategic response based on available information\n",
        "\n",
        "Remember: Each answer contributes to the overall win probability. Make every response compelling and evidence-based.\n",
        "\"\"\"\n",
        "\n",
        "EXTRACT_KEYS_PROMPT = \"\"\"\\\n",
        "You are a strategic bid manager analyzing an RFP document to generate a winning response that aligns with company strengths and RFP requirements.\n",
        "\n",
        "Your task is to extract a comprehensive list of \"questions\" that will:\n",
        "1. Address all RFP requirements\n",
        "2. Highlight company differentiators\n",
        "3. Demonstrate clear competitive advantages\n",
        "4. Showcase relevant experience and capabilities\n",
        "\n",
        "When extracting questions, you MUST:\n",
        "1. Create questions that specifically target information available in the knowledge base\n",
        "2. Ensure questions will elicit responses that highlight:\n",
        "   - Market position and financial strength ($1.2B revenue, growth metrics)\n",
        "   - Technical capabilities and proprietary solutions (WaveAI Pro, EcoSensor)\n",
        "   - Strategic partnerships and ecosystem relationships\n",
        "   - Sustainability achievements (20% carbon reduction, etc.)\n",
        "   - Industry-specific experience and success metrics\n",
        "   - ROI and value proposition elements\n",
        "3. Make questions specific and targeted. Instead of \"Describe security measures\", use \"Detail how WaveAI Pro's security architecture meets HIPAA compliance requirements while leveraging our partnership with TechInnovate\"\n",
        "4. Ensure questions will generate responses that:\n",
        "   - Include quantifiable metrics and achievements\n",
        "   - Highlight competitive advantages\n",
        "   - Demonstrate clear value proposition\n",
        "   - Showcase relevant experience\n",
        "   - Address specific RFP requirements\n",
        "\n",
        "Additional Requirements:\n",
        "- Questions must be comprehensive and cover all RFP sections\n",
        "- Each question must provide sufficient context for downstream processing\n",
        "- Questions should encourage integration of multiple knowledge base sources\n",
        "- Ensure questions will generate responses that maintain consistent win themes\n",
        "\n",
        "Knowledge Base Files:\n",
        "{file_metadata}\n",
        "RFP Full Template:\n",
        "{rfp_text}\n",
        "\"\"\"\n",
        "\n",
        "GENERATE_OUTPUT_PROMPT = \"\"\"\\\n",
        "You are a senior bid strategist with extensive experience in winning complex technical proposals.\n",
        "Your task is to generate a compelling RFP response that achieves a minimum 75% win probability.\n",
        "\n",
        "Input Materials:\n",
        "<rfp_document>\n",
        "{output_template}\n",
        "</rfp_document>\n",
        "<question_answer_pairs>\n",
        "{answers}\n",
        "</question_answer_pairs>\n",
        "\n",
        "Response Requirements:\n",
        "1. Market Leadership\n",
        "   - Weave $1.2B revenue and market position throughout\n",
        "   - Highlight global presence and growth trajectory\n",
        "   - Emphasize industry rankings and recognition\n",
        "\n",
        "2. Technical Excellence\n",
        "   - Feature WaveAI Pro platform capabilities\n",
        "   - Showcase EcoSensor technology\n",
        "   - Detail proprietary algorithms and innovations\n",
        "   - Emphasize edge computing and integration expertise\n",
        "\n",
        "3. Sustainability Leadership\n",
        "   - Highlight 20% carbon reduction achievement\n",
        "   - Detail energy efficiency metrics\n",
        "   - Showcase environmental certifications\n",
        "   - Quantify sustainability benefits\n",
        "\n",
        "4. Value Proposition\n",
        "   - Include detailed ROI analysis\n",
        "   - Quantify operational benefits\n",
        "   - Highlight cost savings opportunities\n",
        "   - Present clear total cost of ownership\n",
        "\n",
        "5. Partnerships & Experience\n",
        "   - Feature strategic partnerships (TechInnovate, GreenTech)\n",
        "   - Highlight research collaborations\n",
        "   - Showcase relevant case studies\n",
        "   - Include success metrics\n",
        "\n",
        "For sections without direct answers:\n",
        "1. Generate responses that align with known company strengths\n",
        "2. Maintain consistency with established win themes\n",
        "3. Include specific metrics and achievements from similar projects\n",
        "4. Ensure alignment with overall value proposition\n",
        "\n",
        "Output Format:\n",
        "- Generate in markdown format\n",
        "- Follow template structure precisely\n",
        "- Integrate answers seamlessly\n",
        "- Maintain professional tone\n",
        "- Ensure consistent win themes throughout\n",
        "\n",
        "Begin output with direct markdown content, no additional text or markdown indicators.\n",
        "\"\"\"\n",
        "\n",
        "class PDFParser:\n",
        "    \"\"\"Simple PDF parser using PyPDF2.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reader = None\n",
        "\n",
        "    async def aload_data(self, file_path: str) -> List[Document]:\n",
        "        \"\"\"Asynchronously load PDF data and convert to Documents.\"\"\"\n",
        "        return self.load_data(file_path)\n",
        "\n",
        "    def load_data(self, file_path: str) -> List[Document]:\n",
        "        \"\"\"Load PDF data and convert to Documents.\"\"\"\n",
        "        documents = []\n",
        "        try:\n",
        "            with open(file_path, 'rb') as file:\n",
        "                reader = PyPDF2.PdfReader(file)\n",
        "                for page_num in range(len(reader.pages)):\n",
        "                    page = reader.pages[page_num]\n",
        "                    text = page.extract_text()\n",
        "\n",
        "                    # Create document with metadata\n",
        "                    doc = Document(\n",
        "                        text=text,\n",
        "                        metadata={\n",
        "                            'page_num': page_num + 1,\n",
        "                            'file_path': file_path,\n",
        "                            'source': file_path\n",
        "                        }\n",
        "                    )\n",
        "                    documents.append(doc)\n",
        "\n",
        "        except Exception as e:\n",
        "            _logger.error(f\"Error reading PDF {file_path}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "        return documents\n",
        "\n",
        "class OutputQuestions(BaseModel):\n",
        "    \"\"\"List of keys that make up the sections of the RFP response.\"\"\"\n",
        "    questions: List[str]\n",
        "\n",
        "class OutputTemplateEvent(Event):\n",
        "    docs: List[Document]\n",
        "\n",
        "class QuestionsExtractedEvent(Event):\n",
        "    questions: List[str]\n",
        "\n",
        "class HandleQuestionEvent(Event):\n",
        "    question: str\n",
        "\n",
        "class QuestionAnsweredEvent(Event):\n",
        "    question: str\n",
        "    answer: str\n",
        "\n",
        "class CollectedAnswersEvent(Event):\n",
        "    combined_answers: str\n",
        "\n",
        "class LogEvent(Event):\n",
        "    msg: str\n",
        "    delta: bool = False\n",
        "\n",
        "class RFPWorkflow(Workflow):\n",
        "    \"\"\"RFP workflow.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        tools,\n",
        "        parser: PDFParser,\n",
        "        llm: Optional[OpenAI] = None,\n",
        "        similarity_top_k: int = 20,\n",
        "        output_dir: str = \"data_out_rfp\",\n",
        "        agent_system_prompt: str = AGENT_SYSTEM_PROMPT,\n",
        "        generate_output_prompt: str = GENERATE_OUTPUT_PROMPT,\n",
        "        extract_keys_prompt: str = EXTRACT_KEYS_PROMPT,\n",
        "        **kwargs,\n",
        "    ) -> None:\n",
        "        \"\"\"Init params.\"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.tools = tools\n",
        "        self.parser = parser\n",
        "        self.llm = llm or OpenAI(model=\"gpt-4-turbo\")\n",
        "        self.similarity_top_k = similarity_top_k\n",
        "        self.output_dir = output_dir\n",
        "        self.agent_system_prompt = agent_system_prompt\n",
        "        self.extract_keys_prompt = extract_keys_prompt\n",
        "\n",
        "        # Create output directory if it doesn't exist\n",
        "        out_path = Path(self.output_dir) / \"workflow_output\"\n",
        "        if not out_path.exists():\n",
        "            out_path.mkdir(parents=True, exist_ok=True)\n",
        "            os.chmod(str(out_path), 0o0777)\n",
        "\n",
        "        self.generate_output_prompt = PromptTemplate(generate_output_prompt)\n",
        "\n",
        "    @step\n",
        "    async def parse_output_template(\n",
        "        self, ctx: Context, ev: StartEvent\n",
        "    ) -> OutputTemplateEvent:\n",
        "        # Load output template file\n",
        "        out_template_path = Path(\n",
        "            f\"{self.output_dir}/workflow_output/output_template.jsonl\"\n",
        "        )\n",
        "        if out_template_path.exists():\n",
        "            with open(out_template_path, \"r\") as f:\n",
        "                docs = [Document.model_validate_json(line) for line in f]\n",
        "        else:\n",
        "            docs = await self.parser.aload_data(ev.rfp_template_path)\n",
        "            # Save output template to file\n",
        "            with open(out_template_path, \"w\") as f:\n",
        "                for doc in docs:\n",
        "                    f.write(doc.model_dump_json())\n",
        "                    f.write(\"\\n\")\n",
        "\n",
        "        await ctx.set(\"output_template\", docs)\n",
        "        return OutputTemplateEvent(docs=docs)\n",
        "\n",
        "    @step\n",
        "    async def extract_questions(\n",
        "        self, ctx: Context, ev: OutputTemplateEvent\n",
        "    ) -> HandleQuestionEvent:\n",
        "        docs = ev.docs\n",
        "\n",
        "        # Save all_questions to file\n",
        "        out_keys_path = Path(f\"{self.output_dir}/workflow_output/all_keys.txt\")\n",
        "        if out_keys_path.exists():\n",
        "            with open(out_keys_path, \"r\") as f:\n",
        "                output_qs = [q.strip() for q in f.readlines()]\n",
        "        else:\n",
        "            # Try stuffing all text into the prompt\n",
        "            all_text = \"\\n\\n\".join([d.get_content(metadata_mode=\"all\") for d in docs])\n",
        "            prompt = PromptTemplate(template=self.extract_keys_prompt)\n",
        "\n",
        "            file_metadata = \"\\n\\n\".join(\n",
        "                [\n",
        "                    f\"Name:{t.metadata.name}\\nDescription:{t.metadata.description}\"\n",
        "                    for t in self.tools\n",
        "                ]\n",
        "            )\n",
        "            try:\n",
        "                if self._verbose:\n",
        "                    ctx.write_event_to_stream(\n",
        "                        LogEvent(msg=\">> Extracting questions from LLM\")\n",
        "                    )\n",
        "\n",
        "                output_qs = self.llm.structured_predict(\n",
        "                    OutputQuestions,\n",
        "                    prompt,\n",
        "                    file_metadata=file_metadata,\n",
        "                    rfp_text=all_text,\n",
        "                ).questions\n",
        "\n",
        "                if self._verbose:\n",
        "                    qs_text = \"\\n\".join([f\"* {q}\" for q in output_qs])\n",
        "                    ctx.write_event_to_stream(LogEvent(msg=f\">> Questions:\\n{qs_text}\"))\n",
        "\n",
        "            except Exception as e:\n",
        "                _logger.error(f\"Error extracting questions from page: {all_text}\")\n",
        "                _logger.error(e)\n",
        "\n",
        "            with open(out_keys_path, \"w\") as f:\n",
        "                f.write(\"\\n\".join(output_qs))\n",
        "\n",
        "        await ctx.set(\"num_to_collect\", len(output_qs))\n",
        "\n",
        "        for question in output_qs:\n",
        "            ctx.send_event(HandleQuestionEvent(question=question))\n",
        "\n",
        "        return None\n",
        "\n",
        "    @step\n",
        "    async def handle_question(\n",
        "        self, ctx: Context, ev: HandleQuestionEvent\n",
        "    ) -> QuestionAnsweredEvent:\n",
        "        question = ev.question\n",
        "\n",
        "        # Initialize a Function Calling \"research\" agent\n",
        "        research_agent = FunctionCallingAgentWorker.from_tools(\n",
        "            self.tools, llm=self.llm, verbose=False, system_prompt=self.agent_system_prompt\n",
        "        ).as_agent()\n",
        "\n",
        "        response = await research_agent.aquery(question)\n",
        "\n",
        "        if self._verbose:\n",
        "            msg = f\">> Asked question: {question}\\n>> Got response: {str(response)}\"\n",
        "            ctx.write_event_to_stream(LogEvent(msg=msg))\n",
        "\n",
        "        return QuestionAnsweredEvent(question=question, answer=str(response))\n",
        "\n",
        "    @step\n",
        "    async def combine_answers(\n",
        "        self, ctx: Context, ev: QuestionAnsweredEvent\n",
        "    ) -> CollectedAnswersEvent:\n",
        "        num_to_collect = await ctx.get(\"num_to_collect\")\n",
        "        results = ctx.collect_events(ev, [QuestionAnsweredEvent] * num_to_collect)\n",
        "        if results is None:\n",
        "            return None\n",
        "\n",
        "        combined_answers = \"\\n\".join([result.model_dump_json() for result in results])\n",
        "        # Save combined_answers to file\n",
        "        with open(\n",
        "            f\"{self.output_dir}/workflow_output/combined_answers.jsonl\", \"w\"\n",
        "        ) as f:\n",
        "            f.write(combined_answers)\n",
        "\n",
        "        return CollectedAnswersEvent(combined_answers=combined_answers)\n",
        "\n",
        "    @step\n",
        "    async def generate_output(\n",
        "        self, ctx: Context, ev: CollectedAnswersEvent\n",
        "    ) -> StopEvent:\n",
        "        output_template = await ctx.get(\"output_template\")\n",
        "        output_template = \"\\n\".join(\n",
        "            [doc.get_content(\"none\") for doc in output_template]\n",
        "        )\n",
        "\n",
        "        if self._verbose:\n",
        "            ctx.write_event_to_stream(LogEvent(msg=\">> GENERATING FINAL OUTPUT\"))\n",
        "\n",
        "        resp = await self.llm.astream(\n",
        "            self.generate_output_prompt,\n",
        "            output_template=output_template,\n",
        "            answers=ev.combined_answers,\n",
        "        )\n",
        "\n",
        "        final_output = \"\"\n",
        "        async for r in resp:\n",
        "            ctx.write_event_to_stream(LogEvent(msg=r, delta=True))\n",
        "            final_output += r\n",
        "\n",
        "        # Save final_output to file\n",
        "        with open(f\"{self.output_dir}/workflow_output/final_output.md\", \"w\") as f:\n",
        "            f.write(final_output)\n",
        "\n",
        "        return StopEvent(result=final_output)\n",
        "\n",
        "def generate_tool(file: str, file_description: Optional[str] = None):\n",
        "    \"\"\"Return a function that retrieves only within a given file.\"\"\"\n",
        "    filters = MetadataFilters(\n",
        "        filters=[\n",
        "            MetadataFilter(key=\"file_path\", operator=FilterOperator.EQ, value=file),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    def chunk_retriever_fn(query: str) -> str:\n",
        "        retriever = index.as_retriever(similarity_top_k=5, filters=filters)\n",
        "        nodes = retriever.retrieve(query)\n",
        "\n",
        "        full_text = \"\\n\\n========================\\n\\n\".join(\n",
        "            [n.get_content(metadata_mode=\"all\") for n in nodes]\n",
        "        )\n",
        "\n",
        "        return full_text\n",
        "\n",
        "    # Define name as a function of the file\n",
        "    fn_name = Path(file).stem + \"_retrieve\"\n",
        "\n",
        "    tool_description = f\"Retrieves a small set of relevant document chunks from {file}.\"\n",
        "    if file_description is not None:\n",
        "        tool_description += f\"\\n\\nFile Description: {file_description}\"\n",
        "\n",
        "    tool = FunctionTool.from_defaults(\n",
        "        fn=chunk_retriever_fn, name=fn_name, description=tool_description\n",
        "    )\n",
        "\n",
        "    return tool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install llama-index-embeddings-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lKmfuwMFG1Rp",
        "outputId": "a001c10d-8b30-41ea-a7a3-d9d0ba7d8207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index-embeddings-openai in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-openai) (0.11.22)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-openai) (1.52.2)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.16.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (0.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.23.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (24.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index.utils.workflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4RdeXScIf2M",
        "outputId": "26349d2a-7454-4c29-ad3f-5d3bb82e9e5c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama_index.utils.workflow in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from llama_index.utils.workflow) (0.11.22)\n",
            "Requirement already satisfied: pyvis<0.4.0,>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from llama_index.utils.workflow) (0.3.2)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (1.16.0)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from pyvis<0.4.0,>=0.3.2->llama_index.utils.workflow) (7.34.0)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.10/dist-packages (from pyvis<0.4.0,>=0.3.2->llama_index.utils.workflow) (3.1.4)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pyvis<0.4.0,>=0.3.2->llama_index.utils.workflow) (3.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (4.0.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama_index.utils.workflow) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama_index.utils.workflow) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama_index.utils.workflow) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama_index.utils.workflow) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama_index.utils.workflow) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama_index.utils.workflow) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama_index.utils.workflow) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama_index.utils.workflow) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama_index.utils.workflow) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama_index.utils.workflow) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9.6->pyvis<0.4.0,>=0.3.2->llama_index.utils.workflow) (3.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (3.23.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (0.14.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama_index.utils.workflow) (0.8.4)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (24.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama_index.utils.workflow) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama_index.utils.workflow) (0.2.13)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama_index.utils.workflow) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import tiktoken\n",
        "from typing import List, Dict, Any\n",
        "from tqdm import tqdm\n",
        "from llama_index.core import Document\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "class ChunkedPDFProcessor:\n",
        "    def __init__(\n",
        "        self,\n",
        "        chunk_size: int = 1000,\n",
        "        chunk_overlap: int = 200,\n",
        "        max_tokens_per_chunk: int = 2000\n",
        "    ):\n",
        "        self.chunk_size = chunk_size\n",
        "        self.chunk_overlap = chunk_overlap\n",
        "        self.max_tokens_per_chunk = max_tokens_per_chunk\n",
        "        self.tokenizer = tiktoken.encoding_for_model(\"gpt-4-turbo\")\n",
        "\n",
        "    def count_tokens(self, text: str) -> int:\n",
        "        \"\"\"Count tokens in text using tiktoken\"\"\"\n",
        "        return len(self.tokenizer.encode(text))\n",
        "\n",
        "    def chunk_document(self, doc: Document) -> List[Document]:\n",
        "        \"\"\"Split document into chunks while preserving metadata\"\"\"\n",
        "        # Initialize sentence splitter\n",
        "        splitter = SentenceSplitter(\n",
        "            chunk_size=self.chunk_size,\n",
        "            chunk_overlap=self.chunk_overlap\n",
        "        )\n",
        "\n",
        "        # Split into chunks\n",
        "        chunks = splitter.split_text(doc.get_content())\n",
        "\n",
        "        # Create new documents with preserved metadata and chunk info\n",
        "        chunked_docs = []\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            # Count tokens in chunk\n",
        "            token_count = self.count_tokens(chunk)\n",
        "\n",
        "            # Skip empty chunks\n",
        "            if not chunk.strip():\n",
        "                continue\n",
        "\n",
        "            # Create new document with original metadata plus chunk info\n",
        "            new_doc = Document(\n",
        "                text=chunk,\n",
        "                metadata={\n",
        "                    **doc.metadata,\n",
        "                    \"chunk_id\": i,\n",
        "                    \"token_count\": token_count,\n",
        "                    \"total_chunks\": len(chunks)\n",
        "                }\n",
        "            )\n",
        "            chunked_docs.append(new_doc)\n",
        "\n",
        "        return chunked_docs\n",
        "\n",
        "def setup_environment():\n",
        "    \"\"\"Setup directories and environment variables\"\"\"\n",
        "    data_dir = \"/content/data\"\n",
        "    data_out_dir = \"data_out_rfp\"\n",
        "    persist_dir = \"storage_rfp_chroma\"\n",
        "\n",
        "    # Create directories\n",
        "    for dir_path in [data_dir, data_out_dir, persist_dir]:\n",
        "        Path(dir_path).mkdir(exist_ok=True)\n",
        "\n",
        "    return data_dir, data_out_dir, persist_dir\n",
        "\n",
        "def process_files_in_batches(\n",
        "    files: List[str],\n",
        "    parser: Any,\n",
        "    processor: ChunkedPDFProcessor,\n",
        "    data_dir: str,\n",
        "    batch_size: int = 5\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Process files in batches with chunking\"\"\"\n",
        "    summary_llm = OpenAI(model=\"gpt-4-turbo\")\n",
        "    file_dicts = {}\n",
        "\n",
        "    for file_name in tqdm(files, desc=\"Processing files\"):\n",
        "        print(f\"\\n>> Processing file {file_name}\")\n",
        "        file_base = Path(file_name).stem\n",
        "        full_file_path = str(Path(data_dir) / file_name)\n",
        "\n",
        "        # Parse the file\n",
        "        file_docs = parser.load_data(full_file_path)\n",
        "\n",
        "        # Process each document with chunking\n",
        "        chunked_docs = []\n",
        "        for doc in tqdm(file_docs, desc=\"Chunking documents\"):\n",
        "            # Add basic metadata\n",
        "            doc.metadata[\"file_path\"] = file_name\n",
        "            doc.metadata[\"page_num\"] = doc.metadata.get(\"page_label\", 0)\n",
        "\n",
        "            # Chunk the document\n",
        "            doc_chunks = processor.chunk_document(doc)\n",
        "            chunked_docs.extend(doc_chunks)\n",
        "\n",
        "        # Process chunks in batches for summary generation\n",
        "        summaries = []\n",
        "        for i in range(0, len(chunked_docs), batch_size):\n",
        "            batch = chunked_docs[i:i + batch_size]\n",
        "\n",
        "            # Generate summary for batch\n",
        "            summary_index = SummaryIndex(batch)\n",
        "            response = summary_index.as_query_engine(llm=summary_llm).query(\n",
        "                \"Generate a short 1-2 line summary of this section.\"\n",
        "            )\n",
        "            summaries.append(str(response))\n",
        "\n",
        "        # Combine summaries\n",
        "        combined_summary = \"\\n\".join(summaries)\n",
        "        final_summary = SummaryIndex([Document(text=combined_summary)]).as_query_engine(\n",
        "            llm=summary_llm\n",
        "        ).query(\"Combine these summaries into a coherent 1-2 line overview.\")\n",
        "\n",
        "        # Store results\n",
        "        file_dicts[file_name] = {\n",
        "            \"file_path\": full_file_path,\n",
        "            \"docs\": chunked_docs,\n",
        "            \"summary\": str(final_summary),\n",
        "            \"chunk_count\": len(chunked_docs),\n",
        "            \"total_tokens\": sum(doc.metadata[\"token_count\"] for doc in chunked_docs)\n",
        "        }\n",
        "\n",
        "        print(f\">> Generated summary: {str(final_summary)}\")\n",
        "        print(f\">> Chunks created: {len(chunked_docs)}\")\n",
        "        print(f\">> Total tokens: {file_dicts[file_name]['total_tokens']}\")\n",
        "\n",
        "    return file_dicts\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Setup environment\n",
        "    data_dir, data_out_dir, persist_dir = setup_environment()\n",
        "\n",
        "    # Initialize components\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"your_api_key_here\"\n",
        "    files = [\"inno_wave_customer_feedback_2023.pdf\", \"innowave_annual_report_2023.pdf\", \"innowave_competitor_analysis_2023.pdf\",\"innowave_innovation_strategy_roadmap_2023.pdf\", \"innowave_market_research_2023.pdf\" ]\n",
        "    parser = PDFParser()\n",
        "    processor = ChunkedPDFProcessor()\n",
        "\n",
        "    # Initialize vector store\n",
        "    vector_store = ChromaVectorStore.from_params(\n",
        "        collection_name=\"rfp_docs\",\n",
        "        persist_dir=persist_dir\n",
        "    )\n",
        "    index = VectorStoreIndex.from_vector_store(vector_store)\n",
        "\n",
        "    # Process files\n",
        "    file_dicts = process_files_in_batches(files, parser, processor, data_dir)\n",
        "\n",
        "    # Generate tools and workflow\n",
        "    tools = [\n",
        "        generate_tool(f, file_description=file_dicts[f][\"summary\"])\n",
        "        for f in files\n",
        "    ]\n",
        "\n",
        "    # Initialize and run workflow\n",
        "    llm = OpenAI(model=\"gpt-4-turbo\")\n",
        "    workflow = RFPWorkflow(\n",
        "        tools,\n",
        "        parser=parser,\n",
        "        llm=llm,\n",
        "        verbose=True,\n",
        "        timeout=None\n",
        "    )\n",
        "\n",
        "    # Run the workflow\n",
        "    async def run_workflow():\n",
        "        handler = workflow.run(\n",
        "            rfp_template_path=str(Path(data_dir) / \"RFP_sample.pdf\")\n",
        "        )\n",
        "        async for event in handler.stream_events():\n",
        "            if isinstance(event, LogEvent):\n",
        "                if event.delta:\n",
        "                    print(event.msg, end=\"\")\n",
        "                else:\n",
        "                    print(event.msg)\n",
        "        response = await handler\n",
        "        print(str(response))\n",
        "\n",
        "    # Execute workflow\n",
        "    import asyncio\n",
        "    asyncio.run(run_workflow())"
      ],
      "metadata": {
        "id": "gU1n1I6YGp07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e70d2e02-1de9-4898-90f3-9038efe6119d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing files:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">> Processing file inno_wave_customer_feedback_2023.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunking documents: 100%|██████████| 2/2 [00:00<00:00, 290.91it/s]\n",
            "Processing files:  20%|██        | 1/5 [00:03<00:14,  3.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Generated summary: In 2023, InnoWave Inc. received positive feedback for its AI and IoT products, customer service, and sustainability, but was advised to enhance user interfaces, expand product options for SMEs, and improve third-party integration.\n",
            ">> Chunks created: 2\n",
            ">> Total tokens: 840\n",
            "\n",
            ">> Processing file innowave_annual_report_2023.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunking documents: 100%|██████████| 4/4 [00:00<00:00, 317.14it/s]\n",
            "Processing files:  40%|████      | 2/5 [00:08<00:12,  4.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Generated summary: InnoWave Inc.'s 2023 Annual Report reveals a 15% revenue increase to $1.2 billion, attributed to advancements in AI and IoT, sustainability initiatives, and global expansion, with future goals focusing on further technological and market growth.\n",
            ">> Chunks created: 4\n",
            ">> Total tokens: 1686\n",
            "\n",
            ">> Processing file innowave_competitor_analysis_2023.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunking documents: 100%|██████████| 6/6 [00:00<00:00, 646.99it/s]\n",
            "Processing files:  60%|██████    | 3/5 [00:12<00:08,  4.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Generated summary: The InnoWave Inc. Competitor Analysis 2023 examines the AI and IoT markets, identifying key competitors and market shares, and uses the SWOT framework to analyze strategic opportunities for differentiation and growth.\n",
            ">> Chunks created: 6\n",
            ">> Total tokens: 2191\n",
            "\n",
            ">> Processing file innowave_innovation_strategy_roadmap_2023.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunking documents: 100%|██████████| 5/5 [00:00<00:00, 199.62it/s]\n",
            "Processing files:  80%|████████  | 4/5 [00:15<00:03,  3.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Generated summary: InnoWave Inc.'s Innovation Strategy Roadmap for 2023 aims to position the company as a leader in the AI and IoT markets by developing innovative, sustainable solutions and focusing on customer-centric products over the next five years.\n",
            ">> Chunks created: 5\n",
            ">> Total tokens: 1876\n",
            "\n",
            ">> Processing file innowave_market_research_2023.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Chunking documents: 100%|██████████| 4/4 [00:00<00:00, 568.43it/s]\n",
            "Processing files: 100%|██████████| 5/5 [00:18<00:00,  3.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Generated summary: The InnoWave Inc. Market Research Report 2023 offers an in-depth analysis of the global AI and IoT markets, highlighting growth trends, competitive dynamics, and strategic recommendations for market positioning and opportunity exploitation.\n",
            ">> Chunks created: 4\n",
            ">> Total tokens: 1654\n",
            "Running step parse_output_template\n",
            "Step parse_output_template produced event OutputTemplateEvent\n",
            "Running step extract_questions\n",
            "Step extract_questions produced no event\n",
            "Running step handle_question\n",
            "Running step handle_question\n",
            "Running step handle_question\n",
            "Running step handle_question\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step handle_question produced event QuestionAnsweredEvent\n",
            "Running step handle_question\n",
            ">> Asked question: 2. What are the sustainability requirements specified in the RFP for the project?\n",
            ">> Got response: To provide an accurate and compelling response to this question, I will need to access the specific RFP document or any related materials that outline the sustainability requirements for the project. Since I currently do not have direct access to such documents in this environment, I will proceed by outlining a general approach based on typical sustainability requirements often seen in RFPs, especially in sectors related to technology and innovation.\n",
            "\n",
            "Typical sustainability requirements in RFPs may include:\n",
            "\n",
            "1. **Environmental Impact Reduction**: Requirements to demonstrate how the project will minimize environmental impact, including reductions in energy use, waste, and greenhouse gas emissions.\n",
            "\n",
            "2. **Sustainable Materials and Resources**: Expectations to use sustainable, recycled, or certified materials in the project to ensure resource conservation.\n",
            "\n",
            "3. **Compliance with Environmental Regulations**: Adherence to local, national, and international environmental laws and regulations.\n",
            "\n",
            "4. **Sustainability Reporting and Metrics**: Requirements for regular reporting on sustainability metrics, demonstrating continuous improvement in environmental performance.\n",
            "\n",
            "5. **Innovation in Sustainability**: Encouragement or mandates for innovative approaches to enhance sustainability, such as implementing cutting-edge clean technologies or sustainable business practices.\n",
            "\n",
            "6. **Community and Social Impact**: Considerations on how the project will positively impact the local community, including social equity and economic benefits.\n",
            "\n",
            "If you can provide access to the specific RFP document or clarify the context further, I can offer a more tailored and detailed response that aligns with the exact requirements of your project.\n",
            "Running step combine_answers\n",
            "Step combine_answers produced no event\n",
            "Step handle_question produced event QuestionAnsweredEvent\n",
            "Running step handle_question\n",
            ">> Asked question: 1. What are the technical requirements for the IoT integration in the Smart Healthcare IoT Platform Integration Project?\n",
            ">> Got response: The technical requirements for the IoT integration in the Smart Healthcare IoT Platform Integration Project include:\n",
            "\n",
            "1. **Scalability and Flexibility**: The platform must be capable of handling a large number of IoT devices and data points, ensuring scalability to accommodate future growth in device numbers and data complexity.\n",
            "\n",
            "2. **Data Security and Compliance**: Adherence to healthcare regulations such as HIPAA in the U.S., ensuring all data is encrypted and securely transmitted. The platform must also include robust authentication and authorization mechanisms to protect sensitive health data.\n",
            "\n",
            "3. **Real-time Data Processing**: Capabilities for real-time data analysis and processing to provide immediate insights and alerts, which are crucial for patient monitoring and emergency response.\n",
            "\n",
            "4. **Interoperability**: The platform should be compatible with various types of healthcare IoT devices and able to integrate seamlessly with existing healthcare systems and software.\n",
            "\n",
            "5. **User-friendly Interface**: A simple, intuitive user interface that allows healthcare professionals to easily access and interpret data, enhancing the usability of the platform.\n",
            "\n",
            "6. **Reliability and Uptime**: High availability and minimal downtime to ensure continuous monitoring and data collection, which are critical in healthcare settings.\n",
            "\n",
            "These requirements are designed to ensure that the IoT integration not only meets the current needs of healthcare providers but also provides a robust foundation for future technological advancements and expansions in smart healthcare solutions.\n",
            "Running step combine_answers\n",
            "Step combine_answers produced no event\n",
            "Step handle_question produced event QuestionAnsweredEvent\n",
            "Running step handle_question\n",
            ">> Asked question: 4. What are the mandatory qualifications and certifications required from vendors for the project?\n",
            ">> Got response: InnoWave Inc. requires vendors to meet specific qualifications and certifications to ensure compliance with our high standards for quality and sustainability. While the specific documents did not provide detailed mandatory qualifications, based on our industry-leading practices, vendors typically need to demonstrate:\n",
            "\n",
            "1. **ISO Certifications**: Relevant ISO standards such as ISO 9001 for quality management systems and ISO 14001 for environmental management.\n",
            "2. **Industry-Specific Certifications**: Depending on the project's focus, certifications like CMMI (Capability Maturity Model Integration) for software development processes or specific AI and IoT technology certifications may be required.\n",
            "3. **Compliance with Local and International Regulations**: This includes data protection regulations such as GDPR for projects involving data handling and privacy.\n",
            "\n",
            "These standards are crucial for maintaining the integrity and excellence of our projects, aligning with our commitment to innovation and sustainability. If you need more specific details on the qualifications and certifications required for your project, please let us know, and we can provide tailored information.\n",
            "Running step combine_answers\n",
            "Step combine_answers produced no event\n",
            "Step handle_question produced event QuestionAnsweredEvent\n",
            "Running step handle_question\n",
            ">> Asked question: 5. What are the proposal requirements specified in the RFP for vendors?\n",
            ">> Got response: The RFP specifies that vendors must demonstrate a strong track record in delivering AI and IoT solutions, with a focus on sustainability and innovation. Vendors are required to provide detailed case studies of previous projects, evidence of financial stability, and a clear plan for project management and execution. Additionally, the proposal must include a comprehensive risk management strategy and a commitment to meeting aggressive timelines.\n",
            "\n",
            "This requirement underscores the importance of showcasing InnoWave Inc.'s competitive strengths, such as our recent 15% revenue increase driven by advancements in AI and IoT technologies, and our commitment to sustainability as highlighted in our 2023 Annual Report. By emphasizing these achievements, along with our innovative approach as detailed in our Innovation Strategy Roadmap, we can effectively meet the RFP's demands and differentiate ourselves from competitors.\n",
            "Running step combine_answers\n",
            "Step combine_answers produced no event\n",
            "Step handle_question produced event QuestionAnsweredEvent\n",
            "Running step handle_question\n",
            ">> Asked question: 3. What are the security requirements outlined in the RFP for the healthcare monitoring platform?\n",
            ">> Got response: It seems that the specific security requirements for the healthcare monitoring platform are not detailed in the documents I have access to. However, based on industry standards and InnoWave Inc.'s commitment to high-quality, secure solutions, I can infer some likely security requirements that would be pertinent:\n",
            "\n",
            "1. **Data Encryption**: Ensuring that all data transmitted and stored is encrypted using industry-standard protocols to protect patient information.\n",
            "2. **Access Controls**: Implementing strict access controls and authentication measures to ensure that only authorized personnel can access sensitive data.\n",
            "3. **Compliance with Regulations**: Adhering to healthcare industry regulations such as HIPAA in the U.S., which mandates the protection and confidential handling of protected health information.\n",
            "4. **Regular Security Audits**: Conducting regular security audits and vulnerability assessments to identify and mitigate potential security risks.\n",
            "5. **Data Integrity Measures**: Utilizing mechanisms to ensure the integrity of data, preventing unauthorized alterations.\n",
            "\n",
            "These inferred requirements align with best practices in the healthcare technology sector and reflect InnoWave Inc.'s dedication to delivering secure and reliable solutions. If more specific details are needed, I recommend consulting the actual RFP document or additional sources directly related to the project requirements.\n",
            "Running step combine_answers\n",
            "Step combine_answers produced no event\n",
            "Step handle_question produced event QuestionAnsweredEvent\n",
            ">> Asked question: 7. What are the submission guidelines provided in the RFP for vendors to follow?\n",
            ">> Got response: To provide a comprehensive and strategic response to this question, I will need to access the specific RFP document or any related summaries available. Since I currently do not have direct access to the RFP document itself, I will proceed by outlining general best practices and guidelines typically expected in RFP submissions based on industry standards and InnoWave Inc.'s experience with similar documents.\n",
            "\n",
            "1. **Document Format**: Proposals should be submitted in a clear and organized format, typically as a PDF file, to ensure that all information is accessible and readable. This includes a table of contents, clear headings, and an executive summary.\n",
            "\n",
            "2. **Content Requirements**: Proposals often need to address specific questions or requirements outlined in the RFP, such as company background, detailed descriptions of proposed solutions, pricing models, and timelines for implementation.\n",
            "\n",
            "3. **Submission Deadline**: Adhering to the submission deadline is crucial. Late submissions are usually not considered.\n",
            "\n",
            "4. **Compliance**: Ensuring that the proposal meets all the specified requirements in the RFP, including legal and regulatory compliance, especially if the RFP is from a government or regulated industry.\n",
            "\n",
            "5. **Innovative Solutions**: Highlighting unique and innovative solutions that differentiate InnoWave Inc. from competitors, focusing on our strengths in AI and IoT, as well as our commitment to sustainability and customer-centric product development.\n",
            "\n",
            "6. **Evidence of Capability**: Including case studies, testimonials, or performance metrics that demonstrate InnoWave Inc.'s ability to deliver on similar projects successfully.\n",
            "\n",
            "7. **Cost-Benefit Analysis**: Providing a detailed analysis of the projected costs, savings, and ROI for the client, emphasizing InnoWave Inc.'s value proposition.\n",
            "\n",
            "8. **Contact Information**: Ensuring that all relevant contact information is included for follow-up discussions or clarifications.\n",
            "\n",
            "By adhering to these guidelines, InnoWave Inc. can ensure a compelling and compliant proposal submission. If more specific details are needed, accessing the actual RFP document or related summaries would be necessary.\n",
            "Running step combine_answers\n",
            "Step combine_answers produced no event\n",
            "Step handle_question produced event QuestionAnsweredEvent\n",
            ">> Asked question: 6. What are the evaluation criteria for the proposals in terms of technical capability, sustainability focus, experience and expertise, and cost?\n",
            ">> Got response: The evaluation criteria for proposals at InnoWave Inc. focus on several key areas:\n",
            "\n",
            "1. **Technical Capability**: Proposals are assessed based on the robustness, innovation, and reliability of the technical solutions offered. This includes the use of cutting-edge technologies in AI and IoT, as well as the ability to integrate these technologies seamlessly into existing systems.\n",
            "\n",
            "2. **Sustainability Focus**: Given InnoWave Inc.'s commitment to sustainability, proposals are evaluated on their environmental impact. This includes the use of sustainable materials, energy efficiency of the proposed solutions, and the overall carbon footprint.\n",
            "\n",
            "3. **Experience and Expertise**: Proposals are scrutinized for the depth of experience and expertise demonstrated by the proposing team. This includes prior successful deployments of similar technologies, expertise in the AI and IoT sectors, and a proven track record of innovation.\n",
            "\n",
            "4. **Cost**: Cost-effectiveness is a critical criterion. Proposals must not only be competitively priced but also demonstrate a clear return on investment (ROI). This includes long-term cost savings through efficiency improvements and the potential for scalability without significant additional costs.\n",
            "\n",
            "These criteria ensure that InnoWave Inc. partners with vendors and service providers who are not only at the forefront of technology but also aligned with the company's strategic goals and values.\n",
            "Running step combine_answers\n",
            "Step combine_answers produced no event\n",
            "Step handle_question produced event QuestionAnsweredEvent\n",
            ">> Asked question: 8. What is the timeline for the RFP process, including key dates and milestones?\n",
            ">> Got response: To provide a comprehensive and accurate timeline for the RFP process, including key dates and milestones, I will need to review the specific RFP document or any related project documentation that outlines these details. If you can provide the RFP document or direct me to the relevant information, I can extract and summarize the timeline effectively.\n",
            "\n",
            "If the RFP document is not available, a typical RFP process timeline might include the following stages:\n",
            "\n",
            "1. **RFP Issuance**: The date when the RFP is officially released to potential bidders.\n",
            "2. **Pre-bid Meeting**: Often held a week or two after the RFP issuance, this meeting addresses any questions bidders might have.\n",
            "3. **Questions and Clarifications**: A period during which bidders can submit questions, usually closing a week after the pre-bid meeting.\n",
            "4. **Proposal Submission Deadline**: The final date by which all proposals must be submitted, typically 4-6 weeks after the RFP issuance.\n",
            "5. **Evaluation Period**: A few weeks to a couple of months where submitted proposals are reviewed and evaluated.\n",
            "6. **Award Notification**: The date on which the successful bidder is officially notified.\n",
            "7. **Contract Negotiation and Signing**: Occurs shortly after the award notification, with a goal to finalize and sign the contract within a few weeks.\n",
            "8. **Project Commencement**: The start date of the project or service delivery as specified in the RFP.\n",
            "\n",
            "Please confirm if you need a detailed timeline based on a specific RFP or if a general overview suffices.\n",
            "Running step combine_answers\n",
            "Step combine_answers produced no event\n",
            "Step handle_question produced event QuestionAnsweredEvent\n",
            ">> Asked question: 9. What are the terms and conditions set forth in the RFP for vendors participating in the Smart Healthcare IoT Platform Integration Project?\n",
            ">> Got response: To provide the most accurate and detailed response regarding the terms and conditions set forth in the RFP for vendors participating in the Smart Healthcare IoT Platform Integration Project, I would need access to the specific RFP document or a database containing its details. Currently, I do not have direct access to such specific external documents or databases in this environment.\n",
            "\n",
            "However, typically, terms and conditions in an RFP for a project like Smart Healthcare IoT Platform Integration might include:\n",
            "\n",
            "1. **Compliance with Regulations**: Vendors must comply with all relevant healthcare regulations such as HIPAA in the U.S., GDPR in Europe for data protection, and other local healthcare standards.\n",
            "\n",
            "2. **Data Security and Privacy**: Stringent requirements for data security and privacy, including data encryption, secure data storage, and transfer protocols.\n",
            "\n",
            "3. **Project Milestones and Deliverables**: Clear definitions of project milestones, deliverables, and timelines that the vendor must meet.\n",
            "\n",
            "4. **Budget and Pricing**: Detailed financial terms, including pricing structures, payment schedules, and penalties for late or substandard delivery.\n",
            "\n",
            "5. **Intellectual Property Rights**: Conditions related to the ownership of intellectual property developed during the project.\n",
            "\n",
            "6. **Performance Metrics**: Specific performance metrics and KPIs that the vendor must achieve.\n",
            "\n",
            "7. **Audit and Reporting**: Requirements for regular auditing of the project and reporting to the contracting entity.\n",
            "\n",
            "8. **Termination Clauses**: Conditions under which the contract can be terminated.\n",
            "\n",
            "For a precise understanding and to ensure compliance with the RFP terms and conditions, it is recommended to review the actual RFP document or consult with legal and project management professionals familiar with such processes. If you need detailed insights from specific documents or need assistance in accessing such information, please let me know how I can assist further!\n",
            "Running step combine_answers\n",
            "Step combine_answers produced event CollectedAnswersEvent\n",
            "Running step generate_output\n",
            ">> GENERATING FINAL OUTPUT\n",
            "# Executive Summary\n",
            "\n",
            "**InnoWave Inc.** is a global leader in healthcare technology solutions, specializing in the integration of AI and IoT for enhanced healthcare outcomes. With a revenue of $1.2 billion and a robust market position, we are poised to deliver unparalleled value to Metropolitan Healthcare Systems (MHS) through our proposed Smart Healthcare IoT Platform Integration Project. Our proposal outlines a comprehensive approach to meet and exceed the technical, sustainability, and security requirements set forth in RFP Number: HC-IoT-2024-001.\n",
            "\n",
            "## Market Leadership\n",
            "InnoWave Inc. stands as a top-tier provider in the healthcare technology sector, recognized globally for our innovative solutions and rapid growth trajectory. Our presence spans across continents, with significant contributions to digital healthcare transformations. Our industry rankings consistently place us at the forefront, underlining our commitment to excellence and leadership in technology.\n",
            "\n",
            "## Technical Excellence\n",
            "Our proposal leverages the **WaveAI Pro** platform, renowned for its advanced AI capabilities and seamless integration with IoT devices. The platform is supported by our proprietary **EcoSensor technology**, which ensures real-time patient monitoring with minimal environmental impact. Our edge computing solutions facilitate rapid data processing, crucial for the real-time analytics required in modern healthcare settings.\n",
            "\n",
            "## Sustainability Leadership\n",
            "InnoWave Inc. has achieved a 20% reduction in carbon emissions in the past year, underscoring our commitment to environmental responsibility. Our solutions are designed to optimize energy use, significantly lowering operational costs while adhering to the highest environmental standards, including ISO 14001 certification.\n",
            "\n",
            "## Value Proposition\n",
            "Our solution offers a compelling return on investment (ROI) by enhancing operational efficiencies and reducing costs. The integration of our technologies is projected to save MHS up to 30% in operational expenses annually. The total cost of ownership is competitively priced, ensuring that MHS gains long-term financial benefits without compromising on quality or functionality.\n",
            "\n",
            "## Partnerships & Experience\n",
            "InnoWave Inc. has established strategic partnerships with industry leaders such as **TechInnovate** and **GreenTech**, enhancing our R&D capabilities and sustainability initiatives. Our extensive portfolio includes successful implementations across similar healthcare projects, where we have consistently delivered improved patient outcomes and operational efficiency.\n",
            "\n",
            "# Technical Proposal\n",
            "\n",
            "## Solution Architecture\n",
            "The proposed architecture integrates seamlessly with existing EHR and hospital management systems, facilitated by our advanced **WaveAI Pro** platform. This integration supports over 10,000 IoT devices, ensuring scalability and robustness.\n",
            "\n",
            "## Implementation Methodology\n",
            "Our phased implementation approach begins with a pilot program in Q1 2025, followed by full deployment across all facilities within 12 months. This method allows for iterative feedback and continuous improvement, minimizing risks and ensuring project success.\n",
            "\n",
            "## Technical Specifications\n",
            "- **AI-Powered Analytics**: Predictive models for patient care using machine learning algorithms.\n",
            "- **IoT Device Integration**: High-compatibility with diverse medical devices, ensuring comprehensive data capture.\n",
            "- **Edge Computing**: Local data processing for faster response times and reduced bandwidth usage.\n",
            "\n",
            "## Integration Approach\n",
            "Our integration strategy involves minimal disruption to existing workflows, with a strong focus on user training and support. Real-time data synchronization with EHRs ensures that patient records are always updated and accessible.\n",
            "\n",
            "## Security Measures\n",
            "We adhere to HIPAA guidelines and implement end-to-end encryption, multi-factor authentication, and regular security audits to protect patient data.\n",
            "\n",
            "## Sustainability Features\n",
            "Our IoT devices are designed for energy efficiency, significantly reducing the carbon footprint of healthcare operations. We provide detailed metrics on energy savings and sustainability impacts.\n",
            "\n",
            "# Implementation Plan\n",
            "\n",
            "## Project Timeline\n",
            "- **Kick-Off**: March 1, 2025\n",
            "- **Phase 1**: Initial setup and integration testing by Q3 2025\n",
            "- **Phase 2**: Full system rollout by Q1 2026\n",
            "- **Support**: Ongoing post-implementation support for 24 months following system deployment.\n",
            "\n",
            "## Pricing Details\n",
            "\n",
            "### Hardware Components\n",
            "- **EcoSensor Devices**: $500,000\n",
            "- **Networking Equipment**: $200,000\n",
            "\n",
            "### Software Licenses\n",
            "- **WaveAI Pro Platform**: $750,000 annually\n",
            "\n",
            "### Implementation Services\n",
            "- **Setup and Configuration**: $300,000\n",
            "- **Training and Support**: $150,000 annually\n",
            "\n",
            "### Maintenance and Updates\n",
            "- **Regular Updates and System Optimization**: $100,000 annually\n",
            "\n",
            "### Sustainability Initiatives\n",
            "- **Green Technology Upgrades**: $50,000\n",
            "\n",
            "The total investment for the Smart Healthcare IoT Platform Integration Project is projected to be $2.05 million, with substantial cost savings and efficiency improvements realized within the first two years of implementation.\n",
            "\n",
            "# Company Experience\n",
            "\n",
            "InnoWave Inc. has over a decade of experience in delivering cutting-edge healthcare technology solutions. Our previous projects have consistently resulted in enhanced patient care and operational efficiencies, with documented success in over 20 major healthcare systems worldwide.\n",
            "\n",
            "# Team Qualifications\n",
            "\n",
            "Our project team consists of industry-leading experts in AI, IoT, healthcare informatics, and sustainability. Each member holds advanced certifications and has extensive experience in their respective fields.\n",
            "\n",
            "# References\n",
            "\n",
            "Detailed case studies and references from previous projects are available upon request. These documents highlight the impact of our solutions and our commitment to client satisfaction and technological excellence.\n",
            "\n",
            "**Submit proposals to:**\n",
            "Metropolitan Healthcare Systems\n",
            "Procurement Department\n",
            "Email: rfp@mhs-healthcare.com\n",
            "\n",
            "We look forward to the opportunity to collaborate with Metropolitan Healthcare Systems and to bring our technological expertise and innovative solutions to enhance patient care across your network.Step generate_output produced event StopEvent\n",
            "# Executive Summary\n",
            "\n",
            "**InnoWave Inc.** is a global leader in healthcare technology solutions, specializing in the integration of AI and IoT for enhanced healthcare outcomes. With a revenue of $1.2 billion and a robust market position, we are poised to deliver unparalleled value to Metropolitan Healthcare Systems (MHS) through our proposed Smart Healthcare IoT Platform Integration Project. Our proposal outlines a comprehensive approach to meet and exceed the technical, sustainability, and security requirements set forth in RFP Number: HC-IoT-2024-001.\n",
            "\n",
            "## Market Leadership\n",
            "InnoWave Inc. stands as a top-tier provider in the healthcare technology sector, recognized globally for our innovative solutions and rapid growth trajectory. Our presence spans across continents, with significant contributions to digital healthcare transformations. Our industry rankings consistently place us at the forefront, underlining our commitment to excellence and leadership in technology.\n",
            "\n",
            "## Technical Excellence\n",
            "Our proposal leverages the **WaveAI Pro** platform, renowned for its advanced AI capabilities and seamless integration with IoT devices. The platform is supported by our proprietary **EcoSensor technology**, which ensures real-time patient monitoring with minimal environmental impact. Our edge computing solutions facilitate rapid data processing, crucial for the real-time analytics required in modern healthcare settings.\n",
            "\n",
            "## Sustainability Leadership\n",
            "InnoWave Inc. has achieved a 20% reduction in carbon emissions in the past year, underscoring our commitment to environmental responsibility. Our solutions are designed to optimize energy use, significantly lowering operational costs while adhering to the highest environmental standards, including ISO 14001 certification.\n",
            "\n",
            "## Value Proposition\n",
            "Our solution offers a compelling return on investment (ROI) by enhancing operational efficiencies and reducing costs. The integration of our technologies is projected to save MHS up to 30% in operational expenses annually. The total cost of ownership is competitively priced, ensuring that MHS gains long-term financial benefits without compromising on quality or functionality.\n",
            "\n",
            "## Partnerships & Experience\n",
            "InnoWave Inc. has established strategic partnerships with industry leaders such as **TechInnovate** and **GreenTech**, enhancing our R&D capabilities and sustainability initiatives. Our extensive portfolio includes successful implementations across similar healthcare projects, where we have consistently delivered improved patient outcomes and operational efficiency.\n",
            "\n",
            "# Technical Proposal\n",
            "\n",
            "## Solution Architecture\n",
            "The proposed architecture integrates seamlessly with existing EHR and hospital management systems, facilitated by our advanced **WaveAI Pro** platform. This integration supports over 10,000 IoT devices, ensuring scalability and robustness.\n",
            "\n",
            "## Implementation Methodology\n",
            "Our phased implementation approach begins with a pilot program in Q1 2025, followed by full deployment across all facilities within 12 months. This method allows for iterative feedback and continuous improvement, minimizing risks and ensuring project success.\n",
            "\n",
            "## Technical Specifications\n",
            "- **AI-Powered Analytics**: Predictive models for patient care using machine learning algorithms.\n",
            "- **IoT Device Integration**: High-compatibility with diverse medical devices, ensuring comprehensive data capture.\n",
            "- **Edge Computing**: Local data processing for faster response times and reduced bandwidth usage.\n",
            "\n",
            "## Integration Approach\n",
            "Our integration strategy involves minimal disruption to existing workflows, with a strong focus on user training and support. Real-time data synchronization with EHRs ensures that patient records are always updated and accessible.\n",
            "\n",
            "## Security Measures\n",
            "We adhere to HIPAA guidelines and implement end-to-end encryption, multi-factor authentication, and regular security audits to protect patient data.\n",
            "\n",
            "## Sustainability Features\n",
            "Our IoT devices are designed for energy efficiency, significantly reducing the carbon footprint of healthcare operations. We provide detailed metrics on energy savings and sustainability impacts.\n",
            "\n",
            "# Implementation Plan\n",
            "\n",
            "## Project Timeline\n",
            "- **Kick-Off**: March 1, 2025\n",
            "- **Phase 1**: Initial setup and integration testing by Q3 2025\n",
            "- **Phase 2**: Full system rollout by Q1 2026\n",
            "- **Support**: Ongoing post-implementation support for 24 months following system deployment.\n",
            "\n",
            "## Pricing Details\n",
            "\n",
            "### Hardware Components\n",
            "- **EcoSensor Devices**: $500,000\n",
            "- **Networking Equipment**: $200,000\n",
            "\n",
            "### Software Licenses\n",
            "- **WaveAI Pro Platform**: $750,000 annually\n",
            "\n",
            "### Implementation Services\n",
            "- **Setup and Configuration**: $300,000\n",
            "- **Training and Support**: $150,000 annually\n",
            "\n",
            "### Maintenance and Updates\n",
            "- **Regular Updates and System Optimization**: $100,000 annually\n",
            "\n",
            "### Sustainability Initiatives\n",
            "- **Green Technology Upgrades**: $50,000\n",
            "\n",
            "The total investment for the Smart Healthcare IoT Platform Integration Project is projected to be $2.05 million, with substantial cost savings and efficiency improvements realized within the first two years of implementation.\n",
            "\n",
            "# Company Experience\n",
            "\n",
            "InnoWave Inc. has over a decade of experience in delivering cutting-edge healthcare technology solutions. Our previous projects have consistently resulted in enhanced patient care and operational efficiencies, with documented success in over 20 major healthcare systems worldwide.\n",
            "\n",
            "# Team Qualifications\n",
            "\n",
            "Our project team consists of industry-leading experts in AI, IoT, healthcare informatics, and sustainability. Each member holds advanced certifications and has extensive experience in their respective fields.\n",
            "\n",
            "# References\n",
            "\n",
            "Detailed case studies and references from previous projects are available upon request. These documents highlight the impact of our solutions and our commitment to client satisfaction and technological excellence.\n",
            "\n",
            "**Submit proposals to:**\n",
            "Metropolitan Healthcare Systems\n",
            "Procurement Department\n",
            "Email: rfp@mhs-healthcare.com\n",
            "\n",
            "We look forward to the opportunity to collaborate with Metropolitan Healthcare Systems and to bring our technological expertise and innovative solutions to enhance patient care across your network.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.utils.workflow import draw_all_possible_flows\n",
        "\n",
        "draw_all_possible_flows(RFPWorkflow, filename=\"rfp_workflow_Nov10_6:39am_2024.html\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGiG-V0zIlrh",
        "outputId": "e332abd5-c721-41c6-8471-0606799ce67d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'NoneType'>\n",
            "<class '__main__.CollectedAnswersEvent'>\n",
            "<class '__main__.HandleQuestionEvent'>\n",
            "<class 'llama_index.core.workflow.events.StopEvent'>\n",
            "<class '__main__.QuestionAnsweredEvent'>\n",
            "<class '__main__.OutputTemplateEvent'>\n",
            "rfp_workflow_Nov10_6:39am_2024.html\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YLJy3ZQ0NEvT",
        "outputId": "1ff993e0-5485-416a-e4fb-681eba4e80fd",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dspy in /usr/local/lib/python3.11/dist-packages (2.6.27)\n",
            "Requirement already satisfied: backoff>=2.2 in /usr/local/lib/python3.11/dist-packages (from dspy) (2.2.1)\n",
            "Requirement already satisfied: joblib~=1.3 in /usr/local/lib/python3.11/dist-packages (from dspy) (1.5.1)\n",
            "Requirement already satisfied: openai>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from dspy) (1.91.0)\n",
            "Requirement already satisfied: pandas>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from dspy) (2.2.2)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.11/dist-packages (from dspy) (2024.11.6)\n",
            "Requirement already satisfied: ujson>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from dspy) (5.10.0)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from dspy) (4.67.1)\n",
            "Requirement already satisfied: datasets>=2.14.6 in /usr/local/lib/python3.11/dist-packages (from dspy) (3.6.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from dspy) (2.32.3)\n",
            "Requirement already satisfied: optuna>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from dspy) (4.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from dspy) (2.11.7)\n",
            "Requirement already satisfied: magicattr>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from dspy) (0.1.6)\n",
            "Requirement already satisfied: litellm>=1.60.3 in /usr/local/lib/python3.11/dist-packages (from dspy) (1.73.2)\n",
            "Requirement already satisfied: diskcache>=5.6.0 in /usr/local/lib/python3.11/dist-packages (from dspy) (5.6.3)\n",
            "Requirement already satisfied: json-repair>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from dspy) (0.47.4)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from dspy) (8.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from dspy) (4.9.0)\n",
            "Requirement already satisfied: asyncer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from dspy) (0.0.8)\n",
            "Requirement already satisfied: cachetools>=5.5.0 in /usr/local/lib/python3.11/dist-packages (from dspy) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dspy) (3.1.1)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from dspy) (13.9.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from dspy) (2.0.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio->dspy) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->dspy) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->dspy) (4.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->dspy) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->dspy) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->dspy) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->dspy) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->dspy) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->dspy) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->dspy) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->dspy) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->dspy) (6.0.2)\n",
            "Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.60.3->dspy) (3.11.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from litellm>=1.60.3->dspy) (8.2.1)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.60.3->dspy) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.60.3->dspy) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.60.3->dspy) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.60.3->dspy) (4.24.0)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.60.3->dspy) (1.1.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.60.3->dspy) (0.9.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm>=1.60.3->dspy) (0.21.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=0.28.1->dspy) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=0.28.1->dspy) (0.10.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.4.0->dspy) (1.16.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna>=3.4.0->dspy) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.4.0->dspy) (2.0.41)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.1->dspy) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.1->dspy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.1->dspy) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dspy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dspy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dspy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->dspy) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->dspy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->dspy) (2025.6.15)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->dspy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->dspy) (2.19.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (1.20.1)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy) (1.1.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm>=1.60.3->dspy) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.60.3->dspy) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets>=2.14.6->dspy) (1.1.5)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.60.3->dspy) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.60.3->dspy) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy) (0.25.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1.1->dspy) (1.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.4.0->dspy) (3.2.3)\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.12.44)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.11)\n",
            "Requirement already satisfied: llama-index-cli<0.5,>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-core<0.13,>=0.12.44 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.44)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.7.7)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.7)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.6,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.5.1)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.2)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.9)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.91.0)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (3.11.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (2.1.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (1.0.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.44->llama-index) (2.0.41)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (4.14.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama-index) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud==0.1.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.26)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud==0.1.26->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.6.15)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (4.13.4)\n",
            "Requirement already satisfied: pandas<2.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.2.2)\n",
            "Requirement already satisfied: pypdf<6,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (5.6.1)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.34)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index) (4.3.8)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.44->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.44->llama-index) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.44->llama-index) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.44->llama-index) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.44->llama-index) (0.2.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.32 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.34)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.44->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.44->llama-index) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.44->llama-index) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.44->llama-index) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.44->llama-index) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.44->llama-index) (3.2.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.44->llama-index) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.44->llama-index) (3.26.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.32->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.44->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (1.17.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index) (3.0.2)\n",
            "Collecting mlflow\n",
            "  Using cached mlflow-3.1.1-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting mlflow-skinny==3.1.1 (from mlflow)\n",
            "  Using cached mlflow_skinny-3.1.1-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.1)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.16.2)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.11/dist-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<21,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.41)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (8.2.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.1)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.57.0)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.115.13)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (1.34.1)\n",
            "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow)\n",
            "  Using cached opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (2.11.7)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (4.14.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.34.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.4.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.6)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.3)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==3.1.1->mlflow) (0.46.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow) (0.55b1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (2025.6.15)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==3.1.1->mlflow) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.6.1)\n",
            "Using cached mlflow-3.1.1-py3-none-any.whl (24.7 MB)\n",
            "Using cached mlflow_skinny-3.1.1-py3-none-any.whl (1.9 MB)\n",
            "Using cached opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
            "Installing collected packages: opentelemetry-sdk, mlflow-skinny, mlflow\n",
            "Successfully installed mlflow-3.1.1 mlflow-skinny-3.1.1 opentelemetry-sdk-1.34.1\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.13)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: mlflow>=3.1 in /usr/local/lib/python3.11/dist-packages (from mlflow[databricks]>=3.1) (3.1.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.91.0)\n",
            "Collecting openai\n",
            "  Downloading openai-1.93.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: mlflow-skinny==3.1.1 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (3.1.1)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (3.1.1)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (1.16.2)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (23.0.0)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<21,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (1.15.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=3.1->mlflow[databricks]>=3.1) (2.0.41)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (8.2.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (3.1.1)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (0.57.0)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (0.115.13)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (1.34.1)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (24.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (2.11.7)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (4.14.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (0.34.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Collecting azure-storage-file-datalake>12 (from mlflow[databricks]>=3.1)\n",
            "  Downloading azure_storage_file_datalake-12.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: google-cloud-storage>=1.30.0 in /usr/local/lib/python3.11/dist-packages (from mlflow[databricks]>=3.1) (2.19.0)\n",
            "Collecting boto3>1 (from mlflow[databricks]>=3.1)\n",
            "  Downloading boto3-1.38.46-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting botocore (from mlflow[databricks]>=3.1)\n",
            "  Downloading botocore-1.38.46-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting databricks-agents<2.0,>=1.0.0 (from mlflow[databricks]>=3.1)\n",
            "  Downloading databricks_agents-1.1.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow>=3.1->mlflow[databricks]>=3.1) (1.1.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Collecting azure-core>=1.30.0 (from azure-storage-file-datalake>12->mlflow[databricks]>=3.1)\n",
            "  Downloading azure_core-1.34.0-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-storage-blob>=12.25.1 (from azure-storage-file-datalake>12->mlflow[databricks]>=3.1)\n",
            "  Downloading azure_storage_blob-12.25.1-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-file-datalake>12->mlflow[databricks]>=3.1)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>1->mlflow[databricks]>=3.1)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3>1->mlflow[databricks]>=3.1)\n",
            "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore->mlflow[databricks]>=3.1) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore->mlflow[databricks]>=3.1) (2.4.0)\n",
            "Collecting databricks-connect (from databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1)\n",
            "  Downloading databricks_connect-16.1.6-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (0.6.7)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1)\n",
            "  Downloading databricks_sdk-0.55.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: jinja2>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (3.1.6)\n",
            "Requirement already satisfied: tenacity>=8.5 in /usr/local/lib/python3.11/dist-packages (from databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (0.9.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow>=3.1->mlflow[databricks]>=3.1) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow>=3.1->mlflow[databricks]>=3.1) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow>=3.1->mlflow[databricks]>=3.1) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow>=3.1->mlflow[databricks]>=3.1) (3.1.3)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (2.38.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (2.25.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (1.7.1)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow>=3.1->mlflow[databricks]>=3.1) (3.2.6)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow>=3.1->mlflow[databricks]>=3.1) (3.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=3.1->mlflow[databricks]>=3.1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=3.1->mlflow[databricks]>=3.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=3.1->mlflow[databricks]>=3.1) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=3.1->mlflow[databricks]>=3.1) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=3.1->mlflow[databricks]>=3.1) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=3.1->mlflow[databricks]>=3.1) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow>=3.1->mlflow[databricks]>=3.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow>=3.1->mlflow[databricks]>=3.1) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (0.4.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow>=3.1->mlflow[databricks]>=3.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow>=3.1->mlflow[databricks]>=3.1) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow>=3.1->mlflow[databricks]>=3.1) (3.2.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from azure-core>=1.30.0->azure-storage-file-datalake>12->mlflow[databricks]>=3.1) (1.17.0)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.11/dist-packages (from azure-storage-blob>=12.25.1->azure-storage-file-datalake>12->mlflow[databricks]>=3.1) (43.0.3)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (0.46.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (4.0.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (1.70.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (1.26.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (0.55b1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (3.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.8.0->databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (2024.11.6)\n",
            "Requirement already satisfied: grpcio-status>=1.59.3 in /usr/local/lib/python3.11/dist-packages (from databricks-connect->databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (1.71.0)\n",
            "Requirement already satisfied: grpcio>=1.59.3 in /usr/local/lib/python3.11/dist-packages (from databricks-connect->databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (1.73.0)\n",
            "Collecting numpy<3 (from mlflow>=3.1->mlflow[databricks]>=3.1)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from databricks-connect->databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (0.10.9.7)\n",
            "Requirement already satisfied: setuptools>=68.0.0 in /usr/local/lib/python3.11/dist-packages (from databricks-connect->databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (80.9.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (0.9.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=2.1.4->azure-storage-blob>=12.25.1->azure-storage-file-datalake>12->mlflow[databricks]>=3.1) (1.17.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow>=3.1->mlflow[databricks]>=3.1) (5.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1) (0.6.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->databricks-agents<2.0,>=1.0.0->mlflow[databricks]>=3.1) (1.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.25.1->azure-storage-file-datalake>12->mlflow[databricks]>=3.1) (2.22)\n",
            "Downloading openai-1.93.0-py3-none-any.whl (755 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m755.0/755.0 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_storage_file_datalake-12.20.0-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.38.46-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.38.46-py3-none-any.whl (13.7 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_agents-1.1.0-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m189.1/189.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.34.0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m207.4/207.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_storage_blob-12.25.1-py3-none-any.whl (406 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m407.0/407.0 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.55.0-py3-none-any.whl (722 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m722.9/722.9 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_connect-16.1.6-py2.py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, jmespath, isodate, botocore, azure-core, s3transfer, openai, databricks-sdk, azure-storage-blob, databricks-connect, boto3, azure-storage-file-datalake, databricks-agents\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.91.0\n",
            "    Uninstalling openai-1.91.0:\n",
            "      Successfully uninstalled openai-1.91.0\n",
            "  Attempting uninstall: databricks-sdk\n",
            "    Found existing installation: databricks-sdk 0.57.0\n",
            "    Uninstalling databricks-sdk-0.57.0:\n",
            "      Successfully uninstalled databricks-sdk-0.57.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed azure-core-1.34.0 azure-storage-blob-12.25.1 azure-storage-file-datalake-12.20.0 boto3-1.38.46 botocore-1.38.46 databricks-agents-1.1.0 databricks-connect-16.1.6 databricks-sdk-0.55.0 isodate-0.7.2 jmespath-1.0.1 numpy-1.26.4 openai-1.93.0 s3transfer-0.13.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "6d3e24267da34a7d9c43391191b79b45"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Cinema Storyteller: TRUE Multi-Agent System Using DSPy, LlamaIndex, and MLflow\n",
        "# SaturdayJune28_2025\n",
        "\n",
        "\"\"\"\n",
        " Cinema Storyteller: TRUE Multi-Agent Film Critic & Storyteller\n",
        "\n",
        "This implements a REAL multi-agent system where:\n",
        "1. Agents call other agents as tools (visible in MLflow traces)\n",
        "2. Agents make autonomous decisions about coordination\n",
        "3. Agent-to-agent communication and orchestration\n",
        "4. Each agent has independent reasoning loops\n",
        "\"\"\"\n",
        "\n",
        "# =============================================================================\n",
        "#  SECTION 1: Environment Setup & Dependencies (Your fixes preserved)\n",
        "# =============================================================================\n",
        "\n",
        "# Install required packages\n",
        "!pip install dspy\n",
        "!pip install llama-index\n",
        "!pip install mlflow\n",
        "!pip install requests\n",
        "!pip install gradio\n",
        "!pip install -U 'mlflow[databricks]>=3.1' openai\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import required libraries\n",
        "import dspy\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List, Dict, Optional, Any\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "import mlflow\n",
        "import gradio as gr\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "print(\" All packages installed successfully!\")\n",
        "\n",
        "# =============================================================================\n",
        "#  SECTION 2: API Configuration (Your fixes preserved)\n",
        "# =============================================================================\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "# Set up your API keys (Your configuration preserved)\n",
        "OPENAI_API_KEY = \"your_api_key_here\"\n",
        "TMDB_API_KEY = \"your_api_key_here\"\n",
        "\n",
        "# Configure environment\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n",
        "# Configure DSPy (Your fix preserved)\n",
        "llm = dspy.LM(model=\"openai/gpt-4o-mini\", max_tokens=1000)\n",
        "dspy.settings.configure(lm=llm)\n",
        "\n",
        "# Configure LlamaIndex (Your fix preserved)\n",
        "Settings.llm = OpenAI(model=\"gpt-4o-mini\")\n",
        "Settings.embed_model = OpenAIEmbedding()\n",
        "\n",
        "# Set Databricks authentication (Your fix preserved)\n",
        "DATABRICKS_HOST = \"https://<your_id>.cloud.databricks.com\"\n",
        "DATABRICKS_TOKEN = getpass(\"Enter your Databricks PAT: \")\n",
        "\n",
        "os.environ[\"DATABRICKS_HOST\"] = DATABRICKS_HOST\n",
        "os.environ[\"DATABRICKS_TOKEN\"] = DATABRICKS_TOKEN\n",
        "\n",
        "# Configure MLflow (Your fix preserved)\n",
        "mlflow.set_tracking_uri(\"databricks\")\n",
        "mlflow.set_experiment(\"/Users/<your-userid>/<your-experiment-name>\")\n",
        "mlflow.autolog()\n",
        "\n",
        "print(\" API configuration complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yccZSKRcOFcY",
        "outputId": "edde0a1d-df96-470c-b1bb-481eddfe58db"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " All packages installed successfully!\n",
            "Enter your Databricks PAT: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/06/28 09:20:37 INFO mlflow.tracking.fluent: Experiment with name '/Users/movcro5@gmail.com/cinema-storyteller-multiagent-tmdbapi' does not exist. Creating a new experiment.\n",
            "2025/06/28 09:20:38 INFO mlflow.tracking.fluent: Autologging successfully enabled for dspy.\n",
            "2025/06/28 09:20:38 INFO mlflow.tracking.fluent: Autologging successfully enabled for langchain.\n",
            "2025/06/28 09:20:38 INFO mlflow.tracking.fluent: Autologging successfully enabled for litellm.\n",
            "2025/06/28 09:20:38 INFO mlflow.tracking.fluent: Autologging successfully enabled for llama_index.core.\n",
            "2025/06/28 09:20:39 INFO mlflow.tracking.fluent: Autologging successfully enabled for openai.\n",
            "2025/06/28 09:20:39 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2025/06/28 09:20:39 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " API configuration complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "#  SECTION 3: Movie Data & Knowledge Base (COMPLETE REPLACEMENT)\n",
        "# =============================================================================\n",
        "\n",
        "class EnhancedTMDBClient:\n",
        "    \"\"\"Enhanced TMDB API client with quality filtering for better recommendations\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str):\n",
        "        self.api_key = api_key\n",
        "        self.base_url = \"https://api.themoviedb.org/3\"\n",
        "\n",
        "    def search_movie(self, title: str) -> Dict:\n",
        "        \"\"\"Search for a movie by title\"\"\"\n",
        "        url = f\"{self.base_url}/search/movie\"\n",
        "        params = {\n",
        "            \"api_key\": self.api_key,\n",
        "            \"query\": title,\n",
        "            \"language\": \"en-US\"\n",
        "        }\n",
        "        try:\n",
        "            response = requests.get(url, params=params)\n",
        "            if response.status_code == 200:\n",
        "                results = response.json().get(\"results\", [])\n",
        "                return results[0] if results else {}\n",
        "        except Exception as e:\n",
        "            print(f\"Error searching movie: {e}\")\n",
        "        return {}\n",
        "\n",
        "    def get_movie_details(self, movie_id: int) -> Dict:\n",
        "        \"\"\"Get detailed movie information including cast, crew, keywords\"\"\"\n",
        "        url = f\"{self.base_url}/movie/{movie_id}\"\n",
        "        params = {\n",
        "            \"api_key\": self.api_key,\n",
        "            \"append_to_response\": \"credits,keywords,similar,recommendations\"\n",
        "        }\n",
        "        try:\n",
        "            response = requests.get(url, params=params)\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting movie details: {e}\")\n",
        "        return {}\n",
        "\n",
        "    def get_movie_recommendations(self, movie_id: int) -> List[Dict]:\n",
        "        \"\"\"Get movie recommendations from TMDB\"\"\"\n",
        "        url = f\"{self.base_url}/movie/{movie_id}/recommendations\"\n",
        "        params = {\n",
        "            \"api_key\": self.api_key,\n",
        "            \"language\": \"en-US\"\n",
        "        }\n",
        "        try:\n",
        "            response = requests.get(url, params=params)\n",
        "            if response.status_code == 200:\n",
        "                return response.json().get(\"results\", [])\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting recommendations: {e}\")\n",
        "        return []\n",
        "\n",
        "    def get_genre_based_recommendations(self, genre_ids: List[int], exclude_id: int = None) -> List[Dict]:\n",
        "        \"\"\"Get movies by genre for better recommendations\"\"\"\n",
        "        url = f\"{self.base_url}/discover/movie\"\n",
        "        params = {\n",
        "            \"api_key\": self.api_key,\n",
        "            \"with_genres\": \",\".join(map(str, genre_ids)),\n",
        "            \"sort_by\": \"popularity.desc\",\n",
        "            \"vote_count.gte\": 100,  # Ensure quality movies\n",
        "            \"language\": \"en-US\"\n",
        "        }\n",
        "        try:\n",
        "            response = requests.get(url, params=params)\n",
        "            if response.status_code == 200:\n",
        "                results = response.json().get(\"results\", [])\n",
        "                # Exclude the original movie\n",
        "                if exclude_id:\n",
        "                    results = [movie for movie in results if movie.get(\"id\") != exclude_id]\n",
        "                return results[:10]  # Return top 10\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting genre recommendations: {e}\")\n",
        "        return []\n",
        "\n",
        "    def extract_movie_metadata(self, movie_details: Dict) -> Dict:\n",
        "        \"\"\"Extract structured metadata from TMDB movie details\"\"\"\n",
        "        if not movie_details:\n",
        "            return {}\n",
        "\n",
        "        # Extract genres with IDs\n",
        "        genres = []\n",
        "        genre_ids = []\n",
        "        for genre in movie_details.get(\"genres\", []):\n",
        "            genres.append(genre[\"name\"].lower())\n",
        "            genre_ids.append(genre[\"id\"])\n",
        "\n",
        "        # Extract cast (top 5)\n",
        "        cast = []\n",
        "        credits = movie_details.get(\"credits\", {})\n",
        "        for actor in credits.get(\"cast\", [])[:5]:\n",
        "            cast.append(actor.get(\"name\", \"\"))\n",
        "\n",
        "        # Extract director and key crew\n",
        "        crew = credits.get(\"crew\", [])\n",
        "        director = \"\"\n",
        "        cinematographer = \"\"\n",
        "        composer = \"\"\n",
        "\n",
        "        for person in crew:\n",
        "            job = person.get(\"job\", \"\")\n",
        "            if job == \"Director\":\n",
        "                director = person.get(\"name\", \"\")\n",
        "            elif job == \"Director of Photography\":\n",
        "                cinematographer = person.get(\"name\", \"\")\n",
        "            elif job == \"Original Music Composer\":\n",
        "                composer = person.get(\"name\", \"\")\n",
        "\n",
        "        # Extract keywords as themes\n",
        "        keywords_data = movie_details.get(\"keywords\", {})\n",
        "        themes = [kw[\"name\"].lower() for kw in keywords_data.get(\"keywords\", [])[:10]]\n",
        "\n",
        "        # Add genre-based themes\n",
        "        themes.extend(genres)\n",
        "\n",
        "        # Determine visual style based on genres and keywords\n",
        "        visual_style = []\n",
        "        if \"science fiction\" in genres:\n",
        "            visual_style.extend([\"futuristic\", \"high-tech\", \"visual effects\"])\n",
        "        if \"action\" in genres:\n",
        "            visual_style.extend([\"dynamic cinematography\", \"practical stunts\"])\n",
        "        if \"drama\" in genres:\n",
        "            visual_style.extend([\"character-focused\", \"realistic\"])\n",
        "        if \"thriller\" in genres:\n",
        "            visual_style.extend([\"suspenseful\", \"dark atmosphere\"])\n",
        "        if \"adventure\" in genres:\n",
        "            visual_style.extend([\"epic scope\", \"exploration\", \"journey\"])\n",
        "\n",
        "        # Build director style\n",
        "        director_style = [director] if director else []\n",
        "        if cinematographer:\n",
        "            director_style.append(f\"cinematography by {cinematographer}\")\n",
        "        if composer:\n",
        "            director_style.append(f\"score by {composer}\")\n",
        "\n",
        "        return {\n",
        "            \"title\": movie_details.get(\"title\", \"\"),\n",
        "            \"release_date\": movie_details.get(\"release_date\", \"\"),\n",
        "            \"overview\": movie_details.get(\"overview\", \"\"),\n",
        "            \"genres\": genres,\n",
        "            \"genre_ids\": genre_ids,\n",
        "            \"themes\": themes,\n",
        "            \"visual_style\": visual_style,\n",
        "            \"director\": director,\n",
        "            \"director_style\": director_style,\n",
        "            \"cast\": cast,\n",
        "            \"runtime\": movie_details.get(\"runtime\", 0),\n",
        "            \"vote_average\": movie_details.get(\"vote_average\", 0),\n",
        "            \"tmdb_id\": movie_details.get(\"id\", 0)\n",
        "        }\n",
        "\n",
        "    def get_quality_filtered_recommendations(self, title: str) -> Dict:\n",
        "        \"\"\"Get high-quality movie recommendations with multiple strategies\"\"\"\n",
        "        # First search for the movie\n",
        "        search_result = self.search_movie(title)\n",
        "        if not search_result:\n",
        "            return {\"error\": f\"Movie '{title}' not found in TMDB\"}\n",
        "\n",
        "        movie_id = search_result.get(\"id\")\n",
        "        if not movie_id:\n",
        "            return {\"error\": f\"No valid movie ID found for '{title}'\"}\n",
        "\n",
        "        # Get detailed information\n",
        "        details = self.get_movie_details(movie_id)\n",
        "        if not details:\n",
        "            return {\"error\": f\"Could not retrieve details for '{title}'\"}\n",
        "\n",
        "        # Extract structured metadata\n",
        "        metadata = self.extract_movie_metadata(details)\n",
        "\n",
        "        # Strategy 1: TMDB Similar Movies\n",
        "        similar_movies_data = details.get(\"similar\", {}).get(\"results\", [])\n",
        "        similar_movies = [movie[\"title\"] for movie in similar_movies_data[:5]]\n",
        "\n",
        "        # Strategy 2: TMDB Recommendations\n",
        "        recommendations_data = details.get(\"recommendations\", {}).get(\"results\", [])\n",
        "        tmdb_recommendations = [movie[\"title\"] for movie in recommendations_data[:5]]\n",
        "\n",
        "        # Strategy 3: Genre-based recommendations (for better quality)\n",
        "        genre_based = []\n",
        "        if metadata.get(\"genre_ids\"):\n",
        "            genre_movies = self.get_genre_based_recommendations(\n",
        "                metadata[\"genre_ids\"],\n",
        "                exclude_id=movie_id\n",
        "            )\n",
        "            genre_based = [movie[\"title\"] for movie in genre_movies[:5]]\n",
        "\n",
        "        # Combine and prioritize\n",
        "        all_recommendations = []\n",
        "\n",
        "        # Add TMDB recommendations first (usually better quality)\n",
        "        all_recommendations.extend(tmdb_recommendations)\n",
        "\n",
        "        # Add genre-based for diversity\n",
        "        for movie in genre_based:\n",
        "            if movie not in all_recommendations:\n",
        "                all_recommendations.append(movie)\n",
        "\n",
        "        # Add similar movies last (sometimes poor quality)\n",
        "        for movie in similar_movies:\n",
        "            if movie not in all_recommendations:\n",
        "                all_recommendations.append(movie)\n",
        "\n",
        "        metadata[\"similar_movies\"] = similar_movies\n",
        "        metadata[\"tmdb_recommendations\"] = tmdb_recommendations\n",
        "        metadata[\"genre_based_recommendations\"] = genre_based\n",
        "        metadata[\"all_recommendations\"] = all_recommendations[:8]  # Top 8 total\n",
        "\n",
        "        return metadata\n",
        "\n",
        "    def get_comprehensive_movie_data(self, title: str) -> Dict:\n",
        "        \"\"\"Get comprehensive movie data for a title - UPDATED\"\"\"\n",
        "        return self.get_quality_filtered_recommendations(title)\n",
        "\n",
        "# Initialize enhanced TMDB client\n",
        "tmdb = EnhancedTMDBClient(TMDB_API_KEY)\n",
        "\n",
        "print(\" Enhanced TMDB client with quality filtering initialized!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLqMs9u3NdTc",
        "outputId": "c159e6a2-4f30-4e63-87c2-22a8b3260968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Enhanced TMDB client with quality filtering initialized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =============================================================================\n",
        "#  SECTION 4: Agent Tools (COMPLETE REPLACEMENT)\n",
        "# =============================================================================\n",
        "\n",
        "def movie_metadata_lookup_tool(movie_title: str) -> str:\n",
        "    \"\"\"Tool for looking up movie metadata from TMDB API\"\"\"\n",
        "    try:\n",
        "        metadata = tmdb.get_comprehensive_movie_data(movie_title)\n",
        "\n",
        "        if \"error\" in metadata:\n",
        "            return f\"Error: {metadata['error']}\"\n",
        "\n",
        "        # Format metadata for agent consumption\n",
        "        formatted_metadata = {\n",
        "            \"title\": metadata.get(\"title\", \"\"),\n",
        "            \"themes\": metadata.get(\"themes\", []),\n",
        "            \"genres\": metadata.get(\"genres\", []),\n",
        "            \"director\": metadata.get(\"director\", \"\"),\n",
        "            \"cast\": metadata.get(\"cast\", []),\n",
        "            \"visual_style\": metadata.get(\"visual_style\", []),\n",
        "            \"overview\": metadata.get(\"overview\", \"\"),\n",
        "            \"similar_movies\": metadata.get(\"similar_movies\", []),\n",
        "            \"recommended_movies\": metadata.get(\"recommended_movies\", [])\n",
        "        }\n",
        "\n",
        "        return json.dumps(formatted_metadata, indent=2)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error retrieving movie data: {str(e)}\"\n",
        "\n",
        "def movie_hypothesis_generator_tool(movie_title: str, metadata: str) -> str:\n",
        "    \"\"\"Tool for generating hypotheses about why user loved a movie using real TMDB data\"\"\"\n",
        "\n",
        "    class HypothesisGenerator(dspy.Signature):\n",
        "        movie_title = dspy.InputField(desc=\"The movie the user loved\")\n",
        "        movie_metadata = dspy.InputField(desc=\"Real movie metadata from TMDB including themes, cast, director\")\n",
        "        hypotheses = dspy.OutputField(desc=\"Three specific hypotheses about what drew them to the movie, separated by '|||'\")\n",
        "\n",
        "    generator = dspy.ChainOfThought(HypothesisGenerator)\n",
        "    result = generator(movie_title=movie_title, movie_metadata=metadata)\n",
        "    return result.hypotheses\n",
        "\n",
        "def thematic_connection_tool(movie_title: str, theme: str) -> str:\n",
        "    \"\"\"Tool for finding thematic connections using LlamaIndex with real TMDB data\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Get the original movie's metadata\n",
        "        original_metadata = tmdb.get_comprehensive_movie_data(movie_title)\n",
        "        if \"error\" in original_metadata:\n",
        "            return f\"Error: {original_metadata['error']}\"\n",
        "\n",
        "        # Build knowledge base from similar and recommended movies\n",
        "        knowledge_docs = []\n",
        "\n",
        "        # Add original movie\n",
        "        doc_content = f\"\"\"\n",
        "        Movie: {original_metadata['title']}\n",
        "        Director: {original_metadata.get('director', 'Unknown')}\n",
        "        Genres: {', '.join(original_metadata.get('genres', []))}\n",
        "        Themes: {', '.join(original_metadata.get('themes', []))}\n",
        "        Cast: {', '.join(original_metadata.get('cast', []))}\n",
        "        Overview: {original_metadata.get('overview', '')}\n",
        "        \"\"\"\n",
        "        knowledge_docs.append(doc_content)\n",
        "\n",
        "        # Add similar movies with their metadata\n",
        "        similar_movies = original_metadata.get(\"similar_movies\", [])\n",
        "        for similar_movie in similar_movies[:3]:  # Limit to avoid API rate limits\n",
        "            similar_metadata = tmdb.get_comprehensive_movie_data(similar_movie)\n",
        "            if \"error\" not in similar_metadata:\n",
        "                similar_doc = f\"\"\"\n",
        "                Movie: {similar_metadata['title']}\n",
        "                Director: {similar_metadata.get('director', 'Unknown')}\n",
        "                Genres: {', '.join(similar_metadata.get('genres', []))}\n",
        "                Themes: {', '.join(similar_metadata.get('themes', []))}\n",
        "                Cast: {', '.join(similar_metadata.get('cast', []))}\n",
        "                Overview: {similar_metadata.get('overview', '')}\n",
        "                Connection to {movie_title}: Similar themes and style\n",
        "                \"\"\"\n",
        "                knowledge_docs.append(similar_doc)\n",
        "\n",
        "        # Create LlamaIndex documents\n",
        "        from llama_index.core import Document\n",
        "        documents = [Document(text=doc) for doc in knowledge_docs]\n",
        "\n",
        "        if not documents:\n",
        "            return f\"No thematic connections found for {movie_title}\"\n",
        "\n",
        "        index = VectorStoreIndex.from_documents(documents)\n",
        "        query_engine = index.as_query_engine(similarity_top_k=3)\n",
        "\n",
        "        query = f\"What movies connect to {movie_title} through the theme of {theme}? Provide specific examples and explanations.\"\n",
        "        response = query_engine.query(query)\n",
        "        return str(response)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error finding thematic connections: {str(e)}\"\n",
        "\n",
        "def narrative_constructor_tool(hypothesis: str, recommended_movie: str, connection_details: str) -> str:\n",
        "    \"\"\"Tool for constructing compelling narrative explanations using real movie data\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Get metadata for the recommended movie\n",
        "        rec_metadata = tmdb.get_comprehensive_movie_data(recommended_movie)\n",
        "\n",
        "        if \"error\" not in rec_metadata:\n",
        "            # Enhance connection details with real movie info\n",
        "            enhanced_details = f\"\"\"\n",
        "            {connection_details}\n",
        "\n",
        "            About {recommended_movie}:\n",
        "            - Director: {rec_metadata.get('director', 'Unknown')}\n",
        "            - Key Themes: {', '.join(rec_metadata.get('themes', [])[:5])}\n",
        "            - Overview: {rec_metadata.get('overview', '')[:200]}...\n",
        "            \"\"\"\n",
        "        else:\n",
        "            enhanced_details = connection_details\n",
        "\n",
        "        class NarrativeConstructor(dspy.Signature):\n",
        "            user_hypothesis = dspy.InputField(desc=\"What aspect of the original movie resonated with the user\")\n",
        "            recommended_movie = dspy.InputField(desc=\"The movie being recommended\")\n",
        "            connection_details = dspy.InputField(desc=\"Specific details about why these movies connect, including real movie metadata\")\n",
        "            narrative_explanation = dspy.OutputField(desc=\"A compelling, story-driven explanation of the recommendation using real movie details\")\n",
        "\n",
        "        constructor = dspy.ChainOfThought(NarrativeConstructor)\n",
        "        result = constructor(\n",
        "            user_hypothesis=hypothesis,\n",
        "            recommended_movie=recommended_movie,\n",
        "            connection_details=enhanced_details\n",
        "        )\n",
        "        return result.narrative_explanation\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error constructing narrative: {str(e)}\"\n",
        "\n",
        "# Tools for orchestrator to call other agents (KEEP THESE SAME)\n",
        "def call_movie_analysis_agent(movie_title: str) -> str:\n",
        "    \"\"\"Tool to call the Movie Analysis Agent\"\"\"\n",
        "    result = movie_analysis_agent(movie_title=movie_title)\n",
        "    return result.analysis_result\n",
        "\n",
        "def call_narrative_agent(hypothesis: str, movie_title: str) -> str:\n",
        "    \"\"\"Tool to call the Narrative Agent\"\"\"\n",
        "    result = narrative_agent(hypothesis=hypothesis, movie_title=movie_title)\n",
        "    return result.narrative_story\n",
        "\n",
        "def call_knowledge_agent(query: str) -> str:\n",
        "    \"\"\"Tool to call the Knowledge Agent\"\"\"\n",
        "    result = knowledge_agent(query=query)\n",
        "    return result.knowledge_result\n",
        "\n",
        "print(\" Updated agent tools with TMDB integration ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7BBJlsXNieY",
        "outputId": "a6fa28e0-6141-4f97-edfc-bb22f23d40ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Updated agent tools with TMDB integration ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "#  SECTION 5: TRUE Multi-Agent System (FIXED)\n",
        "# =============================================================================\n",
        "\n",
        "class MovieAnalysisSignature(dspy.Signature):\n",
        "    \"\"\"You are a movie analysis agent. Use the available tools to analyze user movie preferences and generate recommendations.\"\"\"\n",
        "    movie_title: str = dspy.InputField()\n",
        "    analysis_result: str = dspy.OutputField(desc=\"Complete analysis of the movie with hypotheses and recommendations\")\n",
        "\n",
        "class NarrativeSignature(dspy.Signature):\n",
        "    \"\"\"You are a narrative specialist agent. Create compelling stories that explain movie recommendations.\"\"\"\n",
        "    hypothesis: str = dspy.InputField()\n",
        "    movie_title: str = dspy.InputField()\n",
        "    narrative_story: str = dspy.OutputField(desc=\"Compelling narrative explanation for the recommendation\")\n",
        "\n",
        "class KnowledgeSignature(dspy.Signature):\n",
        "    \"\"\"You are a movie knowledge expert agent. Retrieve and analyze movie information.\"\"\"\n",
        "    query: str = dspy.InputField()\n",
        "    knowledge_result: str = dspy.OutputField(desc=\"Detailed movie knowledge and connections\")\n",
        "\n",
        "class OrchestratorSignature(dspy.Signature):\n",
        "    \"\"\"You are the master orchestrator. Coordinate other specialized agents to provide movie recommendations.\"\"\"\n",
        "    user_input: str = dspy.InputField()\n",
        "    final_recommendations: str = dspy.OutputField(desc=\"Final coordinated movie recommendations with narratives\")\n",
        "\n",
        "# Create individual ReAct agents following your airline example pattern\n",
        "movie_analysis_agent = dspy.ReAct(\n",
        "    MovieAnalysisSignature,\n",
        "    tools=[\n",
        "        movie_metadata_lookup_tool,\n",
        "        movie_hypothesis_generator_tool,\n",
        "        thematic_connection_tool\n",
        "    ]\n",
        ")\n",
        "\n",
        "narrative_agent = dspy.ReAct(\n",
        "    NarrativeSignature,\n",
        "    tools=[\n",
        "        narrative_constructor_tool,\n",
        "        thematic_connection_tool\n",
        "    ]\n",
        ")\n",
        "\n",
        "knowledge_agent = dspy.ReAct(\n",
        "    KnowledgeSignature,\n",
        "    tools=[\n",
        "        movie_metadata_lookup_tool,\n",
        "        thematic_connection_tool\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Tools for orchestrator to call other agents\n",
        "def call_movie_analysis_agent(movie_title: str) -> str:\n",
        "    \"\"\"Tool to call the Movie Analysis Agent\"\"\"\n",
        "    result = movie_analysis_agent(movie_title=movie_title)\n",
        "    return result.analysis_result\n",
        "\n",
        "def call_narrative_agent(hypothesis: str, movie_title: str) -> str:\n",
        "    \"\"\"Tool to call the Narrative Agent\"\"\"\n",
        "    result = narrative_agent(hypothesis=hypothesis, movie_title=movie_title)\n",
        "    return result.narrative_story\n",
        "\n",
        "def call_knowledge_agent(query: str) -> str:\n",
        "    \"\"\"Tool to call the Knowledge Agent\"\"\"\n",
        "    result = knowledge_agent(query=query)\n",
        "    return result.knowledge_result\n",
        "\n",
        "# Master orchestrator with agent tools\n",
        "orchestrator = dspy.ReAct(\n",
        "    OrchestratorSignature,\n",
        "    tools=[\n",
        "        call_movie_analysis_agent,\n",
        "        call_narrative_agent,\n",
        "        call_knowledge_agent,\n",
        "        movie_metadata_lookup_tool,\n",
        "        movie_hypothesis_generator_tool,\n",
        "        thematic_connection_tool,\n",
        "        narrative_constructor_tool\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\" TRUE Multi-Agent System initialized!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCY7E6lJNmmB",
        "outputId": "77c8b587-9873-411d-e631-92e8b7f4b4a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TRUE Multi-Agent System initialized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "#  SECTION 6: Improved Multi-Agent System with Better Recommendations (COMPLETE FIXED)\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class MovieRecommendation:\n",
        "    \"\"\"Structure for a movie recommendation with narrative\"\"\"\n",
        "    title: str\n",
        "    narrative: str\n",
        "    confidence: float\n",
        "    agent_path: str\n",
        "    tmdb_connection: str  # Why TMDB suggested this\n",
        "\n",
        "class TrueMultiAgentCinemaStoryteller:\n",
        "    \"\"\"True multi-agent movie recommendation system with quality filtering\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.recommendation_history = []\n",
        "\n",
        "    def analyze_user_movie(self, movie_title: str) -> Dict:\n",
        "        \"\"\"Main method using true multi-agent coordination with quality filtering\"\"\"\n",
        "\n",
        "        with mlflow.start_run():\n",
        "            # Log user input\n",
        "            mlflow.log_param(\"input_movie\", movie_title)\n",
        "            mlflow.log_param(\"system_type\", \"true_multi_agent_tmdb_quality\")\n",
        "\n",
        "            try:\n",
        "                # Get quality-filtered movie data\n",
        "                movie_data = tmdb.get_quality_filtered_recommendations(movie_title)\n",
        "                if \"error\" in movie_data:\n",
        "                    return {\n",
        "                        \"error\": f\"Movie '{movie_title}' not found in TMDB database. Please check the spelling or try a different title.\",\n",
        "                        \"input_movie\": movie_title\n",
        "                    }\n",
        "\n",
        "                # Get multiple recommendation sources\n",
        "                tmdb_recs = movie_data.get(\"tmdb_recommendations\", [])\n",
        "                genre_recs = movie_data.get(\"genre_based_recommendations\", [])\n",
        "                all_recs = movie_data.get(\"all_recommendations\", [])\n",
        "\n",
        "                # Prepare enhanced prompt with quality data\n",
        "                enhanced_prompt = f\"\"\"\n",
        "I loved the movie {movie_title}. Here's comprehensive data from TMDB:\n",
        "\n",
        "Movie Details:\n",
        "- Director: {movie_data.get('director', 'Unknown')}\n",
        "- Genres: {', '.join(movie_data.get('genres', []))}\n",
        "- Key Themes: {', '.join(movie_data.get('themes', [])[:8])}\n",
        "- Cast: {', '.join(movie_data.get('cast', []))}\n",
        "- Rating: {movie_data.get('vote_average', 0)}/10\n",
        "\n",
        "High-Quality Recommendations:\n",
        "- TMDB Recommendations: {', '.join(tmdb_recs[:3])}\n",
        "- Genre-Based Matches: {', '.join(genre_recs[:3])}\n",
        "- Additional Options: {', '.join(all_recs[6:8])}\n",
        "\n",
        "Find me the best 3 movies I'd love with compelling narrative reasons, prioritizing the TMDB and genre-based recommendations.\n",
        "\"\"\"\n",
        "\n",
        "                # Use orchestrator with enhanced data\n",
        "                raw_result = orchestrator(user_input=enhanced_prompt)\n",
        "\n",
        "                # Parse with improved quality prioritization - FIXED FOR BOLD FORMAT\n",
        "                recommendations = self._parse_quality_recommendations(\n",
        "                    raw_result.final_recommendations,\n",
        "                    movie_title,\n",
        "                    movie_data\n",
        "                )\n",
        "\n",
        "                # Enhanced logging\n",
        "                mlflow.log_metric(\"agents_coordinated\", 4)\n",
        "                mlflow.log_metric(\"recommendations_generated\", len(recommendations))\n",
        "                mlflow.log_metric(\"tmdb_recs_available\", len(tmdb_recs))\n",
        "                mlflow.log_metric(\"genre_recs_available\", len(genre_recs))\n",
        "                mlflow.log_param(\"quality_filtering\", \"enabled\")\n",
        "\n",
        "                # Store enhanced tracking\n",
        "                self.recommendation_history.append({\n",
        "                    \"movie\": movie_title,\n",
        "                    \"movie_data\": movie_data,\n",
        "                    \"raw_agent_result\": raw_result.final_recommendations,\n",
        "                    \"recommendations\": recommendations,\n",
        "                    \"timestamp\": datetime.now(),\n",
        "                    \"tmdb_verified\": True,\n",
        "                    \"quality_sources\": {\n",
        "                        \"tmdb_recs\": len(tmdb_recs),\n",
        "                        \"genre_recs\": len(genre_recs),\n",
        "                        \"total_options\": len(all_recs)\n",
        "                    }\n",
        "                })\n",
        "\n",
        "                return {\n",
        "                    \"input_movie\": movie_title,\n",
        "                    \"movie_data\": movie_data,\n",
        "                    \"agent_coordination_result\": raw_result.final_recommendations,\n",
        "                    \"recommendations\": recommendations,\n",
        "                    \"system_type\": \"true_multi_agent_tmdb_quality\",\n",
        "                    \"tmdb_verified\": True,\n",
        "                    \"quality_sources\": {\n",
        "                        \"tmdb_recommendations\": tmdb_recs,\n",
        "                        \"genre_based\": genre_recs,\n",
        "                        \"all_recommendations\": all_recs\n",
        "                    }\n",
        "                }\n",
        "\n",
        "            except Exception as e:\n",
        "                error_msg = f\"Error in multi-agent analysis: {str(e)}\"\n",
        "                mlflow.log_param(\"error\", error_msg)\n",
        "                return {\n",
        "                    \"error\": error_msg,\n",
        "                    \"input_movie\": movie_title\n",
        "                }\n",
        "\n",
        "    def _parse_quality_recommendations(self, raw_result: str, original_movie: str, movie_data: Dict) -> List[MovieRecommendation]:\n",
        "        \"\"\"Parse results using what agents actually recommended - FIXED FOR BOLD FORMAT\"\"\"\n",
        "\n",
        "        recommendations = []\n",
        "\n",
        "        try:\n",
        "            print(f\" Raw agent result length: {len(raw_result)} characters\")\n",
        "            print(f\" Raw agent result preview: {raw_result[:800]}...\")\n",
        "\n",
        "            # Better movie title extraction for bold format: \"1. **Movie Title**:\"\n",
        "            import re\n",
        "\n",
        "            potential_movies = []\n",
        "            movie_reasoning = {}\n",
        "\n",
        "            # Pattern for: \"1. **Movie Title**: Description\"\n",
        "            pattern = r'(\\d+)\\.\\s*\\*\\*([^*]+)\\*\\*:\\s*([^1-9]*?)(?=\\d+\\.\\s*\\*\\*|\\Z)'\n",
        "            matches = re.findall(pattern, raw_result, re.DOTALL)\n",
        "\n",
        "            print(f\" Found {len(matches)} numbered movie sections\")\n",
        "\n",
        "            for match in matches:\n",
        "                number, movie_title, description = match\n",
        "                movie_title = movie_title.strip()\n",
        "                description = description.strip()\n",
        "\n",
        "                if len(movie_title) > 2 and movie_title.lower() != original_movie.lower():\n",
        "                    potential_movies.append(movie_title)\n",
        "                    movie_reasoning[movie_title] = description[:400]  # Get more description\n",
        "                    print(f\"    {number}. {movie_title}\")\n",
        "\n",
        "            # Fallback: simpler pattern if the above doesn't work\n",
        "            if len(potential_movies) < 2:\n",
        "                print(\" Trying fallback extraction...\")\n",
        "                # Look for **MovieTitle** anywhere\n",
        "                simple_pattern = r'\\*\\*([^*]+)\\*\\*(?=:)'\n",
        "                simple_matches = re.findall(simple_pattern, raw_result)\n",
        "\n",
        "                for movie in simple_matches:\n",
        "                    movie = movie.strip()\n",
        "                    if len(movie) > 2 and movie.lower() != original_movie.lower():\n",
        "                        if movie not in potential_movies:\n",
        "                            potential_movies.append(movie)\n",
        "                            # Find context around this movie\n",
        "                            movie_index = raw_result.find(f\"**{movie}**\")\n",
        "                            if movie_index != -1:\n",
        "                                context = raw_result[movie_index:movie_index+300]\n",
        "                                movie_reasoning[movie] = context\n",
        "                            print(f\"    Fallback: {movie}\")\n",
        "\n",
        "            print(f\" Final extracted movies: {potential_movies}\")\n",
        "\n",
        "            # Get backup movies from TMDB\n",
        "            tmdb_recs = movie_data.get(\"tmdb_recommendations\", [])\n",
        "            genre_recs = movie_data.get(\"genre_based_recommendations\", [])\n",
        "\n",
        "            # Track processed movies to avoid duplicates\n",
        "            processed_titles = set()\n",
        "\n",
        "            # Try agent-mentioned movies first\n",
        "            for i, movie in enumerate(potential_movies[:5]):\n",
        "                if len(recommendations) >= 3:\n",
        "                    break\n",
        "\n",
        "                # Skip if already processed\n",
        "                if movie.lower() in processed_titles:\n",
        "                    print(f\" Skipping duplicate: {movie}\")\n",
        "                    continue\n",
        "\n",
        "                print(f\" Searching TMDB for: '{movie}'\")\n",
        "\n",
        "                # Search for movie with better matching\n",
        "                movie_search = tmdb.search_movie(movie)\n",
        "                if not movie_search:\n",
        "                    print(f\" Movie '{movie}' not found in TMDB\")\n",
        "                    continue\n",
        "\n",
        "                # Get details for the found movie\n",
        "                movie_details = tmdb.get_movie_details(movie_search.get(\"id\"))\n",
        "                if not movie_details:\n",
        "                    print(f\" No details for '{movie}'\")\n",
        "                    continue\n",
        "\n",
        "                movie_metadata = tmdb.extract_movie_metadata(movie_details)\n",
        "\n",
        "                # Verify this is a reasonable match (basic quality check)\n",
        "                if movie_metadata.get('vote_average', 0) < 3.0:\n",
        "                    print(f\" Skipping '{movie}' - very low rating ({movie_metadata.get('vote_average')})\")\n",
        "                    continue\n",
        "\n",
        "                # Add to processed set\n",
        "                processed_titles.add(movie.lower())\n",
        "\n",
        "                # Determine source - FIXED LOGIC\n",
        "                if movie in tmdb_recs:\n",
        "                    source = \"Agent Selected from TMDB Recommendations\"\n",
        "                    confidence_base = 0.95\n",
        "                    print(f\" {movie} found in TMDB recommendations - crediting agent!\")\n",
        "                elif movie in genre_recs:\n",
        "                    source = \"Agent Selected from Genre Matches\"\n",
        "                    confidence_base = 0.85\n",
        "                    print(f\" {movie} found in genre matches - crediting agent!\")\n",
        "                else:\n",
        "                    source = \"Agent Discovered Movie\"\n",
        "                    confidence_base = 0.90\n",
        "                    print(f\" {movie} discovered by agent!\")\n",
        "\n",
        "                # Find meaningful connections\n",
        "                original_genres = set(movie_data.get('genres', []))\n",
        "                movie_genres = set(movie_metadata.get('genres', []))\n",
        "                shared_genres = original_genres.intersection(movie_genres)\n",
        "\n",
        "                original_themes = set(movie_data.get('themes', []))\n",
        "                movie_themes = set(movie_metadata.get('themes', []))\n",
        "                shared_themes = original_themes.intersection(movie_themes)\n",
        "\n",
        "                # Get agent reasoning for this specific movie\n",
        "                agent_reasoning = movie_reasoning.get(movie, \"Multi-agent analysis identified strong connections.\")\n",
        "\n",
        "                # Clean up reasoning text\n",
        "                agent_reasoning = re.sub(r'\\*+', '', agent_reasoning)  # Remove asterisks\n",
        "                agent_reasoning = agent_reasoning.replace('\\n', ' ').strip()\n",
        "\n",
        "                # Create narrative using agent reasoning\n",
        "                narrative = f\"\"\"\n",
        "{movie_metadata.get('title')} was specifically recommended by our multi-agent analysis.\n",
        "\n",
        " **Agent Reasoning**: {agent_reasoning[:250]}...\n",
        "\n",
        " **Verified Connections**:\n",
        " **Shared Genres**: {', '.join(shared_genres) if shared_genres else 'Complementary styles'}\n",
        " **Common Themes**: {', '.join(list(shared_themes)[:3]) if shared_themes else 'Similar storytelling approaches'}\n",
        " **Director**: {movie_metadata.get('director', 'Unknown')}\n",
        "\n",
        " **Why You'll Love It**:\n",
        "{movie_metadata.get('overview', 'A compelling story that our agents identified as matching your taste.')[:150]}...\n",
        "\n",
        " **Quality Score**: {movie_metadata.get('vote_average', 0)}/10 on TMDB\n",
        "\"\"\"\n",
        "\n",
        "                rec = MovieRecommendation(\n",
        "                    title=movie_metadata.get(\"title\", movie),\n",
        "                    narrative=narrative,\n",
        "                    confidence=confidence_base - (i * 0.03),\n",
        "                    agent_path=f\"MultiAgent-Analysis->{source}\",\n",
        "                    tmdb_connection=source\n",
        "                )\n",
        "                recommendations.append(rec)\n",
        "\n",
        "                print(f\" Added: {movie_metadata.get('title')} (Rating: {movie_metadata.get('vote_average')}) - {source}\")\n",
        "\n",
        "            # Fill remaining slots with TMDB backup if needed\n",
        "            if len(recommendations) < 3:\n",
        "                print(f\" Only found {len(recommendations)} from agents, adding TMDB backups...\")\n",
        "                backup_movies = tmdb_recs + genre_recs\n",
        "\n",
        "                for movie in backup_movies:\n",
        "                    if len(recommendations) >= 3:\n",
        "                        break\n",
        "\n",
        "                    # Skip if already processed\n",
        "                    if movie.lower() in processed_titles:\n",
        "                        continue\n",
        "\n",
        "                    movie_metadata = tmdb.get_comprehensive_movie_data(movie)\n",
        "                    if \"error\" not in movie_metadata:\n",
        "                        processed_titles.add(movie.lower())\n",
        "\n",
        "                        narrative = f\"\"\"\n",
        "{movie} was selected as a backup recommendation from TMDB data.\n",
        "\n",
        " **TMDB Connection**: This movie appears in TMDB's recommendations for {original_movie}.\n",
        " **Overview**: {movie_metadata.get('overview', 'No overview available.')[:150]}...\n",
        " **Quality Score**: {movie_metadata.get('vote_average', 0)}/10 on TMDB\n",
        "\"\"\"\n",
        "\n",
        "                        rec = MovieRecommendation(\n",
        "                            title=movie_metadata.get(\"title\", movie),\n",
        "                            narrative=narrative,\n",
        "                            confidence=0.70 - (len(recommendations) * 0.05),\n",
        "                            agent_path=f\"TMDB-Backup->Recommendation\",\n",
        "                            tmdb_connection=\"TMDB Backup Recommendation\"\n",
        "                        )\n",
        "                        recommendations.append(rec)\n",
        "                        print(f\" Added backup: {movie}\")\n",
        "\n",
        "            print(f\" Final recommendations: {[r.title for r in recommendations]}\")\n",
        "            return recommendations\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" Error in parsing: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return []\n",
        "\n",
        "# Initialize the improved multi-agent system\n",
        "true_multiagent_storyteller = TrueMultiAgentCinemaStoryteller()\n",
        "\n",
        "print(\" Improved Multi-Agent System with FIXED bold format parsing ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-ljn3a8Np-U",
        "outputId": "bde8af71-f7fd-40be-a56b-97265d455c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Improved Multi-Agent System with FIXED bold format parsing ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "#  SECTION 7: FIXED Interactive Demo (CORRECTED DATA STRUCTURE)\n",
        "# =============================================================================\n",
        "\n",
        "def create_multiagent_interface():\n",
        "    \"\"\"Create interface showing true multi-agent coordination with TMDB - FIXED\"\"\"\n",
        "\n",
        "    def analyze_with_multiagent(movie_title: str):\n",
        "        \"\"\"Interface function showing agent coordination with real TMDB data - FIXED\"\"\"\n",
        "        if not movie_title.strip():\n",
        "            return \"Please enter a movie title!\", \"\", \"\", \"\"\n",
        "\n",
        "        result = true_multiagent_storyteller.analyze_user_movie(movie_title)\n",
        "\n",
        "        if \"error\" in result:\n",
        "            return result[\"error\"], \"\", \"\", \"\"\n",
        "\n",
        "        movie_data = result.get('movie_data', {})\n",
        "        quality_sources = result.get('quality_sources', {})\n",
        "\n",
        "        # Extract the different recommendation sources (FIXED)\n",
        "        tmdb_recs = quality_sources.get('tmdb_recommendations', [])\n",
        "        genre_recs = quality_sources.get('genre_based', [])\n",
        "        all_recs = quality_sources.get('all_recommendations', [])\n",
        "\n",
        "        # Show TMDB verification with actual data (FIXED)\n",
        "        tmdb_info = f\"\"\"\n",
        "** TMDB Movie Analysis for \"{result['input_movie']}\":**\n",
        "\n",
        " **Movie Found**: {movie_data.get('title', 'Unknown')}\n",
        " **Release**: {movie_data.get('release_date', 'Unknown')}\n",
        " **Director**: {movie_data.get('director', 'Unknown')}\n",
        " **Genres**: {', '.join(movie_data.get('genres', []))}\n",
        " **TMDB Rating**: {movie_data.get('vote_average', 0)}/10\n",
        "\n",
        " **Quality Recommendation Sources Found**:\n",
        " TMDB Recommendations: {len(tmdb_recs)} movies\n",
        " Genre-Based Matches: {len(genre_recs)} movies\n",
        " Total Options: {len(all_recs)} movies\n",
        " Themes Extracted: {len(movie_data.get('themes', []))} themes\n",
        "\"\"\"\n",
        "\n",
        "        # Show agent coordination process (FIXED)\n",
        "        agent_process = f\"\"\"\n",
        "** Multi-Agent Coordination Process:**\n",
        "\n",
        "1. **TMDB Data Collection** \n",
        "   - Retrieved {movie_data.get('title')} metadata\n",
        "   - Found {len(tmdb_recs)} TMDB recommendations: {', '.join(tmdb_recs[:3])}\n",
        "   - Found {len(genre_recs)} genre matches: {', '.join(genre_recs[:3])}\n",
        "\n",
        "2. **Quality Filtering** \n",
        "   - Prioritized TMDB recommendations (highest quality)\n",
        "   - Added genre-based discovery (medium quality)\n",
        "   - Filtered by vote count for quality assurance\n",
        "\n",
        "3. **Orchestrator Agent** \n",
        "   - Received enhanced prompt with quality-filtered data\n",
        "   - Coordinated specialist agents with real movie info\n",
        "\n",
        "4. **Movie Analysis Agent** \n",
        "   - Analyzed themes: {', '.join(movie_data.get('themes', [])[:5])}\n",
        "   - Considered director style: {movie_data.get('director')}\n",
        "\n",
        "5. **Knowledge Agent** \n",
        "   - Built connections using quality-filtered movies\n",
        "   - Cross-referenced with enhanced movie database\n",
        "\n",
        "6. **Narrative Agent** \n",
        "   - Crafted compelling stories using real movie details\n",
        "   - Connected themes, styles, and quality indicators\n",
        "\n",
        "**Enhanced Agent Response:**\n",
        "{result['agent_coordination_result'][:500]}...\n",
        "\"\"\"\n",
        "\n",
        "        # Format recommendations with quality indicators (FIXED)\n",
        "        recommendations_text = \"\"\n",
        "        if result['recommendations']:\n",
        "            for rec in result['recommendations']:\n",
        "                recommendations_text += f\"\"\"\n",
        "** {rec.title}**\n",
        "*Confidence: {rec.confidence:.1%} | Source: {rec.tmdb_connection}*\n",
        "\n",
        "{rec.narrative}\n",
        "\n",
        "---\n",
        "\"\"\"\n",
        "        else:\n",
        "            recommendations_text = \"No recommendations generated. Please try a different movie.\"\n",
        "\n",
        "        # Show REAL comparison with quality sources (FIXED)\n",
        "        system_comparison = f\"\"\"\n",
        "** System Performance with Quality Filtering:**\n",
        "\n",
        "**Input Movie**: {result['input_movie']}\n",
        "**TMDB Data Retrieved**:  Full metadata + Quality filtering\n",
        "\n",
        "**Traditional Recommendation System:**\n",
        " {tmdb_recs[0] if tmdb_recs else 'No data'} (Basic TMDB similarity)\n",
        " {tmdb_recs[1] if len(tmdb_recs) > 1 else 'No data'} (Genre matching)\n",
        " {tmdb_recs[2] if len(tmdb_recs) > 2 else 'No data'} (Rating-based)\n",
        "\n",
        "**Our Enhanced TMDB Multi-Agent System:**\n",
        " **Quality Sources**: {len(tmdb_recs)} TMDB recs + {len(genre_recs)} genre matches\n",
        " **Real Metadata**: {len(movie_data.get('themes', []))} themes, {len(movie_data.get('cast', []))} cast members\n",
        " **Smart Filtering**: Prioritizes quality over quantity\n",
        " **Multi-Agent Reasoning**: Full narrative explanations for each recommendation\n",
        " **Quality Indicators**: Shows source confidence and connection strength\n",
        "\n",
        "**Quality Improvements:**\n",
        " **Better Data**: Genre-based discovery + TMDB recommendations\n",
        " **Smarter Filtering**: Vote count thresholds ensure quality\n",
        " **Enhanced Narratives**: Real movie connections vs generic similarity\n",
        " **Agent Coordination**: Full reasoning chain visible\n",
        "\n",
        "**Database Coverage**: 500,000+ movies with quality filtering\n",
        "**Recommendation Accuracy**: Thematic + narrative + quality scores\n",
        "\"\"\"\n",
        "\n",
        "        return tmdb_info, agent_process, recommendations_text, system_comparison\n",
        "\n",
        "    # Create enhanced Gradio interface\n",
        "    interface = gr.Interface(\n",
        "        fn=analyze_with_multiagent,\n",
        "        inputs=[\n",
        "            gr.Textbox(\n",
        "                label=\" Any Movie Title\",\n",
        "                placeholder=\"Try: Batman Begins, Dune, The Matrix, Parasite, Spirited Away\",\n",
        "                lines=1\n",
        "            )\n",
        "        ],\n",
        "        outputs=[\n",
        "            gr.Textbox(label=\" TMDB Movie Analysis\", lines=12),\n",
        "            gr.Textbox(label=\" Multi-Agent Coordination Process\", lines=15),\n",
        "            gr.Textbox(label=\" Quality-Filtered Recommendations\", lines=12),\n",
        "            gr.Textbox(label=\" Enhanced System Performance\", lines=15)\n",
        "        ],\n",
        "        title=\" ENHANCED: TMDB Multi-Agent Cinema Storyteller\",\n",
        "        description=\"\"\"\n",
        "        **Quality-Enhanced Multi-Agent System with TMDB Integration**\n",
        "\n",
        "         **Quality Improvements:**\n",
        "         **Better Sources**: TMDB recommendations + genre discovery\n",
        "         **Smart Filtering**: Quality thresholds and vote counts\n",
        "         **Enhanced Data**: Director, cast, themes, quality scores\n",
        "         **Multi-Strategy**: 3 recommendation sources prioritized by quality\n",
        "         **Agent Reasoning**: Full narrative explanations for each pick\n",
        "        \"\"\",\n",
        "        examples=[\n",
        "            [\"Batman Begins\"],\n",
        "            [\"Dune\"],\n",
        "            [\"The Matrix\"],\n",
        "            [\"Parasite\"],\n",
        "            [\"Spirited Away\"],\n",
        "            [\"Interstellar\"]\n",
        "        ],\n",
        "        theme=gr.themes.Soft()\n",
        "    )\n",
        "\n",
        "    return interface\n",
        "\n",
        "# Launch the enhanced TMDB multi-agent interface\n",
        "multiagent_demo = create_multiagent_interface()\n",
        "\n",
        "print(\" Enhanced TMDB Multi-Agent Demo ready!\")\n",
        "\n",
        "# No need for additional testing since we tested in Section 6\n",
        "print(\" Interface ready! Quality filtering and multi-agent coordination active.\")\n",
        "\n",
        "# Launch the interface\n",
        "multiagent_demo.launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pkJkcswCNs_A",
        "outputId": "a1c60ff4-4e98-497f-e31a-aa80d30b475d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Enhanced TMDB Multi-Agent Demo ready!\n",
            " Interface ready! Quality filtering and multi-agent coordination active.\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://e2e86add70444150fd.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e2e86add70444150fd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Raw agent result length: 1263 characters\n",
            " Raw agent result preview: 1. **For a Few Dollars More**: Directed by Sergio Leone, this film features Clint Eastwood and Lee Van Cleef as bounty hunters entangled in a morally complex pursuit of a sadistic bandit. The film's exploration of justice versus revenge, combined with its iconic direction and haunting score, makes it a compelling watch for anyone who appreciates the depth of character and narrative complexity found in classic westerns.\n",
            "\n",
            "2. **Once Upon a Time in the West**: Another masterpiece by Sergio Leone, this film delves into the emotional struggles of its characters amidst the backdrop of the American frontier. The story of Jill and the haunting presence of the harmonica serves as a poignant reminder of loss and the personal costs of progress. Its character-driven narrative and rich thematic explorat...\n",
            " Found 3 numbered movie sections\n",
            "    1. For a Few Dollars More\n",
            "    2. Once Upon a Time in the West\n",
            "    3. Django Unchained\n",
            " Final extracted movies: ['For a Few Dollars More', 'Once Upon a Time in the West', 'Django Unchained']\n",
            " Searching TMDB for: 'For a Few Dollars More'\n",
            " For a Few Dollars More found in TMDB recommendations - crediting agent!\n",
            " Added: For a Few Dollars More (Rating: 8.019) - Agent Selected from TMDB Recommendations\n",
            " Searching TMDB for: 'Once Upon a Time in the West'\n",
            " Once Upon a Time in the West found in TMDB recommendations - crediting agent!\n",
            " Added: Once Upon a Time in the West (Rating: 8.283) - Agent Selected from TMDB Recommendations\n",
            " Searching TMDB for: 'Django Unchained'\n",
            " Django Unchained found in genre matches - crediting agent!\n",
            " Added: Django Unchained (Rating: 8.183) - Agent Selected from Genre Matches\n",
            " Final recommendations: ['For a Few Dollars More', 'Once Upon a Time in the West', 'Django Unchained']\n",
            " View run delicate-eel-803 at: https://dbc-730a958a-fe1c.cloud.databricks.com/ml/experiments/3713449945262245/runs/9a0b9d6f5dab4734af440e566f5c694b\n",
            " View experiment at: https://dbc-730a958a-fe1c.cloud.databricks.com/ml/experiments/3713449945262245\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://a009af903256a731b7.gradio.live\n",
            "Killing tunnel 127.0.0.1:7861 <> https://e8a0ffaca89104a916.gradio.live\n",
            "Killing tunnel 127.0.0.1:7862 <> https://520763b7f8d365d4f7.gradio.live\n",
            "Killing tunnel 127.0.0.1:7863 <> https://9f46105cc25f49666f.gradio.live\n",
            "Killing tunnel 127.0.0.1:7864 <> https://dbdbdc26800d2c78bc.gradio.live\n",
            "Killing tunnel 127.0.0.1:7865 <> https://4a78181f3b442a8310.gradio.live\n",
            "Killing tunnel 127.0.0.1:7866 <> https://ad619f6b9ab2cefbe3.gradio.live\n",
            "Killing tunnel 127.0.0.1:7867 <> https://5441a8eed6a2942a09.gradio.live\n",
            "Killing tunnel 127.0.0.1:7868 <> https://e2e86add70444150fd.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}